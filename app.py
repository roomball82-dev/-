# decision_mate_v5_final.py
# âœ… FINAL v5 â€” "ì ˆëŒ€ ê¸°ëŠ¥ ì¶•ì†Œ ì—†ìŒ" í†µí•©ë³¸
# - ì¥ì†Œ íƒ€ì…(ìë™/ì‹ì‚¬/ìˆ /ì¹´í˜) + ìŒì‹ ë¶„ë¥˜(ìë™/í•œ/ì¤‘/ì¼/ì–‘) ì‚¬ì´ë“œë°”
# - í•„í„° ë³€ê²½ ì‹œ ì§ˆë¬¸ íë¦„ë§Œ ë¦¬ì…‹(ëŒ€í™” ìœ ì§€)
# - OpenAI/Kakao í‚¤ ì„¸ì…˜ ìœ ì§€ + ìƒˆ ì¶”ì²œ ë²„íŠ¼(í‚¤ ìœ ì§€)
# - ìì—°ì–´ íŒŒì‹± ë¹¡ì„¸ê²Œ(ëŒ€ë¶€ë¶„ ë¬¸ì¥í˜• ì²˜ë¦¬)
# - "ê·¸ëƒ¥ ì¶”ì²œí•´" fast mode (ì§ˆë¬¸ ì·¨ì†Œ í›„ ì¦‰ì‹œ ì¶”ì²œ)
# - Kakao í›„ë³´ í’€ í™•ì¥(í˜ì´ì§€/ì¤‘ë³µì œê±°/ë°˜ê²½/ì¤‘ì‹¬ì¢Œí‘œ)
# - ì´ë™ìˆ˜ë‹¨/ë„ë³´ì œí•œ/ì£¼ì°¨(ì¶”ì •) ê°€ì¤‘ì¹˜
# - ìˆ  ì—¬ë¶€/ìˆ  ì¤‘ì‹¬ ì‹œ ì£¼ì¢… ë°˜ì˜ ê°•í™”
# - ì†Œê°œíŒ…/ì–´ìƒ‰ + ë¯¼ê°ë„ ë†’ì€ ê²½ìš° "ê³¼í•œ ì˜µì…˜(ì˜¤ë§ˆì¹´ì„¸ ë“±)" ê¸ˆê¸° í•„í„°
# - ì¥ì†Œ íƒ€ì… ê°•ì œ í•„í„°(ì¹´í˜/ìˆ ì§‘/ì‹ì‚¬)
# - í›„ë³´ ë¶€ì¡± ì‹œ ë‹¨ê³„ì  ì™„í™”(search_relax) + ë¬´ì¡°ê±´ 3ê°œ ë³´ì¥
# - ë°©ê¸ˆ ì¶”ì²œ ì œì™¸/ë‹¤ë¥¸ ë° ìš”ì²­ ì²˜ë¦¬
# - ë””ë²„ê·¸ ëª¨ë“œ(ì›ë¬¸/í›„ë³´í’€/íŒŒì‹±ìƒíƒœ)

import json
import re
import math
import requests
import streamlit as st
from openai import OpenAI
from math import radians, sin, cos, sqrt, atan2


# -----------------------------
# App config
# -----------------------------
st.set_page_config(page_title="ê²°ì • ë©”ì´íŠ¸", page_icon="ğŸ½ï¸", layout="wide")
st.title("ğŸ½ï¸ ê²°ì • ë©”ì´íŠ¸ (Decision Mate)")
st.caption("ë§›ì§‘ ì¶”ì²œì´ ì•„ë‹ˆë¼, ì•½ì† ì¥ì†Œ â€˜ê²°ì • í”¼ë¡œâ€™ë¥¼ ì¤„ì´ëŠ” ëŒ€í™”í˜• AI")

# -----------------------------
# Session: API keys (persist)
# -----------------------------
if "openai_key" not in st.session_state:
    st.session_state.openai_key = ""
if "kakao_key" not in st.session_state:
    st.session_state.kakao_key = ""

st.sidebar.header("ğŸ”‘ API ì„¤ì •")
openai_key = st.sidebar.text_input(
    "OpenAI API Key",
    type="password",
    value=st.session_state.openai_key,
)
kakao_key = st.sidebar.text_input(
    "Kakao Local REST API Key",
    type="password",
    value=st.session_state.kakao_key,
)

st.session_state.openai_key = openai_key
st.session_state.kakao_key = kakao_key

debug_mode = st.sidebar.checkbox("ğŸ› ï¸ ë””ë²„ê·¸ ëª¨ë“œ(ì›ë¬¸/í›„ë³´í’€/íŒŒì‹±)", value=False)
client = OpenAI(api_key=openai_key) if openai_key else None


# -----------------------------
# Core state init
# -----------------------------
def init_conditions():
    return {
        "location": None,
        "food_type": None,     # (ëŒ€í™” ê¸°ë°˜) ì˜ˆ: "íŒŒìŠ¤íƒ€", "ê³ ê¸°", "ì´ˆë°¥" ë“± ììœ 
        "purpose": None,
        "people": None,
        "mood": None,
        "constraints": {
            "cannot_eat": [],
            "avoid_recent": [],
            "need_parking": None,
            "avoid_franchise": False,
        },
        "meta": {
            # sidebar
            "context_mode": "ì„ íƒ ì•ˆ í•¨",
            "people_count": 2,
            "budget_tier": "ìƒê´€ì—†ìŒ",
            "place_type": "ìë™",   # ìë™/ì‹ì‚¬/ìˆ /ì¹´í˜
            "food_class": "ìë™",   # ìë™/í•œì‹/ì¤‘ì‹/ì¼ì‹/ì–‘ì‹

            # flow
            "answers": {},          # mode-specific answers
            "fast_mode": False,     # â€œê·¸ëƒ¥ ì¶”ì²œí•´â€ ì¦‰ì‹œ ì¶”ì²œ
            "common": {
                "cannot_eat_done": False,
                "alcohol_level": None,       # ì—†ìŒ/ê°€ë³ê²Œ/ìˆ  ì¤‘ì‹¬
                "alcohol_plan": None,        # í•œ ê³³/1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„/ëª¨ë¥´ê² ìŒ
                "alcohol_type": None,        # ì†Œì£¼/ë§¥ì£¼/ì™€ì¸/ìƒê´€ì—†ìŒ
                "transport": None,           # ì°¨/ëŒ€ì¤‘êµí†µ/ìƒê´€ì—†ìŒ
                "walk_limit_min": 20,        # ë„ë³´ í—ˆìš©(ë¶„)
                "sensitivity_level": None,   # 1~4
                "focus_priority": None,      # ëŒ€í™” ì¤‘ì‹¬/ìŒì‹ ì¤‘ì‹¬/ê· í˜•
                "center_name": None,
                "search_relax": 0,           # í›„ë³´ ë¶€ì¡± ì‹œ ì™„í™” ë‹¨ê³„ 0~3
            },
        }
    }

def init_messages():
    return [{
        "role": "assistant",
        "content": "ì˜¤ì¼€ì´ ğŸ˜\nì˜¤ëŠ˜ ì–´ë””ì„œ ëˆ„êµ¬ë‘ ë­ ë¨¹ì„ì§€ ë‚´ê°€ ë”± ì •í•´ì¤„ê²Œ.\nì¼ë‹¨ **ì–´ëŠ ë™ë„¤/ì—­ ê·¼ì²˜**ì—ì„œ ì°¾ì„ê¹Œ?"
    }]

if "messages" not in st.session_state:
    st.session_state.messages = init_messages()

if "conditions" not in st.session_state:
    st.session_state.conditions = init_conditions()

if "last_picks_ids" not in st.session_state:
    st.session_state.last_picks_ids = []

if "pending_question" not in st.session_state:
    st.session_state.pending_question = None

# debug raw
if "debug_raw_patch" not in st.session_state:
    st.session_state.debug_raw_patch = ""
if "debug_raw_rerank" not in st.session_state:
    st.session_state.debug_raw_rerank = ""
if "debug_candidates" not in st.session_state:
    st.session_state.debug_candidates = []

# location center cache
if "loc_center_cache" not in st.session_state:
    st.session_state.loc_center_cache = {}

# -----------------------------
# Sidebar: scenario filters
# -----------------------------
st.sidebar.markdown("---")
st.sidebar.header("ğŸ§­ ìƒí™© ì„¤ì •")

MODE_OPTIONS = [
    "ì„ íƒ ì•ˆ í•¨",
    "íšŒì‚¬ íšŒì‹",
    "ì¹œêµ¬",
    "ë‹¨ì²´ ëª¨ì„",
    "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…",
    "í˜¼ë°¥",
    "ê°€ì¡±",
]
BUDGET_OPTIONS = ["ìƒê´€ì—†ìŒ", "ê°€ì„±ë¹„", "ë³´í†µ", "ì¡°ê¸ˆ íŠ¹ë³„"]

PLACE_TYPE_OPTIONS = ["ìë™", "ì‹ì‚¬", "ìˆ ", "ì¹´í˜"]
FOOD_CLASS_OPTIONS = ["ìë™", "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹"]

selected_mode = st.sidebar.selectbox("ìƒí™© ëª¨ë“œ", MODE_OPTIONS, index=0)
place_type = st.sidebar.selectbox("ì¥ì†Œ íƒ€ì…", PLACE_TYPE_OPTIONS, index=0)
food_class = st.sidebar.selectbox("ìŒì‹ ë¶„ë¥˜", FOOD_CLASS_OPTIONS, index=0)

people_count = st.sidebar.number_input("ì¸ì›", min_value=1, max_value=30, value=2, step=1)
budget_tier = st.sidebar.radio("ì˜ˆì‚°ëŒ€(1ì¸)", BUDGET_OPTIONS, index=0)

st.sidebar.markdown("---")
avoid_franchise = st.sidebar.checkbox("í”„ëœì°¨ì´ì¦ˆ(ì²´ì¸) ì§€ì–‘", value=False)

st.sidebar.markdown("---")
if st.sidebar.button("ğŸ”„ ìƒˆ ì¶”ì²œ ì‹œì‘(í‚¤ ìœ ì§€)"):
    st.session_state.messages = init_messages()
    st.session_state.pending_question = None
    st.session_state.last_picks_ids = []
    st.session_state.conditions = init_conditions()
    # keys stay in session_state.openai_key/kakao_key
    st.rerun()

# -----------------------------
# Filter change â†’ reset only question flow, keep chat
# -----------------------------
profile = f"{selected_mode}|{place_type}|{food_class}|{int(people_count)}|{budget_tier}|{avoid_franchise}"
prev_profile = st.session_state.get("sidebar_profile")
if prev_profile is None:
    st.session_state.sidebar_profile = profile
else:
    if profile != prev_profile:
        st.session_state.sidebar_profile = profile
        # apply immediately
        st.session_state.pending_question = None
        st.session_state.conditions["meta"]["answers"] = {}
        st.session_state.conditions["meta"]["fast_mode"] = False
        cm = st.session_state.conditions["meta"]["common"]
        # ëª¨ë“œ/íƒ€ì…ì´ ë°”ë€Œë©´ ì˜ë¯¸ ë‹¬ë¼ì§€ëŠ” ì§ˆë¬¸ì€ ë‹¤ì‹œ ë¬»ë„ë¡
        cm["sensitivity_level"] = None
        cm["focus_priority"] = None
        # ìˆ /ì¹´í˜/ì‹ì‚¬ íƒ€ì… ë³€í™”ëŠ” ìˆ  ì§ˆë¬¸ íë¦„ì—ë„ ì˜í–¥ â†’ í•„ìš”í•œ ê²½ìš° ë‹¤ì‹œ ë¬»ë„ë¡
        # (ë‹¨, ì´ë¯¸ ì‚¬ìš©ìê°€ ìˆ ì„ ëª…í™•íˆ ë§í–ˆë‹¤ë©´ ìœ ì§€í•´ë„ ë˜ëŠ”ë°, ì—¬ê¸°ì„  ì•ˆì •ì ìœ¼ë¡œ reset ì•ˆ í•¨)
        # ëŒ€ì‹  place_typeì´ 'ìˆ 'ì´ë©´ alcohol_level ì—†ìœ¼ë©´ ë¹¨ë¦¬ ì±„ìš°ë„ë¡ ì§ˆë¬¸ ëœ¨ê²Œ í•¨

# apply sidebar into conditions
def normalize_conditions(cond: dict):
    if "constraints" not in cond or not isinstance(cond["constraints"], dict):
        cond["constraints"] = {"cannot_eat": [], "avoid_recent": [], "need_parking": None, "avoid_franchise": False}
    c = cond["constraints"]
    c.setdefault("cannot_eat", [])
    c.setdefault("avoid_recent", [])
    c.setdefault("need_parking", None)
    c.setdefault("avoid_franchise", False)
    if not isinstance(c["cannot_eat"], list):
        c["cannot_eat"] = []
    if not isinstance(c["avoid_recent"], list):
        c["avoid_recent"] = []
    if "meta" not in cond or not isinstance(cond["meta"], dict):
        cond["meta"] = {}
    m = cond["meta"]
    m.setdefault("context_mode", "ì„ íƒ ì•ˆ í•¨")
    m.setdefault("people_count", 2)
    m.setdefault("budget_tier", "ìƒê´€ì—†ìŒ")
    m.setdefault("place_type", "ìë™")
    m.setdefault("food_class", "ìë™")
    m.setdefault("answers", {})
    m.setdefault("fast_mode", False)
    m.setdefault("common", {})
    cm = m["common"]
    cm.setdefault("cannot_eat_done", False)
    cm.setdefault("alcohol_level", None)
    cm.setdefault("alcohol_plan", None)
    cm.setdefault("alcohol_type", None)
    cm.setdefault("transport", None)
    cm.setdefault("walk_limit_min", 20)
    cm.setdefault("sensitivity_level", None)
    cm.setdefault("focus_priority", None)
    cm.setdefault("center_name", None)
    cm.setdefault("search_relax", 0)

normalize_conditions(st.session_state.conditions)
st.session_state.conditions["meta"]["context_mode"] = selected_mode
st.session_state.conditions["meta"]["people_count"] = int(people_count)
st.session_state.conditions["meta"]["budget_tier"] = budget_tier
st.session_state.conditions["meta"]["place_type"] = place_type
st.session_state.conditions["meta"]["food_class"] = food_class
st.session_state.conditions["constraints"]["avoid_franchise"] = bool(avoid_franchise)


# -----------------------------
# Text helpers / intents
# -----------------------------
def normalize_text(t: str) -> str:
    if not t:
        return ""
    t = t.strip().lower()
    t = re.sub(r"[`~!@#$%^&*_=+\[\]{};:\"\\|<>]", " ", t)
    t = t.replace("â€¦", " ").replace("Â·", " ").replace("ãƒ»", " ")
    t = re.sub(r"\s+", " ", t).strip()
    return t

def normalize_compact(t: str) -> str:
    return re.sub(r"\s+", "", normalize_text(t))

def contains_any(t_compact: str, keys: list[str]) -> bool:
    return any(k in t_compact for k in keys)

def detect_fast_intent(text: str) -> bool:
    tc = normalize_compact(text)
    keys = ["ê·¸ëƒ¥ì¶”ì²œ", "ê±ì¶”ì²œ", "ë¹¨ë¦¬ì¶”ì²œ", "ë°”ë¡œì¶”ì²œ", "ëê³ ì¶”ì²œ", "ë¬»ì§€ë§ê³ ì¶”ì²œ", "ìŠ¤í‚µ", "skip", "ì•„ë¬´ê±°ë‚˜ì¶”ì²œ", "ëŒ€ì¶©ì¶”ì²œ"]
    return contains_any(tc, keys)

def detect_exclude_last_intent(text: str) -> bool:
    tc = normalize_compact(text)
    keys = ["ë‹¤ë¥¸ë°", "ë‹¤ë¥¸ê³³", "ë°©ê¸ˆì œì™¸", "ì•„ê¹Œì œì™¸", "ê·¸ê±°ë¹¼ê³ ", "ìƒˆë¡œìš´ë°", "ë”´ë°", "ì¤‘ë³µë§ê³ "]
    return contains_any(tc, keys)

def parse_minutes(text: str) -> int | None:
    t = normalize_text(text)
    m = re.search(r"(\d+)\s*(ë¶„|min|mins|minutes)?", t)
    if not m:
        return None
    try:
        v = int(m.group(1))
        if 1 <= v <= 120:
            return v
    except Exception:
        return None
    return None

# -----------------------------
# Natural language parsers (ë¹¡ì„¸ê²Œ)
# -----------------------------
def parse_transport(text: str) -> str | None:
    tc = normalize_compact(text)
    if not tc:
        return None
    car_keys = ["ì°¨", "ìê°€ìš©", "ìš´ì „", "ëª°ê³ ", "ëŒê³ ", "ì£¼ì°¨", "ë°œë ›", "parking", "ëŒ€ë¦¬", "ë ŒíŠ¸", "ì¹´í’€"]
    transit_keys = ["ì§€í•˜ì² ", "ë²„ìŠ¤", "ëŒ€ì¤‘", "ì „ì² ", "ì—­", "ë„ë³´", "ê±¸ì–´", "ëšœë²…", "íƒì‹œ", "í‚¥ë³´ë“œ"]
    any_keys = ["ìƒê´€ì—†", "ì•„ë¬´", "ë¬´ê´€", "ê·¸ëƒ¥"]
    if contains_any(tc, car_keys):
        return "ì°¨"
    if contains_any(tc, transit_keys):
        return "ëŒ€ì¤‘êµí†µ"
    if contains_any(tc, any_keys):
        return "ìƒê´€ì—†ìŒ"
    return None

def parse_alcohol_level(text: str) -> str | None:
    tc = normalize_compact(text)
    if not tc:
        return None
    none_keys = ["ì—†ìŒ", "ì•ˆë§ˆì…”", "ì•ˆë§ˆì‹¤", "ìˆ ì•ˆ", "ê¸ˆì£¼", "ë…¸ì•Œì½œ", "ë…¸ì•Œì½”ì˜¬", "íŒ¨ìŠ¤", "skip", "x", "ã„´ã„´", "ì•ˆí•¨", "ì•ˆë¨¹", "ì•ˆë§ˆ"]
    light_keys = ["ê°€ë³", "í•œì”", "í•œì”ë§Œ", "í•œë‘ì”", "ì ë‹¹íˆ", "ì‚´ì§", "ì¡°ê¸ˆ", "ë¶„ìœ„ê¸°ë§Œ", "1ì”", "2ì”", "í•œë‘"]
    heavy_keys = ["ìˆ ì¤‘ì‹¬", "ë‹¬ë¦¬", "ì·¨í•˜", "ëê¹Œì§€", "ì œëŒ€ë¡œ", "ì§„í•˜ê²Œ", "í­ìŒ", "2ì°¨", "3ì°¨", "ì°¨ìˆ˜", "ìˆ ë¨¹ì", "í•œë°”íƒ•"]
    if contains_any(tc, none_keys):
        return "ì—†ìŒ"
    if contains_any(tc, heavy_keys):
        return "ìˆ  ì¤‘ì‹¬"
    if contains_any(tc, light_keys):
        return "ê°€ë³ê²Œ"
    # ìˆ ì¢…ë¥˜ë§Œ ì–¸ê¸‰í•´ë„ ìµœì†Œ ê°€ë³ê²Œë¡œ
    if contains_any(tc, ["ì†Œì£¼", "ë§¥ì£¼", "ì™€ì¸", "í•˜ì´ë³¼", "ë§‰ê±¸ë¦¬", "ì¹µí…Œì¼"]):
        return "ê°€ë³ê²Œ"
    return None

def parse_alcohol_plan(text: str) -> str | None:
    tc = normalize_compact(text)
    if not tc:
        return None
    one_place = ["í•œê³³", "í•œêµ°ë°", "í•œêµ°ë°ì„œ", "ì˜¬ì¸ì›", "í•œë°©ì—", "ê·¸ìë¦¬ì—ì„œ", "ì˜®ê¸°ê¸°ì‹«", "ì´ë™ì—†"]
    split = ["1ì°¨", "2ì°¨", "3ì°¨", "ë‚˜ëˆ ", "ì˜®ê²¨", "ì´ë™", "ì½”ìŠ¤", "ë°”ê¿”", "ëŒì•„ë‹¤", "2ì°¨ê°ˆ", "2ì°¨ê°€ì"]
    unsure = ["ëª¨ë¥´", "ë¯¸ì •", "ìƒí™©ë´", "ê·¸ë•Œê°€ì„œ", "ì¼ë‹¨ê°€ì„œ"]
    if contains_any(tc, unsure):
        return "ëª¨ë¥´ê² ìŒ"
    if contains_any(tc, split):
        return "1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„"
    if contains_any(tc, one_place):
        return "í•œ ê³³"
    return None

def parse_alcohol_type(text: str) -> str | None:
    tc = normalize_compact(text)
    if not tc:
        return None
    soju = ["ì†Œì£¼", "ì°¸ì´ìŠ¬", "ì²˜ìŒì²˜ëŸ¼", "ì§„ë¡œ", "ìƒˆë¡œ", "ì†Œë§¥", "ë§‰ê±¸ë¦¬", "ì „í†µì£¼"]
    beer = ["ë§¥ì£¼", "ë¹„ì–´", "beer", "í˜¸í”„", "í¬ë˜í”„íŠ¸", "ipa", "ë¼ê±°", "ì—ì¼", "í•˜ì´ë³¼"]
    wine = ["ì™€ì¸", "wine", "ë‚´ì¶”ëŸ´", "ìƒ´í˜ì¸", "ë¹„ìŠ¤íŠ¸ë¡œ"]
    anyv = ["ìƒê´€ì—†", "ì•„ë¬´", "ë¬´ê´€", "ë‹¤ì¢‹", "ë‹¤ê´œì°®"]
    if contains_any(tc, soju):
        return "ì†Œì£¼"
    if contains_any(tc, beer):
        return "ë§¥ì£¼"
    if contains_any(tc, wine):
        return "ì™€ì¸"
    if contains_any(tc, anyv):
        return "ìƒê´€ì—†ìŒ"
    return None

def parse_sensitivity_level(text: str) -> int | None:
    t = normalize_text(text)
    tc = normalize_compact(text)
    m = re.search(r"\b([1-4])\b", t)
    if m:
        return int(m.group(1))
    lvl4 = ["ì¤‘ìš”", "ê²©ì‹", "ê¸°ë…ì¼", "ìƒê²¬ë¡€", "ë¶€ëª¨ë‹˜", "ì ‘ëŒ€", "ëª¨ì‹œëŠ”ìë¦¬", "í”„ëŸ¬í¬ì¦ˆ"]
    lvl3 = ["ì¢€ì‹ ê²½", "ë¶„ìœ„ê¸°", "ì‹¤íŒ¨í•˜ë©´ì•ˆ", "ì†Œê°œíŒ…", "ì¸", "ë°ì´íŠ¸", "ì¡°ìš©í•œë°", "ì˜ˆìœë°"]
    lvl2 = ["ë¬´ë‚œ", "ì ë‹¹íˆ", "ê¹”ë”í•˜ë©´", "ë³´í†µ", "í‰ë²”"]
    lvl1 = ["ì•„ë¬´ìƒê°", "ëŒ€ì¶©", "ë§‰", "ìºì£¼ì–¼", "í¸í•˜ê²Œ", "ê±", "ì•„ë¬´ë°ë‚˜"]
    if contains_any(tc, lvl4):
        return 4
    if contains_any(tc, lvl3):
        return 3
    if contains_any(tc, lvl2):
        return 2
    if contains_any(tc, lvl1):
        return 1
    return None

def parse_focus_priority(text: str) -> str | None:
    tc = normalize_compact(text)
    if not tc:
        return None
    talk = ["ëŒ€í™”", "ìˆ˜ë‹¤", "ì–˜ê¸°", "í† í¬", "ì´ì•¼ê¸°", "ì¡°ìš©", "ë§í•˜ê¸°", "ì°", "ë¶„ìœ„ê¸°ëŒ€í™”"]
    food = ["ìŒì‹", "ë§›", "ë§›ì§‘", "ë©”ë‰´", "ë¨¹ëŠ”", "ì‹ë„ë½", "ë°°ê³ íŒŒ", "ë“ ë“ ", "í‘¸ì§"]
    balance = ["ê· í˜•", "ë°˜ë°˜", "ë‘˜ë‹¤", "ë¹„ìŠ·", "ìƒê´€ì—†", "ì•„ë¬´", "ë¬´ê´€"]
    has_talk = contains_any(tc, talk)
    has_food = contains_any(tc, food)
    if has_talk and has_food:
        return "ê· í˜•"
    if has_talk:
        return "ëŒ€í™” ì¤‘ì‹¬"
    if has_food:
        return "ìŒì‹ ì¤‘ì‹¬"
    if contains_any(tc, balance):
        return "ê· í˜•"
    return None

def parse_dating_stage(text: str) -> str | None:
    t = normalize_text(text)
    tc = normalize_compact(text)
    # ìˆ˜ì¹˜ ê¸°ë°˜: "2ë²ˆì§¸", "3ë²ˆ ë§Œë‚¨"
    if re.search(r"(\d+)\s*(ë²ˆ|ë²ˆì§¸|íšŒ|ì°¨|ë²ˆë§Œë‚¨|ë²ˆì§¸ë§Œë‚¨)", t):
        try:
            n = int(re.search(r"(\d+)", t).group(1))
            if n >= 2:
                return "ìµìˆ™"
        except Exception:
            pass

    first_keys = ["ì²˜ìŒ", "ì²«", "ì²«ë§Œë‚¨", "ì²«ë§Œ", "ì²«ë°ì´íŠ¸", "ì†Œê°œíŒ…", "ì¸ì´ˆ", "ì¸ì´ˆê¸°", "ì´ˆë°˜", "ì´ˆê¸°",
                  "ì•„ì§ì–´ìƒ‰", "ì–´ìƒ‰", "ë‚¯ê°€ë¦¼", "ë‚¯ì„¤", "ì—°ë½ë§Œ", "í†¡ë§Œ", "dmë§Œ", "ì´ˆë©´", "ì˜ëª°ë¼"]
    familiar_keys = ["ìµìˆ™", "í¸", "í¸í•´", "í¸í•œ", "ì¹œí•´", "ê°€ê¹Œì›Œ", "ì—¬ëŸ¬ë²ˆ", "ìì£¼", "ì˜¤ë˜", "ì—°ì¸", "ì»¤í”Œ", "ê¸°ë…ì¼",
                     "ë‘ë²ˆì§¸", "ì„¸ë²ˆì§¸", "në²ˆì§¸"]
    if "ì–´ìƒ‰" in tc and ("ì•ˆ" in tc or "ì•„ë‹ˆ" in tc):
        return "ìµìˆ™"
    if contains_any(tc, familiar_keys):
        return "ìµìˆ™"
    if contains_any(tc, first_keys):
        return "ì²«/ì–´ìƒ‰"
    return None

def parse_friend_style(text: str) -> str | None:
    tc = normalize_compact(text)
    talk = ["ìˆ˜ë‹¤", "ëŒ€í™”", "ì–˜ê¸°", "í† í¬", "ì´ì•¼ê¸°", "ì¡°ìš©", "ë§ë§"]
    food = ["ë¨¹", "ë§›", "ë©”ë‰´", "ë§›ì§‘", "ì‹ë„ë½", "í‘¸ì§", "ë°°ê³ íŒŒ"]
    has_talk = contains_any(tc, talk)
    has_food = contains_any(tc, food)
    if has_talk and not has_food:
        return "ìˆ˜ë‹¤ ì¤‘ì‹¬"
    if has_food and not has_talk:
        return "ë¨¹ëŠ” ì¬ë¯¸ ì¤‘ì‹¬"
    if has_talk and has_food:
        return "ìˆ˜ë‹¤ ì¤‘ì‹¬"
    return None

def parse_work_vibe(text: str) -> str | None:
    tc = normalize_compact(text)
    casual = ["ê°€ë³", "ìºì£¼ì–¼", "í¸í•˜ê²Œ", "ìˆ ìë¦¬", "ì¹œëª©", "ê°€ë³ê²Œí•œì”"]
    formal = ["ì •ëˆ", "ê²©ì‹", "ì ‘ëŒ€", "ì¡°ìš©", "ê¹”ë”", "ìœ—ì‚¬ëŒ", "ì„ì›", "ëŒ€í‘œ", "ìƒì‚¬", "íŒ€ì¥"]
    if contains_any(tc, formal):
        return "ì •ëˆëœ ìë¦¬"
    if contains_any(tc, casual):
        return "ê°€ë³ê²Œ"
    return None

def parse_family_member(text: str) -> str | None:
    tc = normalize_compact(text)
    both = ["ë‘˜ë‹¤", "ì•„ì´ë„", "ì–´ë¥¸ë„", "ë¶€ëª¨ë‹˜ë„", "ì¡°ì¹´ë„", "í• ë¨¸ë‹ˆë„"]
    kids = ["ì•„ì´", "ì•„ê¸°", "ìœ ì•„", "ì´ˆë“±", "ì¡°ì¹´", "í‚¤ì¦ˆ"]
    adults = ["ì–´ë¥¸", "ë¶€ëª¨", "ë¶€ëª¨ë‹˜", "í• ë¨¸ë‹ˆ", "í• ì•„ë²„ì§€", "ì—°ì„¸", "ê³ ë ¹"]
    none = ["ì—†", "ì—†ìŒ", "í•´ë‹¹ì—†", "no"]
    if contains_any(tc, both):
        return "ë‘˜ ë‹¤"
    has_k = contains_any(tc, kids)
    has_a = contains_any(tc, adults)
    if has_k and has_a:
        return "ë‘˜ ë‹¤"
    if has_k:
        return "ì•„ì´"
    if has_a:
        return "ì–´ë¥¸"
    if contains_any(tc, none):
        return "ì—†ìŒ"
    return None


# -----------------------------
# Kakao API (paged + uniq)
# -----------------------------
def kakao_keyword_search(query: str, kakao_rest_key: str, size: int = 15, page: int = 1,
                         x: str | None = None, y: str | None = None,
                         radius: int | None = None, sort: str | None = None):
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {kakao_rest_key}"}
    params = {"query": query, "size": size, "page": page}
    if x and y:
        params["x"] = x
        params["y"] = y
    if radius is not None:
        params["radius"] = radius
    if sort:
        params["sort"] = sort
    res = requests.get(url, headers=headers, params=params, timeout=10)
    res.raise_for_status()
    return res.json()

def kakao_keyword_search_paged(query: str, kakao_rest_key: str, size: int = 15, max_pages: int = 3,
                              x: str | None = None, y: str | None = None,
                              radius: int | None = None, sort: str | None = None):
    all_docs = []
    for page in range(1, max_pages + 1):
        data = kakao_keyword_search(query, kakao_rest_key, size=size, page=page, x=x, y=y, radius=radius, sort=sort)
        docs = data.get("documents", [])
        meta = data.get("meta", {}) or {}
        all_docs.extend(docs)
        if meta.get("is_end") is True:
            break
        # ì•ˆì „: ì‘ë‹µì´ ì§§ì•„ì§€ë©´ ì¤‘ë‹¨
        if len(docs) < size:
            break

    seen, uniq = set(), []
    for d in all_docs:
        pid = d.get("id")
        if not pid or pid in seen:
            continue
        seen.add(pid)
        uniq.append(d)
    return uniq


# -----------------------------
# Geo helpers (distance / walk)
# -----------------------------
def haversine_m(x1, y1, x2, y2):
    lon1, lat1, lon2, lat2 = map(radians, [float(x1), float(y1), float(x2), float(y2)])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return 6371000 * c

def estimate_walk_minutes(distance_m: float, speed_m_per_min: float = 80.0) -> int:
    if distance_m is None or distance_m >= 10**11:
        return 999
    return max(1, int(math.ceil(distance_m / speed_m_per_min)))

def get_location_center(location: str, kakao_rest_key: str):
    loc = (location or "").strip()
    if not loc:
        return None
    cache = st.session_state.loc_center_cache
    if loc in cache:
        return cache[loc]
    candidates = [loc] if "ì—­" in loc else [f"{loc}ì—­", loc]
    for cand in candidates:
        try:
            docs = kakao_keyword_search_paged(cand, kakao_rest_key, size=15, max_pages=1)
            if not docs:
                continue
            d = docs[0]
            center = {"x": d.get("x"), "y": d.get("y"), "name": cand}
            if center["x"] and center["y"]:
                cache[loc] = center
                return center
        except Exception:
            continue
    return None
    # -----------------------------
# Mode-specific questions
# -----------------------------
MODE_REQUIRED_QUESTIONS = {
    "ì¹œêµ¬": [
        {"key": "friend_style", "text": "ì¹œêµ¬ë©´ ì˜¤ëŠ˜ì€ **ìˆ˜ë‹¤/ëŒ€í™”** ìª½ì´ì•¼, ì•„ë‹ˆë©´ **ë©”ë‰´/ë§›** ìª½ì´ì•¼? (ììœ ë¡­ê²Œ ë§í•´ë„ ë¨)", "type": "enum"},
    ],
    "íšŒì‚¬ íšŒì‹": [
        {"key": "work_vibe", "text": "íšŒì‹ ë¶„ìœ„ê¸° ì–´ë–¤ ìª½? (ì˜ˆ: ê°€ë³ê²Œ / ì •ëˆëœ ìë¦¬Â·ì ‘ëŒ€ ëŠë‚Œ)", "type": "enum"},
    ],
    "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…": [
        {"key": "dating_stage", "text": "ê´€ê³„ ë‹¨ê³„ê°€ ì–´ë•Œ? (ì˜ˆ: ì²˜ìŒÂ·ì•„ì§ ì–´ìƒ‰ / ëª‡ ë²ˆ ë§Œë‚¨Â·í¸í•œ í¸)", "type": "enum"},
    ],
    "ê°€ì¡±": [
        {"key": "family_member", "text": "ê°€ì¡± êµ¬ì„±ì— **ì•„ì´/ì–´ë¥¸(ì—°ì„¸)** ìˆì–´? (ì˜ˆ: ì•„ì´ ìˆìŒ/ì–´ë¥¸ ìˆìŒ/ë‘˜ ë‹¤/ì—†ìŒ)", "type": "enum"},
    ],
}

SENSI_TEXT = "ì´ ìë¦¬ëŠ” ì–¼ë§ˆë‚˜ ì‹ ê²½ ì¨ì•¼ í•´? (1 ëŒ€ì¶©~ 4 ì¤‘ìš”í•œ ìë¦¬)"
FOCUS_TEXT = "ì˜¤ëŠ˜ì€ **ëŒ€í™”**ê°€ ë” ì¤‘ìš”í•´? **ìŒì‹**ì´ ë” ì¤‘ìš”í•´? (ëŒ€í™”/ìŒì‹/ê· í˜•)"

def get_next_mode_question(conditions: dict):
    normalize_conditions(conditions)
    mode = conditions["meta"]["context_mode"]
    if not mode or mode == "ì„ íƒ ì•ˆ í•¨" or mode not in MODE_REQUIRED_QUESTIONS:
        return None
    answers = conditions["meta"]["answers"]
    for q in MODE_REQUIRED_QUESTIONS[mode]:
        if answers.get(q["key"]) is None:
            return {"scope": "mode", **q}
    return None

def get_next_common_question(conditions: dict):
    normalize_conditions(conditions)
    cm = conditions["meta"]["common"]

    # 0) location
    if not conditions.get("location"):
        return {"scope": "common", "key": "location", "text": "ì˜¤ì¼€ì´! **ì–´ëŠ ë™ë„¤/ì—­ ê·¼ì²˜**ì—ì„œ ì°¾ì„ê¹Œ? ğŸ“", "type": "free"}

    # 1) cannot_eat (allergy)
    if not cm.get("cannot_eat_done", False):
        return {"scope": "common", "key": "cannot_eat", "text": "ëª» ë¨¹ëŠ” ê±° ìˆì–´? (ì•Œë ˆë¥´ê¸°/ê·¹í˜ í¬í•¨) ì—†ìœ¼ë©´ **ì—†ìŒ** ğŸ™…", "type": "list_or_none"}

    # fast mode: stop asking
    if conditions["meta"].get("fast_mode"):
        return None

    # ìˆ  íƒ€ì… í•„í„°ê°€ ìˆ ì´ë©´: alcohol_level ìš°ì„  ì§ˆë¬¸ ëœ¨ê²Œ
    if cm.get("alcohol_level") is None:
        # place_typeì´ ìˆ ì´ë©´ ìˆ  ì§ˆë¬¸ì´ ë¨¼ì € ëœ¨ëŠ” ê²Œ ìì—°ìŠ¤ëŸ¬ì›€
        return {"scope": "common", "key": "alcohol_level", "text": "ì˜¤ëŠ˜ ìˆ ì€ ì–´ë•Œ? (ì˜ˆ: ì•ˆ ë§ˆì…”/í•œì”/ìˆ  ì¤‘ì‹¬)", "type": "enum_alcohol"}

    if cm.get("transport") is None:
        return {"scope": "common", "key": "transport", "text": "ì´ë™ìˆ˜ë‹¨ì€? (ì˜ˆ: ëšœë²…/ì§€í•˜ì² /íƒì‹œ vs ì°¨/ì£¼ì°¨)", "type": "enum_transport"}

    # ë„ë³´ ì œí•œ: ìì—°ì–´ë¡œ ë°›ë˜, ìƒê´€ì—†ìœ¼ë©´ ë„“ê²Œ
    if cm.get("walk_limit_min") is None:
        return {"scope": "common", "key": "walk_limit_min", "text": "ë„ë³´ëŠ” ìµœëŒ€ ëª‡ ë¶„ê¹Œì§€ ê´œì°®ì•„? (ì˜ˆ: 10ë¶„/15ë¶„/ìƒê´€ì—†ìŒ)", "type": "enum_walk"}

    if cm.get("sensitivity_level") is None:
        return {"scope": "common", "key": "sensitivity_level", "text": SENSI_TEXT, "type": "enum_sensitivity"}

    if cm.get("focus_priority") is None:
        # ì—¬ê¸°ì„œ â€œëŒ€í™” vs ìŒì‹â€ ì§ˆë¬¸ìœ¼ë¡œ ê¸°íš ì˜ë„ ì–´í•„ í¬ì¸íŠ¸ ì‚´ë¦¼
        return {"scope": "common", "key": "focus_priority", "text": FOCUS_TEXT, "type": "enum_focus"}

    # ìˆ  ì¤‘ì‹¬ì´ë©´ í”Œëœ/ì£¼ì¢… ì§ˆë¬¸
    if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_plan") is None:
        return {"scope": "common", "key": "alcohol_plan",
                "text": "ìˆ  ì¤‘ì‹¬ì´ë©´ íë¦„ì€? (ì˜ˆ: í•œ ê³³ì—ì„œ ì­‰ / 1ì°¨2ì°¨ ë‚˜ëˆ” / ëª¨ë¥´ê² ìŒ)", "type": "enum_alcohol_plan"}

    if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_plan") in ("í•œ ê³³", "1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„") and cm.get("alcohol_type") is None:
        return {"scope": "common", "key": "alcohol_type",
                "text": "ì£¼ë¡œ ë­ ë§ˆì‹¤ ìƒê°ì´ì•¼? (ì˜ˆ: ì†Œì£¼/ë§¥ì£¼/ì™€ì¸/ìƒê´€ì—†ìŒ)", "type": "enum_alcohol_type"}

    return None

def get_next_question(conditions: dict):
    q = get_next_common_question(conditions)
    if q:
        return q
    return get_next_mode_question(conditions)


# -----------------------------
# Apply answer (í•µì‹¬)
# - pending ì§ˆë¬¸ì— ë‹µí•˜ë©´ì„œë„, í•œ ë¬¸ì¥ì— ì„ì¸ ë‹¤ë¥¸ ì •ë³´ë“¤ë„ 'ë¹ˆ í•„ë“œë§Œ' ì¶”ê°€ ì±„ì›€
# -----------------------------
def apply_answer(conditions: dict, pending_q: dict, user_text: str) -> bool:
    normalize_conditions(conditions)
    t = user_text or ""
    tc = normalize_compact(t)
    cm = conditions["meta"]["common"]
    answers = conditions["meta"]["answers"]

    # fast intent anywhere
    if detect_fast_intent(t):
        conditions["meta"]["fast_mode"] = True
        return True

    # helper: fill extras if empty
    def fill_extras_if_empty():
        if cm.get("alcohol_level") is None:
            v = parse_alcohol_level(t)
            if v:
                cm["alcohol_level"] = v
                if v == "ì—†ìŒ":
                    cm["alcohol_plan"] = None
                    cm["alcohol_type"] = None
        if cm.get("transport") is None:
            v = parse_transport(t)
            if v:
                cm["transport"] = v
        if cm.get("sensitivity_level") is None:
            v = parse_sensitivity_level(t)
            if v:
                cm["sensitivity_level"] = v
        if cm.get("focus_priority") is None:
            v = parse_focus_priority(t)
            if v:
                cm["focus_priority"] = v
        if cm.get("walk_limit_min") is None:
            v = parse_minutes(t)
            if v:
                cm["walk_limit_min"] = v
        if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬":
            if cm.get("alcohol_plan") is None:
                v = parse_alcohol_plan(t)
                if v:
                    cm["alcohol_plan"] = v
            if cm.get("alcohol_type") is None:
                v = parse_alcohol_type(t)
                if v:
                    cm["alcohol_type"] = v

    key = pending_q.get("key")
    qtype = pending_q.get("type")
    scope = pending_q.get("scope")

    # ----- common: location
    if scope == "common" and key == "location":
        conditions["location"] = t.strip()
        fill_extras_if_empty()
        return True

    # ----- common: cannot_eat
    if scope == "common" and key == "cannot_eat":
        if contains_any(tc, ["ì—†", "ìƒê´€ì—†", "ë‹¤ë¨¹", "ì•„ë¬´ê±°ë‚˜", "no", "ë…¸"]):
            conditions["constraints"]["cannot_eat"] = []
        else:
            parts = re.split(r"[,\n/]+", t)
            cleaned = []
            for p in parts:
                p = p.strip()
                if not p:
                    continue
                p = re.sub(r"(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ë§Œ|ë¹¼ê³ |ë¹¼ì¤˜|ì‹«ì–´|ëª»ë¨¹|ì•Œë ˆë¥´ê¸°)$", "", p).strip()
                if p and p not in cleaned:
                    cleaned.append(p)
            conditions["constraints"]["cannot_eat"] = cleaned[:10]
        cm["cannot_eat_done"] = True
        fill_extras_if_empty()
        return True

    # ----- common: alcohol level
    if scope == "common" and key == "alcohol_level":
        v = parse_alcohol_level(t)
        if not v:        if not v:
            # ìˆ ì¢…ë¥˜ë§Œ ë§í•´ë„ "ê°€ë³ê²Œ"ë¡œ ìµœì†Œ ì±„ì›€
            if contains_any(tc, ["ì†Œì£¼", "ë§¥ì£¼", "ì™€ì¸", "í•˜ì´ë³¼", "ë§‰ê±¸ë¦¬"]):
                v = "ê°€ë³ê²Œ"
        if not v:
            return False
        cm["alcohol_level"] = v
        if v == "ì—†ìŒ":
            cm["alcohol_plan"] = None
            cm["alcohol_type"] = None
        fill_extras_if_empty()
        return True

    # ----- common: transport
    if scope == "common" and key == "transport":
        v = parse_transport(t)
        if not v and contains_any(tc, ["ê±¸ì–´", "ë„ë³´", "ëšœë²…"]):
            v = "ëŒ€ì¤‘êµí†µ"
        if not v:
            return False
        cm["transport"] = v
        # ì°¨ë©´ ì£¼ì°¨ í•„ìš” ì—¬ë¶€ëŠ” â€œê°•ì œ trueâ€ëŠ” í•˜ì§€ ì•Šê³ , ê°€ì¤‘ì¹˜ë§Œ ê°•í™”(í›„ë³´ ì •ë ¬ì—ì„œ ì²˜ë¦¬)
        fill_extras_if_empty()
        return True

    # ----- common: walk limit
    if scope == "common" and key == "walk_limit_min":
        if contains_any(tc, ["ìƒê´€ì—†", "ì•„ë¬´", "ë¬´ê´€"]):
            cm["walk_limit_min"] = 30  # ìƒê´€ì—†ìŒì´ë©´ ë„‰ë„‰íˆ(ë°ëª¨ ì•ˆì •)
            fill_extras_if_empty()
            return True
        v = parse_minutes(t)
        if not v:
            return False
        cm["walk_limit_min"] = max(5, min(60, v))
        fill_extras_if_empty()
        return True

    # ----- common: sensitivity
    if scope == "common" and key == "sensitivity_level":
        v = parse_sensitivity_level(t)
        if not v:
            return False
        cm["sensitivity_level"] = v
        fill_extras_if_empty()
        return True

    # ----- common: focus priority (ëŒ€í™”/ìŒì‹/ê· í˜•)
    if scope == "common" and key == "focus_priority":
        v = parse_focus_priority(t)
        if not v:
            return False
        cm["focus_priority"] = v
        fill_extras_if_empty()
        return True

    # ----- common: alcohol plan
    if scope == "common" and key == "alcohol_plan":
        v = parse_alcohol_plan(t)
        if not v:
            return False
        cm["alcohol_plan"] = v
        fill_extras_if_empty()
        return True

    # ----- common: alcohol type
    if scope == "common" and key == "alcohol_type":
        v = parse_alcohol_type(t)
        if not v:
            if contains_any(tc, ["ìƒê´€ì—†", "ì•„ë¬´", "ë¬´ê´€"]):
                v = "ìƒê´€ì—†ìŒ"
        if not v:
            return False
        cm["alcohol_type"] = v
        fill_extras_if_empty()
        return True

    # ----- mode scope
    if scope == "mode":
        k = key
        picked = None

        if k == "friend_style":
            picked = parse_friend_style(t)
        elif k == "work_vibe":
            picked = parse_work_vibe(t)
        elif k == "dating_stage":
            picked = parse_dating_stage(t)
        elif k == "family_member":
            picked = parse_family_member(t)

        if not picked:
            return False
        answers[k] = picked
        fill_extras_if_empty()
        return True

    # fallback: try fill extras anyway
    fill_extras_if_empty()
    return False


# -----------------------------
# Build query tokens (ê²€ìƒ‰ì–´)
# - ì¥ì†Œ íƒ€ì…/ìŒì‹ ë¶„ë¥˜/ì£¼ì¢…/ì˜ˆì‚°/ëª¨ë“œ/ëŒ€í™”vsìŒì‹ ë°˜ì˜
# -----------------------------
def build_query(conditions: dict) -> str:
    normalize_conditions(conditions)
    m = conditions["meta"]
    cm = m["common"]
    tokens = []

    # location must
    if conditions.get("location"):
        tokens.append(conditions["location"])

    # place type (ê°•ì œ)
    pt = m.get("place_type", "ìë™")
    if pt == "ìˆ ":
        tokens.append("ìˆ ì§‘")
    elif pt == "ì¹´í˜":
        tokens.append("ì¹´í˜")
    elif pt == "ì‹ì‚¬":
        tokens.append("ë§›ì§‘")

    # food class (ê°•ì œ)
    fc = m.get("food_class", "ìë™")
    if fc != "ìë™":
        tokens.append(fc)

    # alcohol signals: ìˆ  ì¤‘ì‹¬/ê°€ë³ê²Œë©´ ìˆ  í‚¤ì›Œë“œ ì„ê¸°(ë‹¨, ptê°€ ì¹´í˜ë©´ ì œì™¸)
    if pt != "ì¹´í˜":
        if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬":
            tokens.append("ìˆ ")
        elif cm.get("alcohol_level") == "ê°€ë³ê²Œ" and pt == "ìë™":
            # ìë™ì¸ë° ìˆ  ê°€ë³ê²Œë©´ í›„ë³´ì— ìˆ ì§‘ë„ ì„ì´ë„ë¡
            tokens.append("ìˆ ì§‘")

    # alcohol type
    at = cm.get("alcohol_type")
    if at and at != "ìƒê´€ì—†ìŒ":
        tokens.append(at)

    # focus: ëŒ€í™” ì¤‘ì‹¬ì´ë©´ ì¡°ìš©/ë¶„ìœ„ê¸°, ìŒì‹ ì¤‘ì‹¬ì´ë©´ ë§›ì§‘/ë©”ë‰´
    focus = cm.get("focus_priority")
    if focus == "ëŒ€í™” ì¤‘ì‹¬":
        tokens.append("ì¡°ìš©í•œ")
    elif focus == "ìŒì‹ ì¤‘ì‹¬":
        tokens.append("ë§›ì§‘")

    # mode hints
    mode = m.get("context_mode")
    if mode == "íšŒì‚¬ íšŒì‹":
        tokens.append("íšŒì‹")
    elif mode == "ë‹¨ì²´ ëª¨ì„":
        tokens.append("ë‹¨ì²´")
    elif mode == "í˜¼ë°¥":
        tokens.append("í˜¼ë°¥")
    elif mode == "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…":
        tokens.append("ë°ì´íŠ¸")

    return " ".join([t for t in tokens if t]).strip()


# -----------------------------
# Candidate pool building (í™•ì¥ + ì™„í™”)
# -----------------------------
def get_candidate_pool(conditions: dict, kakao_key: str):
    """
    ë‹¨ê³„ì  ì™„í™” ë¡œì§:
    relax 0: (ë°˜ê²½ 1200m, max_pages 3)
    relax 1: (ë°˜ê²½ 2000m, max_pages 3)
    relax 2: (ë°˜ê²½ None, max_pages 4)
    relax 3: (query ì•½í™”: location + (place_type/food_class ìµœì†Œë§Œ), max_pages 4)
    """
    normalize_conditions(conditions)
    cm = conditions["meta"]["common"]
    relax = int(cm.get("search_relax", 0))

    location = conditions.get("location")
    center = get_location_center(location, kakao_key)
    if center:
        cm["center_name"] = center.get("name")

    query = build_query(conditions)
    base_pages = 3 if relax <= 1 else 4
    radius = 1200 if relax == 0 else (2000 if relax == 1 else None)

    x = center["x"] if center else None
    y = center["y"] if center else None

    # sort: distance if center exists
    sort = "distance" if center else None

    places = kakao_keyword_search_paged(
        query=query,
        kakao_rest_key=kakao_key,
        size=15,
        max_pages=base_pages,
        x=x,
        y=y,
        radius=radius,
        sort=sort,
    )

    # relax 3: weaken query if still low
    if relax >= 3 and len(places) < 10:
        weak_tokens = [location]
        pt = conditions["meta"].get("place_type", "ìë™")
        fc = conditions["meta"].get("food_class", "ìë™")
        if pt == "ìˆ ":
            weak_tokens.append("ìˆ ì§‘")
        elif pt == "ì¹´í˜":
            weak_tokens.append("ì¹´í˜")
        elif pt == "ì‹ì‚¬":
            weak_tokens.append("ë§›ì§‘")
        if fc != "ìë™":
            weak_tokens.append(fc)
        weak_query = " ".join([t for t in weak_tokens if t]).strip()
        places2 = kakao_keyword_search_paged(
            query=weak_query,
            kakao_rest_key=kakao_key,
            size=15,
            max_pages=4,
            x=x,
            y=y,
            radius=None,
            sort=sort
        )
        # merge uniq
        byid = {p.get("id"): p for p in places if p.get("id")}
        for p in places2:
            pid = p.get("id")
            if pid and pid not in byid:
                byid[pid] = p
        places = list(byid.values())

    return places, center, query


# -----------------------------
# Place type filtering / mild constraints
# -----------------------------
def filter_by_place_type(places: list, place_type: str):
    if place_type == "ì¹´í˜":
        allow = ["ì¹´í˜", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì•„ì´ìŠ¤í¬ë¦¼"]
        out = [p for p in places if any(a in (p.get("category_name") or "") for a in allow)]
        return out if len(out) >= 8 else places
    if place_type == "ìˆ ":
        allow = ["ìˆ ", "ì£¼ì ", "í˜¸í”„", "ì´ìì¹´ì•¼", "ë°”", "í¬ì°¨", "í", "ì™€ì¸", "ë§‰ê±¸ë¦¬", "ì „í†µì£¼"]
        out = [p for p in places if any(a in (p.get("category_name") or "") for a in allow)]
        return out if len(out) >= 8 else places
    if place_type == "ì‹ì‚¬":
        banned = ["ì¹´í˜", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì•„ì´ìŠ¤í¬ë¦¼"]
        out = [p for p in places if not any(b in (p.get("category_name") or "") for b in banned)]
        return out if len(out) >= 8 else places
    return places


def franchise_filter(places: list, avoid: bool):
    if not avoid:
        return places
    # ë§¤ìš° ë³´ìˆ˜ì ìœ¼ë¡œ(ì˜¤íƒ ì¤„ì´ê¸°) ìœ ëª… í”„ì°¨ ì¼ë¶€ë§Œ
    franchise_keywords = ["ìŠ¤íƒ€ë²…ìŠ¤", "íˆ¬ì¸", "ì´ë””ì•¼", "ë©”ê°€ì»¤í”¼", "ë¹½ë‹¤ë°©", "í™ì½©ë°˜ì ", "êµì´Œ", "bhc", "bbq", "ë²„ê±°í‚¹", "ë§¥ë„ë‚ ë“œ", "kfc"]
    out = []
    for p in places:
        name = (p.get("place_name") or "")
        if any(k.lower() in name.lower() for k in franchise_keywords):
            continue
        out.append(p)
    return out if len(out) >= 8 else places


def dating_high_sensitivity_filter(places: list, conditions: dict):
    normalize_conditions(conditions)
    mode = conditions["meta"].get("context_mode")
    cm = conditions["meta"]["common"]
    s = cm.get("sensitivity_level")

    # ì†Œê°œíŒ…/ì¸ + ë¯¼ê°ë„ 3 ì´ìƒì¼ ë•Œë§Œ "ê³¼í•œ ì˜µì…˜" ì œê±°
    if mode != "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…":
        return places
    if not isinstance(s, int) or s < 3:
        return places

    banned_words = ["ì˜¤ë§ˆì¹´ì„¸", "íŒŒì¸ë‹¤ì´ë‹", "ì½”ìŠ¤", "í…Œì´ìŠ¤íŒ…", "í•œìš°ì˜¤ë§ˆì¹´ì„¸", "í”„ë¦¬ë¯¸ì—„ì½”ìŠ¤"]
    out = []
    for p in places:
        name = (p.get("place_name") or "")
        if any(b in name for b in banned_words):
            continue
        out.append(p)
    return out if len(out) >= 8 else places


def alcohol_type_match_score(place: dict, alcohol_type: str | None) -> int:
    if not alcohol_type or alcohol_type == "ìƒê´€ì—†ìŒ":
        return 0
    name = (place.get("place_name") or "").lower()
    cat = (place.get("category_name") or "").lower()
    text = f"{name} {cat}"

    if alcohol_type == "ì†Œì£¼":
        hits = ["í¬ì°¨", "ì£¼ì ", "í•œì‹ì£¼ì ", "ì†Œì£¼", "ë§‰ê±¸ë¦¬", "ì „í†µì£¼", "ì „", "ê³ ê¸°", "ê³±ì°½", "ì‚¼ê²¹"]
        misses = ["í", "ë¸Œë£¨", "ë¸Œë£¨ì–´ë¦¬", "í¬ë˜í”„íŠ¸", "ì™€ì¸", "ì™€ì¸ë°”", "ì¹µí…Œì¼", "bar", "beer", "pub"]
    elif alcohol_type == "ë§¥ì£¼":
        hits = ["í˜¸í”„", "í", "ë¹„ì–´", "ë¸Œë£¨", "ë¸Œë£¨ì–´ë¦¬", "í¬ë˜í”„íŠ¸", "beer", "pub", "ì¹˜í‚¨"]
        misses = ["ì™€ì¸", "ì™€ì¸ë°”", "ì „í†µì£¼", "ë§‰ê±¸ë¦¬", "ì†Œì£¼", "í¬ì°¨", "í•œì‹ì£¼ì "]
    elif alcohol_type == "ì™€ì¸":
        hits = ["ì™€ì¸", "ì™€ì¸ë°”", "ë¹„ìŠ¤íŠ¸ë¡œ", "ë‚´ì¶”ëŸ´", "wine", "bar", "ë¸ŒëŸ°ì¹˜"]
        misses = ["í˜¸í”„", "í", "í¬ì°¨", "ì†Œì£¼", "ë§‰ê±¸ë¦¬"]
    else:
        return 0

    score = 0
    for h in hits:
        if h in text:
            score += 2
    for m in misses:
        if m in text:
            score -= 2
    return score


def prioritize_by_transport_and_alcohol(places: list, center: dict | None, conditions: dict):
    """
    - ì°¨ë©´ parking ì‹œê·¸ë„(ì´ë¦„/ì¹´í…Œê³ ë¦¬) ìˆìœ¼ë©´ ì•½ê°„ ê°€ì 
    - ëŒ€ì¤‘êµí†µì´ë©´ distance ìš°ì„ 
    - ìˆ  ì¤‘ì‹¬ + ì£¼ì¢… ìˆìœ¼ë©´ match scoreë¡œ ì •ë ¬ ë³´ì •
    """
    normalize_conditions(conditions)
    cm = conditions["meta"]["common"]
    transport = cm.get("transport")
    alcohol_type = cm.get("alcohol_type")
    walk_limit = cm.get("walk_limit_min") or 20

    def parking_signal(place: dict) -> int:
        text = f"{place.get('place_name','')} {place.get('category_name','')}".lower()
        score = 0
        if "ì£¼ì°¨" in text or "parking" in text or "ë°œë ›" in text:
            score += 3
        big_like = ["ë°±í™”ì ", "ëª°", "ì•„ìš¸ë ›", "í˜¸í…”", "ì»¨ë²¤ì…˜", "ëŒ€í˜•"]
        if any(k in text for k in big_like):
            score += 1
        return score

    scored = []
    for p in places:
        dist = 10**12
        walk = None
        if center and center.get("x") and center.get("y") and p.get("x") and p.get("y"):
            try:
                dist = haversine_m(center["x"], center["y"], p["x"], p["y"])
                walk = estimate_walk_minutes(dist)
            except Exception:
                dist = 10**12
                walk = None

        # ê¸°ë³¸: dist
        score = dist

        # transport: ì°¨ë©´ parking ê°€ì  / ëŒ€ì¤‘êµí†µì´ë©´ walk limit ë°˜ì˜
        if transport == "ì°¨":
            score -= parking_signal(p) * 140
        elif transport == "ëŒ€ì¤‘êµí†µ":
            if walk is not None and walk > walk_limit:
                score += (walk - walk_limit) * 120  # í˜ë„í‹°
        # alcohol type
        score -= alcohol_type_match_score(p, alcohol_type) * 180

        scored.append((score, dist, p))

    scored.sort(key=lambda x: (x[0], x[1]))
    return [p for _, __, p in scored]


def filter_exclude_last(places: list, exclude_ids: list):
    if not exclude_ids:
        return places
    ex = set(exclude_ids)
    out = [p for p in places if p.get("id") not in ex]
    return out if len(out) >= 6 else places# -----------------------------
# LLM rerank prompt (ê°•ì œ ë°˜ì˜)
# -----------------------------
def rerank_and_format(conditions: dict, places: list):
    if client is None:
        return []

    normalize_conditions(conditions)
    m = conditions["meta"]
    cm = m["common"]

    compact = []
    for p in places[:20]:
        compact.append({
            "id": p.get("id"),
            "name": p.get("place_name"),
            "category": p.get("category_name"),
            "address": p.get("road_address_name") or p.get("address_name"),
            "url": p.get("place_url"),
        })

    rules = {
        "place_type": m.get("place_type"),
        "food_class": m.get("food_class"),
        "budget_tier": m.get("budget_tier"),
        "people_count": m.get("people_count"),
        "mode": m.get("context_mode"),
        "focus": cm.get("focus_priority"),
        "alcohol_level": cm.get("alcohol_level"),
        "alcohol_type": cm.get("alcohol_type"),
        "transport": cm.get("transport"),
        "walk_limit_min": cm.get("walk_limit_min"),
        "sensitivity_level": cm.get("sensitivity_level"),
    }

    prompt = f"""
ë„ˆëŠ” 'ê²°ì • ë©”ì´íŠ¸'ë‹¤.
ì•„ë˜ í›„ë³´ ì¤‘ BEST 3ê³³ë§Œ ê³ ë¥´ê³ , ì™œ ì´ 3ê³³ì¸ì§€ "ì‚¬ìš©ì ì¡°ê±´ ê¸°ë°˜"ìœ¼ë¡œë§Œ ì„¤ëª…í•´ë¼.

ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ì¶œë ¥:
{{
  "picks":[
    {{
      "id":"...",
      "one_line":"ì¹œêµ¬í†¤ í•œì¤„",
      "scene_feel":"ì´ ê³³ì—ì„œ ì•½ì†í•˜ë©´ ì–´ë–¤ ëŠë‚Œì¸ì§€ 1~2ë¬¸ì¥",
      "hashtags":["#...","#...","#...","#..."],
      "matched_conditions":["ì‹¤ì œë¡œ ë°˜ì˜í•œ ì¡°ê±´ë§Œ"],
      "reason":"2~3ë¬¸ì¥. ê³¼ì¥ ê¸ˆì§€. í›„ë³´ ë°ì´í„° ê¸°ë°˜ë§Œ."
    }}
  ]
}}

ì¤‘ìš” ê·œì¹™:
- picksëŠ” ë°˜ë“œì‹œ 3ê°œ.
- place_type/food_classëŠ” ìµœëŒ€í•œ ì§€ì¼œë¼(í›„ë³´ê°€ ì´ë¯¸ í•„í„°ëœ ìƒíƒœì§€ë§Œ, ìµœì¢… ì„ íƒë„ ë§ì¶°ë¼).
- ìˆ  ì¤‘ì‹¬ + ì£¼ì¢… ìˆìœ¼ë©´ ì£¼ì¢…ì— ë§ëŠ” ê³³ ìš°ì„ .
- ì†Œê°œíŒ…/ì–´ìƒ‰ + ë¯¼ê°ë„ ë†’ìŒ(3~4)ì´ë©´ 'ê³¼í•œ ì˜µì…˜(ì˜¤ë§ˆì¹´ì„¸/íŒŒì¸ë‹¤ì´ë‹ ëŠë‚Œ)' ì§€ì–‘.
- í›„ë³´ ë°ì´í„°ì— ì—†ëŠ” ì •ë³´(ì£¼ì°¨ ê°€ëŠ¥ í™•ì •/ì‹¤ë‚´ ì¢Œì„ ê°„ê²©/ê°€ê²©) ìƒìƒ ê¸ˆì§€.
- hashtagsëŠ” ì‚¬ìš©ì ì¡°ê±´ ì¤‘ì‹¬ìœ¼ë¡œ, ë¶€ì¡±í•˜ë©´ categoryë¡œ ë³´ì¶©(4~6ê°œ).
- "ë¬´ì¡°ê±´/ìµœê³ /ì™„ë²½" ê°™ì€ í‘œí˜„ ê¸ˆì§€.

[ì‚¬ìš©ì ì¡°ê±´/ë£°]
{json.dumps(rules, ensure_ascii=False, indent=2)}

[í›„ë³´ ëª©ë¡]
{json.dumps(compact, ensure_ascii=False, indent=2)}
"""

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.25,
        response_format={"type": "json_object"},
    )
    raw = (res.choices[0].message.content or "").strip()
    st.session_state.debug_raw_rerank = raw

    data = safe_json_load(raw) or extract_first_json_object(raw)
    if not isinstance(data, dict):
        return []
    picks = data.get("picks", [])
    if not isinstance(picks, list):
        return []
    return picks[:3]


def safe_json_load(text: str):
    try:
        return json.loads(text)
    except Exception:
        return None

def extract_first_json_object(text: str):
    m = re.search(r"\{.*\}", text, re.DOTALL)
    if not m:
        return None
    return safe_json_load(m.group(0))


def ensure_3_picks(picks: list, candidates: list):
    if not isinstance(picks, list):
        picks = []
    cand_map = {p.get("id"): p for p in candidates if p.get("id")}
    used = set()
    fixed = []

    for pk in picks:
        if not isinstance(pk, dict):
            continue
        pid = pk.get("id")
        if not pid or pid not in cand_map or pid in used:
            continue
        used.add(pid)
        fixed.append(pk)

    for p in candidates:
        pid = p.get("id")
        if not pid or pid in used:
            continue
        used.add(pid)
        fixed.append({
            "id": pid,
            "one_line": "í›„ë³´ ìƒìœ„ì—ì„œ ë¬´ë‚œí•˜ê²Œ ë§ëŠ” ê³³ë„ ê°™ì´ ì±™ê²¨ë’€ì–´ ğŸ˜",
            "scene_feel": "ë§í¬ ëˆŒëŸ¬ì„œ ì‚¬ì§„/ë¦¬ë·°ë§Œ ë¹ ë¥´ê²Œ í™•ì¸í•˜ë©´ ê°ì´ ì˜¬ ê±°ì•¼.",
            "hashtags": ["#ê·¼ì²˜", "#ë¬´ë‚œ", "#í›„ë³´ì¶”ê°€", "#ë°”ë¡œí™•ì¸"],
            "matched_conditions": ["ê·¼ì²˜ ìš°ì„ "],
            "reason": "ì¶”ì²œ ê²°ê³¼ê°€ ë¶€ì¡±í•´ì„œ í›„ë³´ í’€ ìƒìœ„ì—ì„œ ì•ˆì „í•˜ê²Œ ì±„ì› ì–´."
        })
        if len(fixed) >= 3:
            break

    return fixed[:3]


def generate_pre_text(conditions: dict, query: str):
    if client is None:
        return f"ì˜¤ì¼€ì´ã…‹ã…‹ **{query}**ë¡œ ë°”ë¡œ 3ê³³ ë½‘ì•„ë³¼ê²Œ ğŸ”"
    prompt = f"""
ë„ˆëŠ” ì‹ë‹¹ ì˜ ì•„ëŠ” ì¹œêµ¬ë‹¤.
ì¶”ì²œ ì‹œì‘ ë©˜íŠ¸ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ, ì¡°ê±´ ë°˜ì˜í•´ì„œ ë§Œë“¤ì–´ë¼. ì´ëª¨ì§€ 1ê°œ.

ì¡°ê±´:
{json.dumps(conditions, ensure_ascii=False)}

ê²€ìƒ‰ì–´:
{query}
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8
    )
    return (res.choices[0].message.content or "").strip()


# -----------------------------
# Render chat history
# -----------------------------
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("ì˜ˆ: í™ëŒ€ì—­ ê·¼ì²˜, ì†Œê°œíŒ…ì´ë¼ ì¡°ìš©í–ˆìœ¼ë©´ / ì˜ˆ: ê·¸ëƒ¥ ì¶”ì²œí•´")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        if not openai_key or not kakao_key:
            st.warning("ì‚¬ì´ë“œë°”ì— OpenAI í‚¤ë‘ Kakao í‚¤ë¶€í„° ë„£ì–´ì¤˜!")
            st.stop()

        # pending ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ìš°ì„  ì²˜ë¦¬
        normalize_conditions(st.session_state.conditions)

        # â€œë°©ê¸ˆ ì¶”ì²œ ì œì™¸ / ë‹¤ë¥¸ ë°â€ ì˜ë„ ì²˜ë¦¬
        exclude_last = detect_exclude_last_intent(user_input)

        pending = st.session_state.pending_question
        if pending:
            ok = apply_answer(st.session_state.conditions, pending, user_input)
            if not ok:
                # ë‹¤ì‹œ ê°™ì€ ì§ˆë¬¸(ìœ ë„ ë¬¸êµ¬ë§Œ ì‚´ì§)
                msg = f"ì˜¤ì¼€ì´ ê·¼ë° ë‚´ê°€ ì œëŒ€ë¡œ ì¡ê²Œ í•œ ë²ˆë§Œ ë”! ğŸ˜…\n\n**{pending['text']}**"
                st.markdown(msg)
                st.session_state.messages.append({"role": "assistant", "content": msg})
                st.stop()
            st.session_state.pending_question = None
        else:
            # pendingì´ ì—†ëŠ”ë° ì‚¬ìš©ìê°€ ë§ì€ ì •ë³´ë¥¼ ì£¼ë©´ 'ë¹ˆ í•„ë“œ'ë¥¼ ìµœëŒ€í•œ ì±„ìš´ë‹¤
            # locationì´ ì—†ìœ¼ë©´ locationìœ¼ë¡œ ë°›ê¸°
            if not st.session_state.conditions.get("location"):
                st.session_state.conditions["location"] = user_input.strip()
            else:
                # fast mode í¬í•¨í•´ì„œ apply_answerê°€ ë¹„ìŠ·í•œ ë³´ì¡° ì±„ì›€ì„ í•´ì£¼ì§€ë§Œ,
                # ì—¬ê¸°ì„œëŠ” pendingì´ ì—†ìœ¼ë‹ˆ common scope dummyë¡œ ì²˜ë¦¬
                dummy_q = {"scope": "common", "key": "noop", "type": "free"}
                apply_answer(st.session_state.conditions, dummy_q, user_input)

        conditions = st.session_state.conditions
        cm = conditions["meta"]["common"]

        # ë””ë²„ê·¸: í˜„ì¬ ì¡°ê±´
        if debug_mode:
            with st.expander("ğŸ§¾ í˜„ì¬ ëˆ„ì  ì¡°ê±´(JSON)"):
                st.json(conditions)

        # ë‹¤ìŒ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ì§ˆë¬¸
        next_q = get_next_question(conditions)
        if next_q:
            st.session_state.pending_question = next_q
            st.markdown(next_q["text"])
            st.session_state.messages.append({"role": "assistant", "content": next_q["text"]})
            st.stop()

        # -----------------------------
        # ì¶”ì²œ ë‹¨ê³„
        # -----------------------------
        query = build_query(conditions)
        pre = generate_pre_text(conditions, query)
        st.markdown(pre)

        # í›„ë³´ í’€ í™•ë³´ + ë‹¨ê³„ ì™„í™”
        all_places, center, used_query = get_candidate_pool(conditions, kakao_key)

        # í•„í„° ì²´ì¸
        all_places = franchise_filter(all_places, conditions["constraints"].get("avoid_franchise", False))
        all_places = filter_by_place_type(all_places, conditions["meta"].get("place_type", "ìë™"))
        all_places = dating_high_sensitivity_filter(all_places, conditions)
        all_places = prioritize_by_transport_and_alcohol(all_places, center, conditions)

        # ë°©ê¸ˆ ì¶”ì²œ ì œì™¸
        if exclude_last:
            all_places = filter_exclude_last(all_places, st.session_state.last_picks_ids)

        # í›„ë³´ ë„ˆë¬´ ì ìœ¼ë©´ ì™„í™” ë‹¨ê³„ ì˜¬ë¦¬ê³  ì¬ì¡°íšŒ
        relax_guard = 0
        while len(all_places) < 8 and relax_guard < 3:
            cm["search_relax"] = min(3, int(cm.get("search_relax", 0)) + 1)
            all_places, center, used_query = get_candidate_pool(conditions, kakao_key)
            all_places = franchise_filter(all_places, conditions["constraints"].get("avoid_franchise", False))
            all_places = filter_by_place_type(all_places, conditions["meta"].get("place_type", "ìë™"))
            all_places = dating_high_sensitivity_filter(all_places, conditions)
            all_places = prioritize_by_transport_and_alcohol(all_places, center, conditions)
            if exclude_last:
                all_places = filter_exclude_last(all_places, st.session_state.last_picks_ids)
            relax_guard += 1

        if debug_mode:
            with st.expander("ğŸ§ª í›„ë³´ í’€(ìƒìœ„ 25)"):
                st.write(f"query: {used_query}")
                st.write(f"candidates: {len(all_places)} / relax: {cm.get('search_relax')}")
                for p in all_places[:25]:
                    st.write(f"- {p.get('place_name')} | {p.get('category_name')} | {p.get('road_address_name') or p.get('address_name')}")

        if not all_places:
            msg = "í—‰â€¦ ì´ ì¡°ê±´ìœ¼ë¡œëŠ” ë”± ë§ëŠ” ë°ê°€ ì˜ ì•ˆ ì¡íˆë„¤ ğŸ¥²\nì§€ì—­ì„ ì¡°ê¸ˆë§Œ ë„“í˜€ë³¼ê¹Œ?"
            st.markdown(msg)
            st.session_state.messages.append({"role": "assistant", "content": msg})
            st.stop()

        # rerank
        picks = rerank_and_format(conditions, all_places)

        if debug_mode:
            with st.expander("ğŸ¤– (ë””ë²„ê·¸) rerank LLM ì›ë¬¸"):
                st.code(st.session_state.debug_raw_rerank)

        # 3ê°œ ë³´ì¥
        picks = ensure_3_picks(picks, all_places)

        # ë Œë”ë§
        kakao_map = {p.get("id"): p for p in all_places if p.get("id")}

        st.markdown("---")
        st.subheader("ğŸ½ï¸ ë”± 3ê³³ë§Œ ê³¨ëì–´")

        cols = st.columns(3)
        current_pick_ids = []

        for i, pick in enumerate(picks[:3]):
            pid = pick.get("id")
            place = kakao_map.get(pid)
            if not pid or not place:
                continue
            current_pick_ids.append(pid)

            with cols[i]:
                name = place.get("place_name")
                addr = place.get("road_address_name") or place.get("address_name")
                url = place.get("place_url")
                category = place.get("category_name")

                st.markdown(f"### {i+1}. {name}")
                st.caption(category or "")
                st.write(f"ğŸ“ {addr}")

                st.markdown(f"**{pick.get('# -----------------------------
# LLM rerank prompt (ê°•ì œ ë°˜ì˜)
# -----------------------------
def rerank_and_format(conditions: dict, places: list):
    if client is None:
        return []

    normalize_conditions(conditions)
    m = conditions["meta"]
    cm = m["common"]

    compact = []
    for p in places[:20]:
        compact.append({
            "id": p.get("id"),
            "name": p.get("place_name"),
            "category": p.get("category_name"),
            "address": p.get("road_address_name") or p.get("address_name"),
            "url": p.get("place_url"),
        })

    rules = {
        "place_type": m.get("place_type"),
        "food_class": m.get("food_class"),
        "budget_tier": m.get("budget_tier"),
        "people_count": m.get("people_count"),
        "mode": m.get("context_mode"),
        "focus": cm.get("focus_priority"),
        "alcohol_level": cm.get("alcohol_level"),
        "alcohol_type": cm.get("alcohol_type"),
        "transport": cm.get("transport"),
        "walk_limit_min": cm.get("walk_limit_min"),
        "sensitivity_level": cm.get("sensitivity_level"),
    }

    prompt = f"""
ë„ˆëŠ” 'ê²°ì • ë©”ì´íŠ¸'ë‹¤.
ì•„ë˜ í›„ë³´ ì¤‘ BEST 3ê³³ë§Œ ê³ ë¥´ê³ , ì™œ ì´ 3ê³³ì¸ì§€ "ì‚¬ìš©ì ì¡°ê±´ ê¸°ë°˜"ìœ¼ë¡œë§Œ ì„¤ëª…í•´ë¼.

ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ì¶œë ¥:
{{
  "picks":[
    {{
      "id":"...",
      "one_line":"ì¹œêµ¬í†¤ í•œì¤„",
      "scene_feel":"ì´ ê³³ì—ì„œ ì•½ì†í•˜ë©´ ì–´ë–¤ ëŠë‚Œì¸ì§€ 1~2ë¬¸ì¥",
      "hashtags":["#...","#...","#...","#..."],
      "matched_conditions":["ì‹¤ì œë¡œ ë°˜ì˜í•œ ì¡°ê±´ë§Œ"],
      "reason":"2~3ë¬¸ì¥. ê³¼ì¥ ê¸ˆì§€. í›„ë³´ ë°ì´í„° ê¸°ë°˜ë§Œ."
    }}
  ]
}}

ì¤‘ìš” ê·œì¹™:
- picksëŠ” ë°˜ë“œì‹œ 3ê°œ.
- place_type/food_classëŠ” ìµœëŒ€í•œ ì§€ì¼œë¼(í›„ë³´ê°€ ì´ë¯¸ í•„í„°ëœ ìƒíƒœì§€ë§Œ, ìµœì¢… ì„ íƒë„ ë§ì¶°ë¼).
- ìˆ  ì¤‘ì‹¬ + ì£¼ì¢… ìˆìœ¼ë©´ ì£¼ì¢…ì— ë§ëŠ” ê³³ ìš°ì„ .
- ì†Œê°œíŒ…/ì–´ìƒ‰ + ë¯¼ê°ë„ ë†’ìŒ(3~4)ì´ë©´ 'ê³¼í•œ ì˜µì…˜(ì˜¤ë§ˆì¹´ì„¸/íŒŒì¸ë‹¤ì´ë‹ ëŠë‚Œ)' ì§€ì–‘.
- í›„ë³´ ë°ì´í„°ì— ì—†ëŠ” ì •ë³´(ì£¼ì°¨ ê°€ëŠ¥ í™•ì •/ì‹¤ë‚´ ì¢Œì„ ê°„ê²©/ê°€ê²©) ìƒìƒ ê¸ˆì§€.
- hashtagsëŠ” ì‚¬ìš©ì ì¡°ê±´ ì¤‘ì‹¬ìœ¼ë¡œ, ë¶€ì¡±í•˜ë©´ categoryë¡œ ë³´ì¶©(4~6ê°œ).
- "ë¬´ì¡°ê±´/ìµœê³ /ì™„ë²½" ê°™ì€ í‘œí˜„ ê¸ˆì§€.

[ì‚¬ìš©ì ì¡°ê±´/ë£°]
{json.dumps(rules, ensure_ascii=False, indent=2)}

[í›„ë³´ ëª©ë¡]
{json.dumps(compact, ensure_ascii=False, indent=2)}
"""

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.25,
        response_format={"type": "json_object"},
    )
    raw = (res.choices[0].message.content or "").strip()
    st.session_state.debug_raw_rerank = raw

    data = safe_json_load(raw) or extract_first_json_object(raw)
    if not isinstance(data, dict):
        return []
    picks = data.get("picks", [])
    if not isinstance(picks, list):
        return []
    return picks[:3]


def safe_json_load(text: str):
    try:
        return json.loads(text)
    except Exception:
        return None

def extract_first_json_object(text: str):
    m = re.search(r"\{.*\}", text, re.DOTALL)
    if not m:
        return None
    return safe_json_load(m.group(0))


def ensure_3_picks(picks: list, candidates: list):
    if not isinstance(picks, list):
        picks = []
    cand_map = {p.get("id"): p for p in candidates if p.get("id")}
    used = set()
    fixed = []

    for pk in picks:
        if not isinstance(pk, dict):
            continue
        pid = pk.get("id")
        if not pid or pid not in cand_map or pid in used:
            continue
        used.add(pid)
        fixed.append(pk)

    for p in candidates:
        pid = p.get("id")
        if not pid or pid in used:
            continue
        used.add(pid)
        fixed.append({
            "id": pid,
            "one_line": "í›„ë³´ ìƒìœ„ì—ì„œ ë¬´ë‚œí•˜ê²Œ ë§ëŠ” ê³³ë„ ê°™ì´ ì±™ê²¨ë’€ì–´ ğŸ˜",
            "scene_feel": "ë§í¬ ëˆŒëŸ¬ì„œ ì‚¬ì§„/ë¦¬ë·°ë§Œ ë¹ ë¥´ê²Œ í™•ì¸í•˜ë©´ ê°ì´ ì˜¬ ê±°ì•¼.",
            "hashtags": ["#ê·¼ì²˜", "#ë¬´ë‚œ", "#í›„ë³´ì¶”ê°€", "#ë°”ë¡œí™•ì¸"],
            "matched_conditions": ["ê·¼ì²˜ ìš°ì„ "],
            "reason": "ì¶”ì²œ ê²°ê³¼ê°€ ë¶€ì¡±í•´ì„œ í›„ë³´ í’€ ìƒìœ„ì—ì„œ ì•ˆì „í•˜ê²Œ ì±„ì› ì–´."
        })
        if len(fixed) >= 3:
            break

    return fixed[:3]


def generate_pre_text(conditions: dict, query: str):
    if client is None:
        return f"ì˜¤ì¼€ì´ã…‹ã…‹ **{query}**ë¡œ ë°”ë¡œ 3ê³³ ë½‘ì•„ë³¼ê²Œ ğŸ”"
    prompt = f"""
ë„ˆëŠ” ì‹ë‹¹ ì˜ ì•„ëŠ” ì¹œêµ¬ë‹¤.
ì¶”ì²œ ì‹œì‘ ë©˜íŠ¸ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ, ì¡°ê±´ ë°˜ì˜í•´ì„œ ë§Œë“¤ì–´ë¼. ì´ëª¨ì§€ 1ê°œ.

ì¡°ê±´:
{json.dumps(conditions, ensure_ascii=False)}

ê²€ìƒ‰ì–´:
{query}
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8
    )
    return (res.choices[0].message.content or "").strip()


# -----------------------------
# Render chat history
# -----------------------------
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("ì˜ˆ: í™ëŒ€ì—­ ê·¼ì²˜, ì†Œê°œíŒ…ì´ë¼ ì¡°ìš©í–ˆìœ¼ë©´ / ì˜ˆ: ê·¸ëƒ¥ ì¶”ì²œí•´")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        if not openai_key or not kakao_key:
            st.warning("ì‚¬ì´ë“œë°”ì— OpenAI í‚¤ë‘ Kakao í‚¤ë¶€í„° ë„£ì–´ì¤˜!")
            st.stop()

        # pending ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ìš°ì„  ì²˜ë¦¬
        normalize_conditions(st.session_state.conditions)

        # â€œë°©ê¸ˆ ì¶”ì²œ ì œì™¸ / ë‹¤ë¥¸ ë°â€ ì˜ë„ ì²˜ë¦¬
        exclude_last = detect_exclude_last_intent(user_input)

        pending = st.session_state.pending_question
        if pending:
            ok = apply_answer(st.session_state.conditions, pending, user_input)
            if not ok:
                # ë‹¤ì‹œ ê°™ì€ ì§ˆë¬¸(ìœ ë„ ë¬¸êµ¬ë§Œ ì‚´ì§)
                msg = f"ì˜¤ì¼€ì´ ê·¼ë° ë‚´ê°€ ì œëŒ€ë¡œ ì¡ê²Œ í•œ ë²ˆë§Œ ë”! ğŸ˜…\n\n**{pending['text']}**"
                st.markdown(msg)
                st.session_state.messages.append({"role": "assistant", "content": msg})
                st.stop()
            st.session_state.pending_question = None
        else:
            # pendingì´ ì—†ëŠ”ë° ì‚¬ìš©ìê°€ ë§ì€ ì •ë³´ë¥¼ ì£¼ë©´ 'ë¹ˆ í•„ë“œ'ë¥¼ ìµœëŒ€í•œ ì±„ìš´ë‹¤
            # locationì´ ì—†ìœ¼ë©´ locationìœ¼ë¡œ ë°›ê¸°
            if not st.session_state.conditions.get("location"):
                st.session_state.conditions["location"] = user_input.strip()
            else:
                # fast mode í¬í•¨í•´ì„œ apply_answerê°€ ë¹„ìŠ·í•œ ë³´ì¡° ì±„ì›€ì„ í•´ì£¼ì§€ë§Œ,
                # ì—¬ê¸°ì„œëŠ” pendingì´ ì—†ìœ¼ë‹ˆ common scope dummyë¡œ ì²˜ë¦¬
                dummy_q = {"scope": "common", "key": "noop", "type": "free"}
                apply_answer(st.session_state.conditions, dummy_q, user_input)

        conditions = st.session_state.conditions
        cm = conditions["meta"]["common"]

        # ë””ë²„ê·¸: í˜„ì¬ ì¡°ê±´
        if debug_mode:
            with st.expander("ğŸ§¾ í˜„ì¬ ëˆ„ì  ì¡°ê±´(JSON)"):
                st.json(conditions)

        # ë‹¤ìŒ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ì§ˆë¬¸
        next_q = get_next_question(conditions)
        if next_q:
            st.session_state.pending_question = next_q
            st.markdown(next_q["text"])
            st.session_state.messages.append({"role": "assistant", "content": next_q["text"]})
            st.stop()

        # -----------------------------
        # ì¶”ì²œ ë‹¨ê³„
        # -----------------------------
        query = build_query(conditions)
        pre = generate_pre_text(conditions, query)
        st.markdown(pre)

        # í›„ë³´ í’€ í™•ë³´ + ë‹¨ê³„ ì™„í™”
        all_places, center, used_query = get_candidate_pool(conditions, kakao_key)

        # í•„í„° ì²´ì¸
        all_places = franchise_filter(all_places, conditions["constraints"].get("avoid_franchise", False))
        all_places = filter_by_place_type(all_places, conditions["meta"].get("place_type", "ìë™"))
        all_places = dating_high_sensitivity_filter(all_places, conditions)
        all_places = prioritize_by_transport_and_alcohol(all_places, center, conditions)

        # ë°©ê¸ˆ ì¶”ì²œ ì œì™¸
        if exclude_last:
            all_places = filter_exclude_last(all_places, st.session_state.last_picks_ids)

        # í›„ë³´ ë„ˆë¬´ ì ìœ¼ë©´ ì™„í™” ë‹¨ê³„ ì˜¬ë¦¬ê³  ì¬ì¡°íšŒ
        relax_guard = 0
        while len(all_places) < 8 and relax_guard < 3:
            cm["search_relax"] = min(3, int(cm.get("search_relax", 0)) + 1)
            all_places, center, used_query = get_candidate_pool(conditions, kakao_key)
            all_places = franchise_filter(all_places, conditions["constraints"].get("avoid_franchise", False))
            all_places = filter_by_place_type(all_places, conditions["meta"].get("place_type", "ìë™"))
            all_places = dating_high_sensitivity_filter(all_places, conditions)
            all_places = prioritize_by_transport_and_alcohol(all_places, center, conditions)
            if exclude_last:
                all_places = filter_exclude_last(all_places, st.session_state.last_picks_ids)
            relax_guard += 1

        if debug_mode:
            with st.expander("ğŸ§ª í›„ë³´ í’€(ìƒìœ„ 25)"):
                st.write(f"query: {used_query}")
                st.write(f"candidates: {len(all_places)} / relax: {cm.get('search_relax')}")
                for p in all_places[:25]:
                    st.write(f"- {p.get('place_name')} | {p.get('category_name')} | {p.get('road_address_name') or p.get('address_name')}")

        if not all_places:
            msg = "í—‰â€¦ ì´ ì¡°ê±´ìœ¼ë¡œëŠ” ë”± ë§ëŠ” ë°ê°€ ì˜ ì•ˆ ì¡íˆë„¤ ğŸ¥²\nì§€ì—­ì„ ì¡°ê¸ˆë§Œ ë„“í˜€ë³¼ê¹Œ?"
            st.markdown(msg)
            st.session_state.messages.append({"role": "assistant", "content": msg})
            st.stop()

        # rerank
        picks = rerank_and_format(conditions, all_places)

        if debug_mode:
            with st.expander("ğŸ¤– (ë””ë²„ê·¸) rerank LLM ì›ë¬¸"):
                st.code(st.session_state.debug_raw_rerank)

        # 3ê°œ ë³´ì¥
        picks = ensure_3_picks(picks, all_places)

        # ë Œë”ë§
        kakao_map = {p.get("id"): p for p in all_places if p.get("id")}

        st.markdown("---")
        st.subheader("ğŸ½ï¸ ë”± 3ê³³ë§Œ ê³¨ëì–´")

        cols = st.columns(3)
        current_pick_ids = []

        for i, pick in enumerate(picks[:3]):
            pid = pick.get("id")
            place = kakao_map.get(pid)
            if not pid or not place:
                continue
            current_pick_ids.append(pid)

            with cols[i]:
                name = place.get("place_name")
                addr = place.get("road_address_name") or place.get("address_name")
                url = place.get("place_url")
                category = place.get("category_name")

                st.markdown(f"### {i+1}. {name}")
                st.caption(category or "")
                st.write(f"ğŸ“ {addr}")

                st.markdown(f"**{pick.get('                st.markdown(f"**{pick.get('one_line','')}**")

                scene = pick.get("scene_feel")
                if scene:
                    st.markdown(f"_ì´ ìë¦¬ ëŠë‚Œ_: {scene}")

                matched = pick.get("matched_conditions", [])
                if matched:
                    st.markdown("**ë°˜ì˜í•œ ì¡°ê±´**")
                    st.markdown(" Â· ".join([f"`{m}`" for m in matched]))

                tags = pick.get("hashtags", [])
                if tags:
                    st.markdown(" ".join(tags))

                st.markdown("**ì™œ ì—¬ê¸°ëƒë©´â€¦**")
                st.write(pick.get("reason", ""))

                # ë„ë³´ ì‹œê°„ í‘œì‹œ (ìˆìœ¼ë©´)
                if center and center.get("x") and center.get("y") and place.get("x") and place.get("y"):
                    try:
                        dist = haversine_m(center["x"], center["y"], place["x"], place["y"])
                        walk_min = estimate_walk_minutes(dist)
                        st.caption(f"ğŸš¶ ì˜ˆìƒ ë„ë³´ ì•½ {walk_min}ë¶„")
                    except Exception:
                        pass

                if url:
                    st.link_button("ì¹´ì¹´ì˜¤ë§µì—ì„œ ë³´ê¸°", url)

        # ë‹¤ìŒ ì¶”ì²œì—ì„œ ì œì™¸ ì €ì¥
        st.session_state.last_picks_ids = current_pick_ids

        final = "ë! ğŸ˜\nì…‹ ì¤‘ì— í•˜ë‚˜ ê³ ë¥´ê±°ë‚˜, 'ë‹¤ë¥¸ ë°', 'ë” ì¡°ìš©í•œ ë°', 'ì™„ì „ ë‹¤ë¥¸ ë¶„ìœ„ê¸°' ì´ëŸ° ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì¼œë„ ë¼."
        st.session_state.messages.append({"role": "assistant", "content": final})
        st.markdown(final)
