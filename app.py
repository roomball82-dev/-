# decision_mate_v7_final.py
# âœ… ì‹¬ì‚¬ìš© ì•ˆì • ë°ëª¨ ìš°ì„  + ë…¼ì˜í•œ ì™„ì„±ë„(í•µì‹¬ ê¸°ëŠ¥) ì „ë¶€ ë°˜ì˜í•œ í†µì§œ ìµœì¢…ë³¸
# - Sidebar: ìƒí™© ëª¨ë“œ / ì¥ì†Œ íƒ€ì… / ìŒì‹ ë¶„ë¥˜ / ì¸ì› / ì˜ˆì‚° / í”„ì°¨ ì§€ì–‘ / ë””ë²„ê·¸
# - Chat: ì§ˆë¬¸ íŠ¸ë¦¬ + ìì—°ì–´ ì…ë ¥ ëŒ€ë¶€ë¶„ ì²˜ë¦¬ + fast mode(ê·¸ëƒ¥ ì¶”ì²œí•´) + ë‹¤ë¥¸ ë°(exclude last)
# - Candidate: ì¹´ì¹´ì˜¤ ë¡œì»¬ API í˜ì´ì§€ í™•ì¥ + ì™„í™” ë‹¨ê³„ + ê±°ë¦¬/ë„ë³´ ì¶”ì • + íƒ€ì… ê°•ì œ í•„í„° + ë¯¼ê°ë„ ê¸ˆê¸°(ì†Œê°œíŒ… ê³¼í•œ ì˜µì…˜ ì§€ì–‘)
# - Alcohol: ìˆ  ì—¬ë¶€ + ìˆ  ì¤‘ì‹¬ì´ë©´ ì£¼ì¢…/1ì°¨2ì°¨ ë°˜ì˜(ê°€ì¤‘ì¹˜/í”„ë¡¬í”„íŠ¸)
# - Output: ë¬´ì¡°ê±´ 3ê°œ ë³´ì¥ + ì¶”ì²œ ì´ìœ /ì¥ë©´/í•´ì‹œíƒœê·¸ + ì¹´ì¹´ì˜¤ë§µ ë§í¬

import json
import re
import math
import requests
import streamlit as st
from openai import OpenAI
from math import radians, sin, cos, sqrt, atan2


# -----------------------------
# Streamlit page
# -----------------------------
st.set_page_config(page_title="ê²°ì • ë©”ì´íŠ¸", page_icon="ğŸ½ï¸", layout="wide")
st.title("ğŸ½ï¸ ê²°ì • ë©”ì´íŠ¸ (Decision Mate)")
st.caption("ë§›ì§‘ ì¶”ì²œì´ ì•„ë‹ˆë¼, ì•½ì† ì¥ì†Œ 'ê²°ì • í”¼ë¡œ'ë¥¼ ì¤„ì´ëŠ” ëŒ€í™”í˜• ì¶”ì²œ")


# -----------------------------
# Session init
# -----------------------------
def init_messages():
    return [{
        "role": "assistant",
        "content": "ì˜¤ì¼€ì´ ğŸ˜\nì˜¤ëŠ˜ ì–´ë””ì„œ ëˆ„êµ¬ë‘ ë­ ë¨¹ì„ì§€ ë‚´ê°€ ë”± ì •í•´ì¤„ê²Œ.\nì¼ë‹¨ **ì–´ëŠ ë™ë„¤/ì—­ ê·¼ì²˜**ì—ì„œ ì°¾ì„ê¹Œ?"
    }]


def init_conditions():
    return {
        "location": None,
        "constraints": {
            "cannot_eat": [],
            "avoid_recent": [],
            "avoid_franchise": False,
            "need_parking": None,  # í™•ì • ì •ë³´ëŠ” ì•„ë‹ˆê³  ê°€ì¤‘ì¹˜ íŒíŠ¸ë¡œë§Œ ì‚¬ìš©
        },
        "meta": {
            # sidebar
            "mode": "ì„ íƒ ì•ˆ í•¨",
            "place_type": "ìë™",   # ìë™/ì‹ì‚¬/ìˆ /ì¹´í˜
            "food_class": "ìë™",   # ìë™/í•œì‹/ì¤‘ì‹/ì¼ì‹/ì–‘ì‹
            "people_count": 2,
            "budget_tier": "ìƒê´€ì—†ìŒ",

            # chat flow
            "fast_mode": False,     # "ê·¸ëƒ¥ ì¶”ì²œí•´"ë©´ ì§ˆë¬¸ ì¤‘ë‹¨
            "pending_question": None,
            "answers": {},          # mode-specific answers

            # common extracted
            "common": {
                "cannot_eat_done": False,
                "alcohol_level": None,   # ì—†ìŒ/ê°€ë³ê²Œ/ìˆ  ì¤‘ì‹¬
                "alcohol_plan": None,    # í•œ ê³³/1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„/ëª¨ë¥´ê² ìŒ
                "alcohol_type": None,    # ì†Œì£¼/ë§¥ì£¼/ì™€ì¸/ìƒê´€ì—†ìŒ
                "transport": None,       # ì°¨/ëŒ€ì¤‘êµí†µ/ìƒê´€ì—†ìŒ
                "walk_limit_min": 20,    # ê¸°ë³¸ 20
                "sensitivity": None,     # 1~4
                "focus": None,           # ëŒ€í™” ì¤‘ì‹¬/ìŒì‹ ì¤‘ì‹¬/ê· í˜•
                "search_relax": 0,       # í›„ë³´ ë¶€ì¡±ì‹œ ì™„í™” ë‹¨ê³„
                "center": None,          # {x,y,name}
            }
        }
    }


if "messages" not in st.session_state:
    st.session_state.messages = init_messages()

if "conditions" not in st.session_state:
    st.session_state.conditions = init_conditions()

if "last_picks_ids" not in st.session_state:
    st.session_state.last_picks_ids = []

if "openai_key" not in st.session_state:
    st.session_state.openai_key = ""
if "kakao_key" not in st.session_state:
    st.session_state.kakao_key = ""

if "debug_raw_rerank" not in st.session_state:
    st.session_state.debug_raw_rerank = ""

if "loc_center_cache" not in st.session_state:
    st.session_state.loc_center_cache = {}


# -----------------------------
# Sidebar
# -----------------------------
st.sidebar.header("ğŸ”‘ API ì„¤ì •")
openai_key = st.sidebar.text_input("OpenAI API Key", type="password", value=st.session_state.openai_key)
kakao_key = st.sidebar.text_input("Kakao Local REST API Key", type="password", value=st.session_state.kakao_key)
st.session_state.openai_key = openai_key
st.session_state.kakao_key = kakao_key

debug_mode = st.sidebar.checkbox("ğŸ› ï¸ ë””ë²„ê·¸ ëª¨ë“œ", value=False)

st.sidebar.markdown("---")
st.sidebar.header("ğŸ§­ ìƒí™© ì„¤ì •")

MODE_OPTIONS = [
    "ì„ íƒ ì•ˆ í•¨",
    "íšŒì‚¬ íšŒì‹",
    "ì¹œêµ¬",
    "ë‹¨ì²´ ëª¨ì„",
    "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…",
    "í˜¼ë°¥",
    "ê°€ì¡±",
]
PLACE_TYPE_OPTIONS = ["ìë™", "ì‹ì‚¬", "ìˆ ", "ì¹´í˜"]
FOOD_CLASS_OPTIONS = ["ìë™", "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹"]
BUDGET_OPTIONS = ["ìƒê´€ì—†ìŒ", "ê°€ì„±ë¹„", "ë³´í†µ", "ì¡°ê¸ˆ íŠ¹ë³„"]

mode = st.sidebar.selectbox("ìƒí™© ëª¨ë“œ", MODE_OPTIONS, index=0)
place_type = st.sidebar.selectbox("ì¥ì†Œ íƒ€ì…", PLACE_TYPE_OPTIONS, index=0)
food_class = st.sidebar.selectbox("ìŒì‹ ë¶„ë¥˜", FOOD_CLASS_OPTIONS, index=0)
people_count = st.sidebar.number_input("ì¸ì›", min_value=1, max_value=30, value=2, step=1)
budget_tier = st.sidebar.radio("ì˜ˆì‚°ëŒ€(1ì¸)", BUDGET_OPTIONS, index=0)
avoid_franchise = st.sidebar.checkbox("í”„ëœì°¨ì´ì¦ˆ(ì²´ì¸) ì§€ì–‘", value=False)

st.sidebar.markdown("---")
if st.sidebar.button("ğŸ”„ ìƒˆ ì¶”ì²œ ì‹œì‘(í‚¤ ìœ ì§€)"):
    # í‚¤ëŠ” sessionì— ë‚¨ê¸°ê³  ëŒ€í™”/ì¡°ê±´ë§Œ ë¦¬ì…‹
    st.session_state.messages = init_messages()
    st.session_state.conditions = init_conditions()
    st.session_state.last_picks_ids = []
    st.rerun()


# apply sidebar to conditions (í•„ìˆ˜)
cond = st.session_state.conditions
cond["meta"]["mode"] = mode
cond["meta"]["place_type"] = place_type
cond["meta"]["food_class"] = food_class
cond["meta"]["people_count"] = int(people_count)
cond["meta"]["budget_tier"] = budget_tier
cond["constraints"]["avoid_franchise"] = bool(avoid_franchise)


# -----------------------------
# OpenAI client
# -----------------------------
client = OpenAI(api_key=openai_key) if openai_key else None


# -----------------------------
# Helpers: text normalize + intent detect
# -----------------------------
def nt(text: str) -> str:
    if not text:
        return ""
    t = text.strip().lower()
    t = re.sub(r"[`~!@#$%^&*_=+\[\]{};:\"\\|<>]", " ", t)
    t = t.replace("â€¦", " ").replace("Â·", " ").replace("ãƒ»", " ")
    t = re.sub(r"\s+", " ", t).strip()
    return t


def nc(text: str) -> str:
    return re.sub(r"\s+", "", nt(text))


def contains_any(tc: str, keys: list[str]) -> bool:
    return any(k in tc for k in keys)


def detect_fast(text: str) -> bool:
    tc = nc(text)
    keys = ["ê·¸ëƒ¥ì¶”ì²œ", "ê±ì¶”ì²œ", "ë°”ë¡œì¶”ì²œ", "ëê³ ì¶”ì²œ", "ë¬»ì§€ë§ê³ ", "ìŠ¤í‚µ", "skip", "ëŒ€ì¶©ì¶”ì²œ", "ì•„ë¬´ê±°ë‚˜ì¶”ì²œ"]
    return contains_any(tc, keys)


def detect_exclude_last(text: str) -> bool:
    tc = nc(text)
    keys = ["ë‹¤ë¥¸ë°", "ë‹¤ë¥¸ê³³", "ë”´ë°", "ë°©ê¸ˆì œì™¸", "ì•„ê¹Œì œì™¸", "ê·¸ê±°ë¹¼ê³ ", "ì¤‘ë³µë§ê³ ", "ìƒˆë¡œìš´ë°"]
    return contains_any(tc, keys)


# -----------------------------
# Natural language parsers (í•µì‹¬)
# -----------------------------
def parse_minutes(text: str) -> int | None:
    t = nt(text)
    m = re.search(r"(\d+)\s*(ë¶„|min|mins|minutes)?", t)
    if not m:
        return None
    try:
        v = int(m.group(1))
        if 1 <= v <= 120:
            return v
    except Exception:
        return None
    return None


def parse_transport(text: str) -> str | None:
    tc = nc(text)
    if not tc:
        return None
    car = ["ì°¨", "ìê°€ìš©", "ìš´ì „", "ëª°ê³ ", "ëŒê³ ", "ì£¼ì°¨", "ë°œë ›", "parking", "ëŒ€ë¦¬", "ë ŒíŠ¸"]
    transit = ["ì§€í•˜ì² ", "ë²„ìŠ¤", "ëŒ€ì¤‘", "ì „ì² ", "ì—­", "ëšœë²…", "ë„ë³´", "ê±¸ì–´", "íƒì‹œ", "í‚¥ë³´ë“œ"]
    anyv = ["ìƒê´€ì—†", "ì•„ë¬´", "ë¬´ê´€"]
    if contains_any(tc, car):
        return "ì°¨"
    if contains_any(tc, transit):
        return "ëŒ€ì¤‘êµí†µ"
    if contains_any(tc, anyv):
        return "ìƒê´€ì—†ìŒ"
    return None


def parse_alcohol_level(text: str) -> str | None:
    tc = nc(text)
    if not tc:
        return None
    none_keys = ["ì—†ìŒ", "ì•ˆë§ˆì…”", "ì•ˆë§ˆì‹¤", "ìˆ ì•ˆ", "ê¸ˆì£¼", "ë…¸ì•Œ", "íŒ¨ìŠ¤", "ì•ˆí•¨", "ì•ˆë¨¹", "ì•ˆë§ˆ", "no"]
    light_keys = ["ê°€ë³", "í•œì”", "í•œë‘ì”", "ì ë‹¹", "ì‚´ì§", "ì¡°ê¸ˆ", "ë¶„ìœ„ê¸°ë§Œ", "1ì”", "2ì”"]
    heavy_keys = ["ìˆ ì¤‘ì‹¬", "ë‹¬ë¦¬", "ëê¹Œì§€", "ì œëŒ€ë¡œ", "ì§„í•˜ê²Œ", "í­ìŒ", "2ì°¨", "3ì°¨", "ì°¨ìˆ˜"]
    if contains_any(tc, none_keys):
        return "ì—†ìŒ"
    if contains_any(tc, heavy_keys):
        return "ìˆ  ì¤‘ì‹¬"
    if contains_any(tc, light_keys):
        return "ê°€ë³ê²Œ"
    if contains_any(tc, ["ì†Œì£¼", "ë§¥ì£¼", "ì™€ì¸", "í•˜ì´ë³¼", "ë§‰ê±¸ë¦¬", "ì¹µí…Œì¼"]):
        return "ê°€ë³ê²Œ"
    return None


def parse_alcohol_plan(text: str) -> str | None:
    tc = nc(text)
    one_place = ["í•œê³³", "í•œêµ°ë°", "í•œìë¦¬", "ì˜®ê¸°ê¸°ì‹«", "ì´ë™ì—†", "ê·¸ìë¦¬ì—ì„œ", "í•œë°©ì—"]
    split = ["1ì°¨", "2ì°¨", "3ì°¨", "ë‚˜ëˆ ", "ì˜®ê²¨", "ì´ë™", "ì½”ìŠ¤", "ëŒì•„ë‹¤", "2ì°¨ê°€ì"]
    unsure = ["ëª¨ë¥´", "ë¯¸ì •", "ìƒí™©ë´", "ê·¸ë•Œê°€ì„œ"]
    if contains_any(tc, unsure):
        return "ëª¨ë¥´ê² ìŒ"
    if contains_any(tc, split):
        return "1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„"
    if contains_any(tc, one_place):
        return "í•œ ê³³"
    return None


def parse_alcohol_type(text: str) -> str | None:
    tc = nc(text)
    soju = ["ì†Œì£¼", "ì°¸ì´ìŠ¬", "ì²˜ìŒì²˜ëŸ¼", "ì§„ë¡œ", "ìƒˆë¡œ", "ì†Œë§¥", "ë§‰ê±¸ë¦¬", "ì „í†µì£¼"]
    beer = ["ë§¥ì£¼", "ë¹„ì–´", "beer", "í˜¸í”„", "í¬ë˜í”„íŠ¸", "ipa", "ë¼ê±°", "ì—ì¼", "í•˜ì´ë³¼", "í"]
    wine = ["ì™€ì¸", "wine", "ë‚´ì¶”ëŸ´", "ìƒ´í˜ì¸", "ë¹„ìŠ¤íŠ¸ë¡œ", "ì™€ì¸ë°”"]
    anyv = ["ìƒê´€ì—†", "ì•„ë¬´", "ë¬´ê´€", "ë‹¤ì¢‹", "ë‹¤ê´œì°®"]
    if contains_any(tc, soju):
        return "ì†Œì£¼"
    if contains_any(tc, beer):
        return "ë§¥ì£¼"
    if contains_any(tc, wine):
        return "ì™€ì¸"
    if contains_any(tc, anyv):
        return "ìƒê´€ì—†ìŒ"
    return None


def parse_sensitivity(text: str) -> int | None:
    t = nt(text)
    tc = nc(text)
    m = re.search(r"\b([1-4])\b", t)
    if m:
        return int(m.group(1))
    lvl4 = ["ì¤‘ìš”", "ê²©ì‹", "ê¸°ë…ì¼", "ìƒê²¬ë¡€", "ì ‘ëŒ€", "ë¶€ëª¨ë‹˜", "í”„ëŸ¬í¬ì¦ˆ"]
    lvl3 = ["ì†Œê°œíŒ…", "ì¸", "ë°ì´íŠ¸", "ì‹ ê²½", "ë¶„ìœ„ê¸°", "ì¡°ìš©í•œë°", "ì‹¤íŒ¨í•˜ë©´ì•ˆ"]
    lvl2 = ["ë¬´ë‚œ", "ì ë‹¹", "ë³´í†µ", "ê¹”ë”í•˜ë©´"]
    lvl1 = ["ëŒ€ì¶©", "ì•„ë¬´", "ë§‰", "ìºì£¼ì–¼", "í¸í•˜ê²Œ"]
    if contains_any(tc, lvl4):
        return 4
    if contains_any(tc, lvl3):
        return 3
    if contains_any(tc, lvl2):
        return 2
    if contains_any(tc, lvl1):
        return 1
    return None


def parse_focus(text: str) -> str | None:
    tc = nc(text)
    talk = ["ëŒ€í™”", "ìˆ˜ë‹¤", "ì–˜ê¸°", "ì´ì•¼ê¸°", "í† í¬", "ì¡°ìš©", "ë§í•˜ê¸°"]
    food = ["ìŒì‹", "ë§›", "ë§›ì§‘", "ë©”ë‰´", "ì‹ë„ë½", "ë“ ë“ ", "í‘¸ì§", "ë°°ê³ íŒŒ"]
    balance = ["ê· í˜•", "ë°˜ë°˜", "ë‘˜ë‹¤", "ìƒê´€ì—†", "ë¬´ê´€", "ì•„ë¬´"]
    has_talk = contains_any(tc, talk)
    has_food = contains_any(tc, food)
    if has_talk and has_food:
        return "ê· í˜•"
    if has_talk:
        return "ëŒ€í™” ì¤‘ì‹¬"
    if has_food:
        return "ìŒì‹ ì¤‘ì‹¬"
    if contains_any(tc, balance):
        return "ê· í˜•"
    return None


def parse_mode_answer(mode_key: str, text: str) -> str | None:
    tc = nc(text)

    if mode_key == "friend_style":
        if contains_any(tc, ["ìˆ˜ë‹¤", "ëŒ€í™”", "ì–˜ê¸°", "ì¡°ìš©", "í† í¬"]):
            return "ìˆ˜ë‹¤ ì¤‘ì‹¬"
        if contains_any(tc, ["ë§›", "ë©”ë‰´", "ë¨¹", "ì‹ë„ë½", "í‘¸ì§"]):
            return "ë¨¹ëŠ” ì¬ë¯¸ ì¤‘ì‹¬"
        return None

    if mode_key == "work_vibe":
        if contains_any(tc, ["ì ‘ëŒ€", "ê²©ì‹", "ì •ëˆ", "ì¡°ìš©", "ìœ—ì‚¬ëŒ", "ì„ì›", "ëŒ€í‘œ"]):
            return "ì •ëˆëœ ìë¦¬"
        if contains_any(tc, ["ê°€ë³", "ìºì£¼ì–¼", "í¸í•˜ê²Œ", "ì¹œëª©", "ìˆ ìë¦¬"]):
            return "ê°€ë³ê²Œ"
        return None

    if mode_key == "dating_stage":
        if contains_any(tc, ["ì²˜ìŒ", "ì²«", "ì†Œê°œíŒ…", "ì–´ìƒ‰", "ì´ˆë°˜", "ì´ˆê¸°", "ì´ˆë©´"]):
            return "ì²«/ì–´ìƒ‰"
        if contains_any(tc, ["ìµìˆ™", "í¸", "ì»¤í”Œ", "ì—°ì¸", "ì—¬ëŸ¬ë²ˆ", "ìì£¼", "ê¸°ë…ì¼"]):
            return "ìµìˆ™"
        # "2ë²ˆì§¸" ê°™ì€ í‘œí˜„
        if re.search(r"(\d+)\s*(ë²ˆ|ë²ˆì§¸|íšŒ|ì°¨)", nt(text)):
            try:
                n = int(re.search(r"(\d+)", nt(text)).group(1))
                if n >= 2:
                    return "ìµìˆ™"
            except Exception:
                pass
        return None

    if mode_key == "family_member":
        if contains_any(tc, ["ë‘˜ë‹¤", "ì•„ì´ë„", "ì–´ë¥¸ë„", "ë¶€ëª¨ë‹˜ë„"]):
            return "ë‘˜ ë‹¤"
        has_kid = contains_any(tc, ["ì•„ì´", "ì•„ê¸°", "ìœ ì•„", "ì¡°ì¹´", "í‚¤ì¦ˆ"])
        has_adult = contains_any(tc, ["ë¶€ëª¨", "ë¶€ëª¨ë‹˜", "í• ë¨¸ë‹ˆ", "í• ì•„ë²„ì§€", "ì—°ì„¸", "ì–´ë¥¸"])
        if has_kid and has_adult:
            return "ë‘˜ ë‹¤"
        if has_kid:
            return "ì•„ì´"
        if has_adult:
            return "ì–´ë¥¸"
        if contains_any(tc, ["ì—†", "ì—†ìŒ", "í•´ë‹¹ì—†"]):
            return "ì—†ìŒ"
        return None

    return None


# -----------------------------
# Kakao API (paged + uniq)
# -----------------------------
def kakao_keyword_search(query: str, rest_key: str, size: int = 15, page: int = 1,
                         x: str | None = None, y: str | None = None,
                         radius: int | None = None, sort: str | None = None):
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {rest_key}"}
    params = {"query": query, "size": size, "page": page}
    if x and y:
        params["x"] = x
        params["y"] = y
    if radius is not None:
        params["radius"] = radius
    if sort:
        params["sort"] = sort

    res = requests.get(url, headers=headers, params=params, timeout=10)
    res.raise_for_status()
    return res.json()


def kakao_search_paged(query: str, rest_key: str, max_pages: int = 3, size: int = 15,
                      x: str | None = None, y: str | None = None,
                      radius: int | None = None, sort: str | None = None):
    all_docs = []
    for page in range(1, max_pages + 1):
        data = kakao_keyword_search(query, rest_key, size=size, page=page, x=x, y=y, radius=radius, sort=sort)
        docs = data.get("documents", []) or []
        meta = data.get("meta", {}) or {}
        all_docs.extend(docs)
        if meta.get("is_end") is True:
            break
        if len(docs) < size:
            break

    uniq = {}
    for d in all_docs:
        pid = d.get("id")
        if pid:
            uniq[pid] = d
    return list(uniq.values())


# -----------------------------
# Geo helpers
# -----------------------------
def haversine_m(x1, y1, x2, y2):
    lon1, lat1, lon2, lat2 = map(radians, [float(x1), float(y1), float(x2), float(y2)])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return 6371000 * c


def estimate_walk_minutes(distance_m: float, speed_m_per_min: float = 80.0) -> int:
    return max(1, int(math.ceil(distance_m / speed_m_per_min)))


def get_location_center(location: str, rest_key: str):
    loc = (location or "").strip()
    if not loc:
        return None

    cache = st.session_state.loc_center_cache
    if loc in cache:
        return cache[loc]

    candidates = [loc] if "ì—­" in loc else [f"{loc}ì—­", loc]
    for cand in candidates:
        try:
            docs = kakao_search_paged(cand, rest_key, max_pages=1, size=15)
            if not docs:
                continue
            d = docs[0]
            x, y = d.get("x"), d.get("y")
            if x and y:
                center = {"x": x, "y": y, "name": cand}
                cache[loc] = center
                return center
        except Exception:
            continue
    return None


# -----------------------------
# Query + Candidate pipeline
# -----------------------------
def build_query(conditions: dict) -> str:
    m = conditions["meta"]
    cm = m["common"]
    tokens = []

    if conditions.get("location"):
        tokens.append(conditions["location"])

    # place type
    pt = m.get("place_type", "ìë™")
    if pt == "ìˆ ":
        tokens.append("ìˆ ì§‘")
    elif pt == "ì¹´í˜":
        tokens.append("ì¹´í˜")
    elif pt == "ì‹ì‚¬":
        tokens.append("ë§›ì§‘")

    # food class
    fc = m.get("food_class", "ìë™")
    if fc != "ìë™":
        tokens.append(fc)

    # alcohol hint
    if pt != "ì¹´í˜":
        if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬":
            tokens.append("ìˆ ")
        elif cm.get("alcohol_level") == "ê°€ë³ê²Œ" and pt == "ìë™":
            tokens.append("ìˆ ì§‘")

    # alcohol type
    at = cm.get("alcohol_type")
    if at and at != "ìƒê´€ì—†ìŒ":
        tokens.append(at)

    # focus hint
    focus = cm.get("focus")
    if focus == "ëŒ€í™” ì¤‘ì‹¬":
        tokens.append("ì¡°ìš©í•œ")
    elif focus == "ìŒì‹ ì¤‘ì‹¬":
        tokens.append("ë§›ì§‘")

    # mode hints (ê°€ë³ê²Œë§Œ)
    mode = m.get("mode")
    if mode == "íšŒì‚¬ íšŒì‹":
        tokens.append("íšŒì‹")
    elif mode == "ë‹¨ì²´ ëª¨ì„":
        tokens.append("ë‹¨ì²´")
    elif mode == "í˜¼ë°¥":
        tokens.append("í˜¼ë°¥")
    elif mode == "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…":
        tokens.append("ë°ì´íŠ¸")

    return " ".join([t for t in tokens if t]).strip()


def get_candidate_pool(conditions: dict, rest_key: str):
    """
    ì™„í™” ë‹¨ê³„:
    relax 0: radius=1200, pages=2
    relax 1: radius=2000, pages=3
    relax 2: radius=None, pages=4
    relax 3: query ì•½í™”(location + place_type + food_class), radius=None, pages=4
    """
    m = conditions["meta"]
    cm = m["common"]
    relax = int(cm.get("search_relax", 0))

    center = get_location_center(conditions.get("location"), rest_key)
    cm["center"] = center

    pages = 2 if relax == 0 else (3 if relax == 1 else 4)
    radius = 1200 if relax == 0 else (2000 if relax == 1 else None)

    x = center["x"] if center else None
    y = center["y"] if center else None
    sort = "distance" if center else None

    query = build_query(conditions)
    places = kakao_search_paged(query, rest_key, max_pages=pages, size=15, x=x, y=y, radius=radius, sort=sort)

    if relax >= 3 and len(places) < 10:
        weak = [conditions.get("location", "")]
        pt = m.get("place_type", "ìë™")
        fc = m.get("food_class", "ìë™")
        if pt == "ìˆ ":
            weak.append("ìˆ ì§‘")
        elif pt == "ì¹´í˜":
            weak.append("ì¹´í˜")
        elif pt == "ì‹ì‚¬":
            weak.append("ë§›ì§‘")
        if fc != "ìë™":
            weak.append(fc)
        weak_query = " ".join([t for t in weak if t]).strip()
        places2 = kakao_search_paged(weak_query, rest_key, max_pages=4, size=15, x=x, y=y, radius=None, sort=sort)
        byid = {p.get("id"): p for p in places if p.get("id")}
        for p in places2:
            pid = p.get("id")
            if pid and pid not in byid:
                byid[pid] = p
        places = list(byid.values())

    return places, center, query


def filter_by_place_type(places: list, place_type: str):
    if place_type == "ì¹´í˜":
        allow = ["ì¹´í˜", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì•„ì´ìŠ¤í¬ë¦¼"]
        out = [p for p in places if any(a in (p.get("category_name") or "") for a in allow)]
        return out if len(out) >= 8 else places
    if place_type == "ìˆ ":
        allow = ["ìˆ ", "ì£¼ì ", "í˜¸í”„", "ì´ìì¹´ì•¼", "ë°”", "í¬ì°¨", "í", "ì™€ì¸", "ë§‰ê±¸ë¦¬", "ì „í†µì£¼"]
        out = [p for p in places if any(a in (p.get("category_name") or "") for a in allow)]
        return out if len(out) >= 8 else places
    if place_type == "ì‹ì‚¬":
        banned = ["ì¹´í˜", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì•„ì´ìŠ¤í¬ë¦¼"]
        out = [p for p in places if not any(b in (p.get("category_name") or "") for b in banned)]
        return out if len(out) >= 8 else places
    return places


def franchise_filter(places: list, avoid: bool):
    if not avoid:
        return places
    franchise_keywords = ["ìŠ¤íƒ€ë²…ìŠ¤", "íˆ¬ì¸", "ì´ë””ì•¼", "ë©”ê°€ì»¤í”¼", "ë¹½ë‹¤ë°©", "í™ì½©ë°˜ì ", "êµì´Œ", "bhc", "bbq", "ë²„ê±°í‚¹", "ë§¥ë„ë‚ ë“œ", "kfc"]
    out = []
    for p in places:
        name = (p.get("place_name") or "")
        if any(k.lower() in name.lower() for k in franchise_keywords):
            continue
        out.append(p)
    return out if len(out) >= 8 else places


def dating_high_sensitivity_filter(places: list, conditions: dict):
    m = conditions["meta"]
    cm = m["common"]
    if m.get("mode") != "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…":
        return places
    s = cm.get("sensitivity")
    if not isinstance(s, int) or s < 3:
        return places
    banned_words = ["ì˜¤ë§ˆì¹´ì„¸", "íŒŒì¸ë‹¤ì´ë‹", "í…Œì´ìŠ¤íŒ…", "ì½”ìŠ¤"]
    out = []
    for p in places:
        name = (p.get("place_name") or "")
        if any(b in name for b in banned_words):
            continue
        out.append(p)
    return out if len(out) >= 8 else places


def alcohol_type_match_score(place: dict, alcohol_type: str | None) -> int:
    if not alcohol_type or alcohol_type == "ìƒê´€ì—†ìŒ":
        return 0
    name = (place.get("place_name") or "").lower()
    cat = (place.get("category_name") or "").lower()
    text = f"{name} {cat}"

    if alcohol_type == "ì†Œì£¼":
        hits = ["í¬ì°¨", "ì£¼ì ", "í•œì‹ì£¼ì ", "ì†Œì£¼", "ë§‰ê±¸ë¦¬", "ì „í†µì£¼", "ê³±ì°½", "ì‚¼ê²¹", "ê³ ê¸°"]
        misses = ["í", "ë¸Œë£¨", "ë¸Œë£¨ì–´ë¦¬", "í¬ë˜í”„íŠ¸", "ì™€ì¸", "ì™€ì¸ë°”", "ì¹µí…Œì¼", "beer", "pub"]
    elif alcohol_type == "ë§¥ì£¼":
        hits = ["í˜¸í”„", "í", "ë¹„ì–´", "ë¸Œë£¨", "ë¸Œë£¨ì–´ë¦¬", "í¬ë˜í”„íŠ¸", "beer", "pub", "ì¹˜í‚¨", "í•˜ì´ë³¼"]
        misses = ["ì™€ì¸", "ì™€ì¸ë°”", "ì „í†µì£¼", "ë§‰ê±¸ë¦¬", "í¬ì°¨", "í•œì‹ì£¼ì ", "ì†Œì£¼"]
    elif alcohol_type == "ì™€ì¸":
        hits = ["ì™€ì¸", "ì™€ì¸ë°”", "ë¹„ìŠ¤íŠ¸ë¡œ", "ë‚´ì¶”ëŸ´", "wine", "bar", "ë¸ŒëŸ°ì¹˜"]
        misses = ["í˜¸í”„", "í", "í¬ì°¨", "ì†Œì£¼", "ë§‰ê±¸ë¦¬"]
    else:
        return 0

    score = 0
    for h in hits:
        if h in text:
            score += 2
    for m in misses:
        if m in text:
            score -= 2
    return score


def prioritize_places(places: list, center: dict | None, conditions: dict):
    m = conditions["meta"]
    cm = m["common"]
    transport = cm.get("transport")
    walk_limit = cm.get("walk_limit_min") or 20
    alcohol_type = cm.get("alcohol_type")

    def parking_signal(p: dict) -> int:
        text = f"{p.get('place_name','')} {p.get('category_name','')}".lower()
        score = 0
        if "ì£¼ì°¨" in text or "parking" in text or "ë°œë ›" in text:
            score += 3
        return score

    scored = []
    for p in places:
        dist = 10**12
        walk = None
        if center and center.get("x") and center.get("y") and p.get("x") and p.get("y"):
            try:
                dist = haversine_m(center["x"], center["y"], p["x"], p["y"])
                walk = estimate_walk_minutes(dist)
            except Exception:
                dist = 10**12
                walk = None

        score = dist

        if transport == "ì°¨":
            score -= parking_signal(p) * 140
        elif transport == "ëŒ€ì¤‘êµí†µ":
            if walk is not None and walk > walk_limit:
                score += (walk - walk_limit) * 120

        score -= alcohol_type_match_score(p, alcohol_type) * 180

        scored.append((score, dist, p))

    scored.sort(key=lambda x: (x[0], x[1]))
    return [p for _, __, p in scored]


def filter_exclude_last(places: list, exclude_ids: list):
    if not exclude_ids:
        return places
    ex = set(exclude_ids)
    out = [p for p in places if p.get("id") not in ex]
    return out if len(out) >= 6 else places


# -----------------------------
# Questions (ê³µí†µ + ëª¨ë“œë³„)
# -----------------------------
MODE_QUESTIONS = {
    "ì¹œêµ¬": [{"key": "friend_style", "text": "ì¹œêµ¬ë©´ ì˜¤ëŠ˜ì€ **ìˆ˜ë‹¤/ëŒ€í™”** ìª½ì´ì•¼, ì•„ë‹ˆë©´ **ë©”ë‰´/ë§›** ìª½ì´ì•¼? (ììœ ë¡­ê²Œ ë§í•´ë„ ë¨)"}],
    "íšŒì‚¬ íšŒì‹": [{"key": "work_vibe", "text": "íšŒì‹ ë¶„ìœ„ê¸° ì–´ë–¤ ìª½? (ì˜ˆ: ê°€ë³ê²Œ / ì •ëˆëœ ìë¦¬Â·ì ‘ëŒ€ ëŠë‚Œ)"}],
    "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…": [{"key": "dating_stage", "text": "ê´€ê³„ ë‹¨ê³„ê°€ ì–´ë•Œ? (ì˜ˆ: ì²˜ìŒÂ·ì•„ì§ ì–´ìƒ‰ / ëª‡ ë²ˆ ë§Œë‚¨Â·í¸í•œ í¸)"}],
    "ê°€ì¡±": [{"key": "family_member", "text": "ê°€ì¡± êµ¬ì„±ì— **ì•„ì´/ì–´ë¥¸(ì—°ì„¸)** ìˆì–´? (ì•„ì´ ìˆìŒ/ì–´ë¥¸ ìˆìŒ/ë‘˜ ë‹¤/ì—†ìŒ)"}],
}

def next_common_question(conditions: dict):
    cm = conditions["meta"]["common"]
    m = conditions["meta"]

    if not conditions.get("location"):
        return {"scope": "common", "key": "location", "text": "ì˜¤ì¼€ì´! **ì–´ëŠ ë™ë„¤/ì—­ ê·¼ì²˜**ì—ì„œ ì°¾ì„ê¹Œ? ğŸ“"}

    if not cm.get("cannot_eat_done"):
        return {"scope": "common", "key": "cannot_eat", "text": "ëª» ë¨¹ëŠ” ê±° ìˆì–´? (ì•Œë ˆë¥´ê¸°/ê·¹í˜ í¬í•¨) ì—†ìœ¼ë©´ **ì—†ìŒ** ğŸ™…"}

    # fast modeë©´ ë” ì•ˆ ë¬»ê³  ë°”ë¡œ ì¶”ì²œ
    if m.get("fast_mode"):
        return None

    if cm.get("alcohol_level") is None:
        # place_typeì´ ì¹´í˜ë©´ ìˆ  ì§ˆë¬¸ì„ ë’¤ë¡œ ë¯¸ë£¨ë˜, ì‚¬ìš©ìê°€ ìˆ ì„ ë§í•˜ë©´ ìë™ ë°˜ì˜ë¨
        if m.get("place_type") == "ì¹´í˜":
            cm["alcohol_level"] = "ì—†ìŒ"
        else:
            return {"scope": "common", "key": "alcohol_level", "text": "ì˜¤ëŠ˜ ìˆ ì€ ì–´ë•Œ? (ì•ˆ ë§ˆì…”/í•œì”/ìˆ  ì¤‘ì‹¬)"}

    if cm.get("transport") is None:
        return {"scope": "common", "key": "transport", "text": "ì´ë™ìˆ˜ë‹¨ì€? (ëšœë²…/ì§€í•˜ì² /íƒì‹œ vs ì°¨/ì£¼ì°¨)"}

    if cm.get("walk_limit_min") is None:
        return {"scope": "common", "key": "walk_limit_min", "text": "ë„ë³´ëŠ” ìµœëŒ€ ëª‡ ë¶„ê¹Œì§€ ê´œì°®ì•„? (10ë¶„/15ë¶„/ìƒê´€ì—†ìŒ)"}

    if cm.get("sensitivity") is None:
        return {"scope": "common", "key": "sensitivity", "text": "ì´ ìë¦¬ëŠ” ì–¼ë§ˆë‚˜ ì‹ ê²½ ì¨ì•¼ í•´? (1 ëŒ€ì¶©~ 4 ì¤‘ìš”í•œ ìë¦¬)"}

    if cm.get("focus") is None:
        return {"scope": "common", "key": "focus", "text": "ì˜¤ëŠ˜ì€ **ëŒ€í™”**ê°€ ë” ì¤‘ìš”í•´? **ìŒì‹**ì´ ë” ì¤‘ìš”í•´? (ëŒ€í™”/ìŒì‹/ê· í˜•)"}

    if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_plan") is None:
        return {"scope": "common", "key": "alcohol_plan", "text": "ìˆ  ì¤‘ì‹¬ì´ë©´ íë¦„ì€? (í•œ ê³³/1ì°¨2ì°¨ ë‚˜ëˆ”/ëª¨ë¥´ê² ìŒ)"}

    if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_type") is None:
        return {"scope": "common", "key": "alcohol_type", "text": "ì£¼ë¡œ ë­ ë§ˆì‹¤ ìƒê°ì´ì•¼? (ì†Œì£¼/ë§¥ì£¼/ì™€ì¸/ìƒê´€ì—†ìŒ)"}

    return None


def next_mode_question(conditions: dict):
    m = conditions["meta"]
    mode = m.get("mode", "ì„ íƒ ì•ˆ í•¨")
    if mode not in MODE_QUESTIONS:
        return None
    answers = m.get("answers", {})
    for q in MODE_QUESTIONS[mode]:
        if answers.get(q["key"]) is None:
            return {"scope": "mode", **q}
    return None


def get_next_question(conditions: dict):
    q = next_common_question(conditions)
    if q:
        return q
    return next_mode_question(conditions)


# -----------------------------
# Apply answer (pending ì§ˆë¬¸ + ìë™ ì±„ì›€)
# -----------------------------
def apply_answer(conditions: dict, pending: dict | None, user_text: str) -> bool:
    m = conditions["meta"]
    cm = m["common"]
    answers = m.get("answers", {})

    if detect_fast(user_text):
        m["fast_mode"] = True
        return True

    # ìë™ ì±„ì›€(ë¹„ì–´ìˆì„ ë•Œë§Œ)
    def fill_extras():
        if cm.get("alcohol_level") is None:
            v = parse_alcohol_level(user_text)
            if v:
                cm["alcohol_level"] = v
                if v == "ì—†ìŒ":
                    cm["alcohol_plan"] = None
                    cm["alcohol_type"] = None
        if cm.get("transport") is None:
            v = parse_transport(user_text)
            if v:
                cm["transport"] = v
        if cm.get("walk_limit_min") is None:
            v = parse_minutes(user_text)
            if v:
                cm["walk_limit_min"] = max(5, min(60, v))
        if cm.get("sensitivity") is None:
            v = parse_sensitivity(user_text)
            if v:
                cm["sensitivity"] = v
        if cm.get("focus") is None:
            v = parse_focus(user_text)
            if v:
                cm["focus"] = v
        if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬":
            if cm.get("alcohol_plan") is None:
                v = parse_alcohol_plan(user_text)
                if v:
                    cm["alcohol_plan"] = v
            if cm.get("alcohol_type") is None:
                v = parse_alcohol_type(user_text)
                if v:
                    cm["alcohol_type"] = v

    # pending ì—†ìœ¼ë©´ extrasë§Œ ì±„ì›Œë„ ì„±ê³µ ì²˜ë¦¬
    if not pending:
        fill_extras()
        return True

    key = pending.get("key")
    scope = pending.get("scope")
    tc = nc(user_text)

    if scope == "common" and key == "location":
        conditions["location"] = user_text.strip()
        fill_extras()
        return True

    if scope == "common" and key == "cannot_eat":
        if contains_any(tc, ["ì—†", "ìƒê´€ì—†", "ë‹¤ë¨¹", "ì•„ë¬´ê±°ë‚˜", "no", "ë…¸"]):
            conditions["constraints"]["cannot_eat"] = []
        else:
            parts = re.split(r"[,\n/]+", user_text)
            cleaned = []
            for p in parts:
                p = p.strip()
                if not p:
                    continue
                p = re.sub(r"(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ë§Œ|ë¹¼ê³ |ë¹¼ì¤˜|ì‹«ì–´|ëª»ë¨¹|ì•Œë ˆë¥´ê¸°)$", "", p).strip()
                if p and p not in cleaned:
                    cleaned.append(p)
            conditions["constraints"]["cannot_eat"] = cleaned[:10]
        cm["cannot_eat_done"] = True
        fill_extras()
        return True

    if scope == "common" and key == "alcohol_level":
        v = parse_alcohol_level(user_text)
        if not v:
            # "ì—†ìŒ"ì˜ ë‹¤ì–‘í•œ í‘œí˜„
            if contains_any(tc, ["ì•ˆë§ˆ", "ìˆ ì•ˆ", "íŒ¨ìŠ¤", "x", "ë…¸"]):
                v = "ì—†ìŒ"
        if not v:
            return False
        cm["alcohol_level"] = v
        if v == "ì—†ìŒ":
            cm["alcohol_plan"] = None
            cm["alcohol_type"] = None
        fill_extras()
        return True

    if scope == "common" and key == "transport":
        v = parse_transport(user_text)
        if not v and contains_any(tc, ["ê±¸ì–´", "ë„ë³´", "ëšœë²…"]):
            v = "ëŒ€ì¤‘êµí†µ"
        if not v:
            return False
        cm["transport"] = v
        fill_extras()
        return True

    if scope == "common" and key == "walk_limit_min":
        if contains_any(tc, ["ìƒê´€ì—†", "ì•„ë¬´", "ë¬´ê´€"]):
            cm["walk_limit_min"] = 30
            fill_extras()
            return True
        v = parse_minutes(user_text)
        if not v:
            return False
        cm["walk_limit_min"] = max(5, min(60, v))
        fill_extras()
        return True

    if scope == "common" and key == "sensitivity":
        v = parse_sensitivity(user_text)
        if not v:
            return False
        cm["sensitivity"] = v
        fill_extras()
        return True

    if scope == "common" and key == "focus":
        v = parse_focus(user_text)
        if not v:
            return False
        cm["focus"] = v
        fill_extras()
        return True

    if scope == "common" and key == "alcohol_plan":
        v = parse_alcohol_plan(user_text)
        if not v:
            return False
        cm["alcohol_plan"] = v
        fill_extras()
        return True

    if scope == "common" and key == "alcohol_type":
        v = parse_alcohol_type(user_text)
        if not v:
            return False
        cm["alcohol_type"] = v
        fill_extras()
        return True

    if scope == "mode":
        v = parse_mode_answer(key, user_text)
        if not v:
            return False
        answers[key] = v
        m["answers"] = answers
        fill_extras()
        return True

    fill_extras()
    return True


# -----------------------------
# LLM rerank (ì•ˆì • JSON)
# -----------------------------
def safe_json_load(text: str):
    try:
        return json.loads(text)
    except Exception:
        return None


def extract_first_json_object(text: str):
    m = re.search(r"\{.*\}", text, re.DOTALL)
    if not m:
        return None
    return safe_json_load(m.group(0))


def rerank_and_format(conditions: dict, places: list):
    if client is None:
        return []

    m = conditions["meta"]
    cm = m["common"]

    compact = []
    for p in places[:20]:
        compact.append({
            "id": p.get("id"),
            "name": p.get("place_name"),
            "category": p.get("category_name"),
            "address": p.get("road_address_name") or p.get("address_name"),
            "url": p.get("place_url"),
        })

    rules = {
        "mode": m.get("mode"),
        "place_type": m.get("place_type"),
        "food_class": m.get("food_class"),
        "people_count": m.get("people_count"),
        "budget_tier": m.get("budget_tier"),
        "focus": cm.get("focus"),
        "alcohol_level": cm.get("alcohol_level"),
        "alcohol_plan": cm.get("alcohol_plan"),
        "alcohol_type": cm.get("alcohol_type"),
        "transport": cm.get("transport"),
        "walk_limit_min": cm.get("walk_limit_min"),
        "sensitivity": cm.get("sensitivity"),
        "cannot_eat": conditions["constraints"].get("cannot_eat", []),
        "avoid_franchise": conditions["constraints"].get("avoid_franchise", False),
    }

    prompt = f"""
ë„ˆëŠ” 'ê²°ì • ë©”ì´íŠ¸'ë‹¤. í›„ë³´ ì¤‘ BEST 3ê³³ë§Œ ê³ ë¥´ê³ , ì™œ ì´ 3ê³³ì¸ì§€ 'ì‚¬ìš©ì ì¡°ê±´ ê¸°ë°˜'ìœ¼ë¡œë§Œ ì„¤ëª…í•´ë¼.

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ë§Œ ì¶œë ¥:
{{
  "picks":[
    {{
      "id":"...",
      "one_line":"ì¹œêµ¬í†¤ í•œì¤„",
      "scene_feel":"ì´ ê³³ì—ì„œ ì•½ì†í•˜ë©´ ì–´ë–¤ ëŠë‚Œì¸ì§€ 1~2ë¬¸ì¥",
      "hashtags":["#...","#...","#...","#..."],
      "matched_conditions":["ì‹¤ì œë¡œ ë°˜ì˜í•œ ì¡°ê±´ë§Œ"],
      "reason":"2~3ë¬¸ì¥. ê³¼ì¥ ê¸ˆì§€. í›„ë³´ ë°ì´í„° ê¸°ë°˜ë§Œ."
    }}
  ]
}}

ì¤‘ìš”:
- picksëŠ” ë°˜ë“œì‹œ 3ê°œ.
- place_type/food_classë¥¼ ìµœëŒ€í•œ ì§€ì¼œë¼.
- ìˆ  ì¤‘ì‹¬ + ì£¼ì¢… ìˆìœ¼ë©´ ì£¼ì¢…ì— ë§ëŠ” ê³³ ìš°ì„ .
- ì†Œê°œíŒ…/ì²«/ì–´ìƒ‰ + ë¯¼ê°ë„(3~4)ì´ë©´ 'ê³¼í•œ ì˜µì…˜(ì˜¤ë§ˆì¹´ì„¸/íŒŒì¸ë‹¤ì´ë‹ ëŠë‚Œ)' ì§€ì–‘.
- í›„ë³´ ë°ì´í„°ì— ì—†ëŠ” ì •ë³´(ì£¼ì°¨ í™•ì •/ì‹¤ë‚´ê°„ê²©/ê°€ê²©/ì˜ˆì•½ê°€ëŠ¥ ë“±) ìƒìƒ ê¸ˆì§€.
- hashtags 4~6ê°œ.
- "ë¬´ì¡°ê±´/ìµœê³ /ì™„ë²½" ê¸ˆì§€.

[ì‚¬ìš©ì ì¡°ê±´]
{json.dumps(rules, ensure_ascii=False, indent=2)}

[í›„ë³´ ëª©ë¡]
{json.dumps(compact, ensure_ascii=False, indent=2)}
"""

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.25,
        response_format={"type": "json_object"},
    )
    raw = (res.choices[0].message.content or "").strip()
    st.session_state.debug_raw_rerank = raw

    data = safe_json_load(raw) or extract_first_json_object(raw)
    if not isinstance(data, dict):
        return []
    picks = data.get("picks", [])
    if not isinstance(picks, list):
        return []
    return picks[:3]


def ensure_3_picks(picks: list, candidates: list):
    if not isinstance(picks, list):
        picks = []

    cand_map = {p.get("id"): p for p in candidates if p.get("id")}
    used = set()
    fixed = []

    for pk in picks:
        if not isinstance(pk, dict):
            continue
        pid = pk.get("id")
        if not pid or pid in used or pid not in cand_map:
            continue
        used.add(pid)
        # ì•ˆì „ í•„ë“œ ë³´ê°•
        pk.setdefault("one_line", "ì—¬ê¸° ë¬´ë‚œí•˜ê²Œ ê´œì°®ì•„ ë³´ì—¬ ğŸ˜")
        pk.setdefault("scene_feel", "ì¹´ì¹´ì˜¤ë§µ ì‚¬ì§„/ë¦¬ë·°ë¡œ ë¶„ìœ„ê¸° ë¹ ë¥´ê²Œ í™•ì¸ ê°€ëŠ¥!")
        pk.setdefault("hashtags", ["#ê·¼ì²˜", "#ë¬´ë‚œ", "#í›„ë³´", "#ë°”ë¡œí™•ì¸"])
        pk.setdefault("matched_conditions", ["ê·¼ì²˜ ìš°ì„ "])
        pk.setdefault("reason", "í›„ë³´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì¡°ê±´ì— ë¬´ë‚œí•˜ê²Œ ë§ëŠ” í¸ì´ë¼ í¬í•¨í–ˆì–´.")
        fixed.append(pk)

    for p in candidates:
        if len(fixed) >= 3:
            break
        pid = p.get("id")
        if not pid or pid in used:
            continue
        used.add(pid)
        fixed.append({
            "id": pid,
            "one_line": "í›„ë³´ ìƒìœ„ì—ì„œ ì•ˆì „í•˜ê²Œ í•˜ë‚˜ ë” ì±™ê¹€ ğŸ˜",
            "scene_feel": "ë§í¬ ëˆŒëŸ¬ì„œ ë¦¬ë·°/ì‚¬ì§„ í™•ì¸í•˜ë©´ ê° ë°”ë¡œ ì˜¬ ê±°ì•¼.",
            "hashtags": ["#ê·¼ì²˜", "#ë¬´ë‚œ", "#í›„ë³´ì¶”ê°€", "#ë°”ë¡œí™•ì¸"],
            "matched_conditions": ["ê·¼ì²˜ ìš°ì„ "],
            "reason": "ì¶”ì²œ ê²°ê³¼ê°€ ë¶€ì¡±í•´ì„œ í›„ë³´ í’€ ìƒìœ„ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì±„ì› ì–´."
        })

    return fixed[:3]


def generate_pre_text(conditions: dict, query: str):
    if client is None:
        return f"ì˜¤ì¼€ì´ã…‹ã…‹ **{query}**ë¡œ ë°”ë¡œ 3ê³³ ë½‘ì•„ë³¼ê²Œ ğŸ”"
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"ì¹œêµ¬ì²˜ëŸ¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ì¶”ì²œ ì‹œì‘ ë©˜íŠ¸. ì¡°ê±´ ë°˜ì˜. ì´ëª¨ì§€ 1ê°œ.\nê²€ìƒ‰ì–´: {query}"}],
        temperature=0.8
    )
    return (res.choices[0].message.content or "").strip()


# -----------------------------
# Render chat history
# -----------------------------
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])


# -----------------------------
# Main chat input
# -----------------------------
user_input = st.chat_input("ì˜ˆ: í™ëŒ€ì—­ ê·¼ì²˜, ì†Œê°œíŒ…ì´ë¼ ì¡°ìš©í–ˆìœ¼ë©´ / ì˜ˆ: ê·¸ëƒ¥ ì¶”ì²œí•´ / ì˜ˆ: ë‹¤ë¥¸ ë°")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        if not openai_key or not kakao_key:
            st.warning("ì‚¬ì´ë“œë°”ì— OpenAI í‚¤ë‘ Kakao í‚¤ë¶€í„° ë„£ì–´ì¤˜!")
            st.stop()

        # exclude last intent
        exclude_last = detect_exclude_last(user_input)

        # apply answer
        pending = st.session_state.conditions["meta"].get("pending_question")
        ok = apply_answer(st.session_state.conditions, pending, user_input)
        if pending and not ok:
            msg = f"ì˜¤ì¼€ì´ ê·¼ë° ë‚´ê°€ ì œëŒ€ë¡œ ì¡ê²Œ í•œ ë²ˆë§Œ ë”! ğŸ˜…\n\n**{pending['text']}**"
            st.markdown(msg)
            st.session_state.messages.append({"role": "assistant", "content": msg})
            st.stop()

        # clear pending
        st.session_state.conditions["meta"]["pending_question"] = None

        # next question?
        next_q = get_next_question(st.session_state.conditions)
        if next_q:
            st.session_state.conditions["meta"]["pending_question"] = next_q
            st.markdown(next_q["text"])
            st.session_state.messages.append({"role": "assistant", "content": next_q["text"]})
            st.stop()

        # -----------------------------
        # Recommend phase
        # -----------------------------
        conditions = st.session_state.conditions
        cm = conditions["meta"]["common"]

        query = build_query(conditions)
        pre = generate_pre_text(conditions, query)
        st.markdown(pre)

        # candidate pipeline with relax escalation
        relax_guard = 0
        places = []
        center = None
        used_query = query

        while relax_guard < 4:
            places, center, used_query = get_candidate_pool(conditions, kakao_key)
            places = franchise_filter(places, conditions["constraints"].get("avoid_franchise", False))
            places = filter_by_place_type(places, conditions["meta"].get("place_type", "ìë™"))
            places = dating_high_sensitivity_filter(places, conditions)
            places = prioritize_places(places, center, conditions)
            if exclude_last:
                places = filter_exclude_last(places, st.session_state.last_picks_ids)

            if len(places) >= 8:
                break

            # not enough -> relax up
            cm["search_relax"] = min(3, int(cm.get("search_relax", 0)) + 1)
            relax_guard += 1

        if debug_mode:
            with st.expander("ğŸ§¾ í˜„ì¬ ëˆ„ì  ì¡°ê±´(JSON)"):
                st.json(conditions)
            with st.expander("ğŸ§ª í›„ë³´ í’€(ìƒìœ„ 25)"):
                st.write(f"query: {used_query}")
                st.write(f"candidates: {len(places)} / relax: {cm.get('search_relax')}")
                for p in places[:25]:
                    st.write(f"- {p.get('place_name')} | {p.get('category_name')} | {p.get('road_address_name') or p.get('address_name')}")

        if not places:
            msg = "í—‰â€¦ ì´ ì¡°ê±´ìœ¼ë¡œëŠ” ë”± ë§ëŠ” ë°ê°€ ì˜ ì•ˆ ì¡íˆë„¤ ğŸ¥²\nì§€ì—­ì„ ì¡°ê¸ˆë§Œ ë„“í˜€ë³¼ê¹Œ?"
            st.markdown(msg)
            st.session_state.messages.append({"role": "assistant", "content": msg})
            st.stop()

        # rerank
        picks = rerank_and_format(conditions, places)
        if debug_mode:
            with st.expander("ğŸ¤– (ë””ë²„ê·¸) rerank LLM ì›ë¬¸"):
                st.code(st.session_state.debug_raw_rerank)

        # ensure 3
        picks = ensure_3_picks(picks, places)

        kakao_map = {p.get("id"): p for p in places if p.get("id")}

        st.markdown("---")
        st.subheader("ğŸ½ï¸ ë”± 3ê³³ë§Œ ê³¨ëì–´")
        cols = st.columns(3)

        current_pick_ids = []

        for i, pick in enumerate(picks[:3]):
            pid = pick.get("id")
            place = kakao_map.get(pid)
            if not pid or not place:
                continue
            current_pick_ids.append(pid)

            with cols[i]:
                name = place.get("place_name")
                addr = place.get("road_address_name") or place.get("address_name")
                url = place.get("place_url")
                category = place.get("category_name")

                st.markdown(f"### {i+1}. {name}")
                st.caption(category or "")
                st.write(f"ğŸ“ {addr}")

                st.markdown(f"**{pick.get('one_line','')}**")
                scene = pick.get("scene_feel")
                if scene:
                    st.markdown(f"_ì´ ìë¦¬ ëŠë‚Œ_: {scene}")

                matched = pick.get("matched_conditions", [])
                if matched:
                    st.markdown("**ë°˜ì˜í•œ ì¡°ê±´**")
                    st.markdown(" Â· ".join([f"`{m}`" for m in matched]))

                tags = pick.get("hashtags", [])
                if tags:
                    st.markdown(" ".join(tags))

                st.markdown("**ì™œ ì—¬ê¸°ëƒë©´â€¦**")
                st.write(pick.get("reason", ""))

                # walk estimate
                if center and center.get("x") and center.get("y") and place.get("x") and place.get("y"):
                    try:
                        dist = haversine_m(center["x"], center["y"], place["x"], place["y"])
                        walk_min = estimate_walk_minutes(dist)
                        st.caption(f"ğŸš¶ ì˜ˆìƒ ë„ë³´ ì•½ {walk_min}ë¶„")
                    except Exception:
                        pass

                if url:
                    st.link_button("ì¹´ì¹´ì˜¤ë§µì—ì„œ ë³´ê¸°", url)

        st.session_state.last_picks_ids = current_pick_ids

        final = "ë! ğŸ˜\nì…‹ ì¤‘ì— í•˜ë‚˜ ê³ ë¥´ê±°ë‚˜, **'ë‹¤ë¥¸ ë°'**, **'ë” ì¡°ìš©í•œ ë°'**, **'ì™„ì „ ë‹¤ë¥¸ ë¶„ìœ„ê¸°'** ì´ë ‡ê²Œ ë‹¤ì‹œ ì‹œì¼œë„ ë¼."
        st.session_state.messages.append({"role": "assistant", "content": final})
        st.markdown(final)
