# decision_mate_app_final_v3.py
# Streamlit prototype for "ê²°ì • ë©”ì´íŠ¸" (Decision Mate)
# v3 changes:
# - ìì—°ì–´ ë‹µë³€ í—ˆìš©(ì •í™•í•œ ì„ íƒì§€ ê°•ì œ X) ê°•í™”: apply_answer() í†µì§œ êµì²´
# - ê³µí†µ ì§ˆë¬¸ì— "ëŒ€í™” vs ìŒì‹ ì¤‘ì‹¬" (focus_priority) ì¶”ê°€
# - build_query()ì— focus_priorityë¥¼ ì•½í•˜ê²Œ ë°˜ì˜(í›„ë³´ í’€ ë§ë¼ì£½ì§€ ì•Šê²Œ)
# - ê¸°ì¡´: í›„ë³´ í’€ í™•ì¥(page+radius+center), ensure 3 picks, í•„í„°+LLM í•˜ì´ë¸Œë¦¬ë“œ ìœ ì§€

import json
import re
import time
import math
import requests
import streamlit as st
from openai import OpenAI
from math import radians, sin, cos, sqrt, atan2

# -----------------------------
# App config
# -----------------------------
st.set_page_config(page_title="ê²°ì • ë©”ì´íŠ¸", page_icon="ğŸ½ï¸", layout="wide")
st.title("ğŸ½ï¸ ê²°ì • ë©”ì´íŠ¸ (Decision Mate)")
st.caption("ë§›ì§‘ ì¶”ì²œì´ ì•„ë‹ˆë¼, ì•½ì† ì¥ì†Œ â€˜ê²°ì • í”¼ë¡œâ€™ë¥¼ ì¤„ì´ëŠ” ëŒ€í™”í˜• AI")

# -----------------------------
# Sidebar
# -----------------------------
st.sidebar.header("ğŸ”‘ API ì„¤ì •")
openai_key = st.sidebar.text_input("OpenAI API Key", type="password")
kakao_key = st.sidebar.text_input("Kakao Local REST API Key", type="password")

st.sidebar.markdown("---")
debug_mode = st.sidebar.checkbox("ğŸ› ï¸ ë””ë²„ê·¸ ëª¨ë“œ(LLM ì›ë¬¸/í›„ë³´í’€ ì¶œë ¥)", value=False)

client = OpenAI(api_key=openai_key) if openai_key else None

# -----------------------------
# Session State
# -----------------------------
if "messages" not in st.session_state:
    st.session_state.messages = [{
        "role": "assistant",
        "content": "ì˜¤ì¼€ì´ ğŸ˜\nì˜¤ëŠ˜ ì–´ë””ì„œ ëˆ„êµ¬ë‘ ë­ ë¨¹ì„ì§€ ë‚´ê°€ ë”± ì •í•´ì¤„ê²Œ.\nì¼ë‹¨ **ì–´ëŠ ë™ë„¤/ì—­ ê·¼ì²˜**ì—ì„œ ì°¾ì„ê¹Œ?"
    }]

if "conditions" not in st.session_state:
    st.session_state.conditions = {
        "location": None,
        "food_type": None,
        "purpose": None,
        "people": None,
        "mood": None,
        "constraints": {
            "cannot_eat": [],
            "avoid_recent": [],
            "need_parking": None
        },
        "meta": {
            "context_mode": None,       # íšŒì‚¬ íšŒì‹ / ì¹œêµ¬ / ë‹¨ì²´ ëª¨ì„ / ì—°ì¸Â·ì†Œê°œíŒ… / í˜¼ë°¥ / ê°€ì¡± / None
            "people_count": None,       # int
            "budget_tier": "ìƒê´€ì—†ìŒ",  # ê°€ì„±ë¹„ / ë³´í†µ / ì¡°ê¸ˆ íŠ¹ë³„ / ìƒê´€ì—†ìŒ
            "answers": {},
            "common": {
                "cannot_eat_done": False,
                "alcohol_level": None,        # ì—†ìŒ / ê°€ë³ê²Œ / ìˆ  ì¤‘ì‹¬
                "transport": None,            # ì°¨ / ëŒ€ì¤‘êµí†µ / ìƒê´€ì—†ìŒ
                "sensitivity_level": None,    # 1~4
                "focus_priority": None,       # ëŒ€í™” ì¤‘ì‹¬ / ìŒì‹ ì¤‘ì‹¬ / ê· í˜•
                "alcohol_plan": None,         # (ìˆ  ì¤‘ì‹¬) í•œ ê³³ / 1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„ / ëª¨ë¥´ê² ìŒ
                "alcohol_type": None,         # (ìˆ  ì¤‘ì‹¬) ì†Œì£¼/ë§¥ì£¼/ì™€ì¸/ìƒê´€ì—†ìŒ
                "search_relax": 0,            # 0~3
                "center_name": None,
            },
            "fast_mode": False
        }
    }

if "last_picks_ids" not in st.session_state:
    st.session_state.last_picks_ids = []

if "pending_question" not in st.session_state:
    st.session_state.pending_question = None

if "debug_raw_patch" not in st.session_state:
    st.session_state.debug_raw_patch = ""

if "debug_raw_rerank" not in st.session_state:
    st.session_state.debug_raw_rerank = ""

if "loc_center_cache" not in st.session_state:
    st.session_state.loc_center_cache = {}

# -----------------------------
# Helpers
# -----------------------------
def safe_json_load(text: str):
    try:
        return json.loads(text)
    except Exception:
        return None

def extract_first_json_object(text: str):
    m = re.search(r"\{.*\}", text, re.DOTALL)
    if not m:
        return None
    return safe_json_load(m.group(0))

def normalize_conditions(cond: dict):
    if not isinstance(cond, dict):
        return

    cond.setdefault("constraints", {})
    c = cond["constraints"]
    c.setdefault("cannot_eat", [])
    c.setdefault("avoid_recent", [])
    c.setdefault("need_parking", None)
    if not isinstance(c["cannot_eat"], list):
        c["cannot_eat"] = []
    if not isinstance(c["avoid_recent"], list):
        c["avoid_recent"] = []

    cond.setdefault("meta", {})
    m = cond["meta"]
    m.setdefault("context_mode", None)
    m.setdefault("people_count", None)
    m.setdefault("budget_tier", "ìƒê´€ì—†ìŒ")
    m.setdefault("answers", {})
    m.setdefault("fast_mode", False)

    m.setdefault("common", {})
    cm = m["common"]
    cm.setdefault("cannot_eat_done", False)
    cm.setdefault("alcohol_level", None)
    cm.setdefault("transport", None)
    cm.setdefault("sensitivity_level", None)
    cm.setdefault("focus_priority", None)
    cm.setdefault("alcohol_plan", None)
    cm.setdefault("alcohol_type", None)
    cm.setdefault("search_relax", 0)
    cm.setdefault("center_name", None)

def merge_conditions(base: dict, patch: dict):
    if not isinstance(patch, dict):
        return base
    if "constraints" in patch and isinstance(patch["constraints"], dict):
        for k, v in patch["constraints"].items():
            if v is None:
                continue
            base["constraints"][k] = v
    if "meta" in patch and isinstance(patch["meta"], dict):
        base_meta = base.get("meta", {}) or {}
        for k, v in patch["meta"].items():
            if v is None:
                continue
            base_meta[k] = v
        base["meta"] = base_meta
    for k, v in patch.items():
        if k in ("constraints", "meta"):
            continue
        if v is None:
            continue
        base[k] = v
    normalize_conditions(base)
    return base

def detect_skip_intent(text: str) -> bool:
    t = (text or "").strip()
    if not t:
        return False
    keywords = ["ê·¸ëƒ¥ ì¶”ì²œ", "ê± ì¶”ì²œ", "ë¹¨ë¦¬ ì¶”ì²œ", "ìŠ¤í‚µ", "ì•„ë¬´ê±°ë‚˜", "ëê³  ì¶”ì²œ", "ë°”ë¡œ ì¶”ì²œ", "ì¶”ì²œí•´ì¤˜"]
    return any(k in t for k in keywords)

def detect_expand_intent(text: str) -> bool:
    t = (text or "").strip()
    if not t:
        return False
    keywords = ["ë„“í˜€", "ë„“í˜€ë´", "ë²”ìœ„", "ì¡°ê¸ˆë§Œ ë„“í˜€", "ê·¼ì²˜ë¡œ", "ì£¼ë³€ìœ¼ë¡œ", "ë” ë©€ì–´ë„"]
    return any(k in t for k in keywords)

# -----------------------------
# Sidebar: Mode / People / Budget
# -----------------------------
st.sidebar.markdown("---")
st.sidebar.header("ğŸ§­ ìƒí™© ì„¤ì •")

MODE_OPTIONS = [
    "ì„ íƒ ì•ˆ í•¨",
    "íšŒì‚¬ íšŒì‹",
    "ì¹œêµ¬",
    "ë‹¨ì²´ ëª¨ì„",
    "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…",
    "í˜¼ë°¥",
    "ê°€ì¡±",
]
BUDGET_OPTIONS = ["ìƒê´€ì—†ìŒ", "ê°€ì„±ë¹„", "ë³´í†µ", "ì¡°ê¸ˆ íŠ¹ë³„"]

selected_mode = st.sidebar.selectbox("ìƒí™© ëª¨ë“œ", MODE_OPTIONS, index=0)
people_count = st.sidebar.number_input("ì¸ì›", min_value=1, max_value=30, value=2, step=1)
budget_tier = st.sidebar.radio("ì˜ˆì‚°ëŒ€(1ì¸)", BUDGET_OPTIONS, index=0)

normalize_conditions(st.session_state.conditions)
meta = st.session_state.conditions["meta"]
meta["context_mode"] = None if selected_mode == "ì„ íƒ ì•ˆ í•¨" else selected_mode
meta["people_count"] = int(people_count) if people_count else None
meta["budget_tier"] = budget_tier

# -----------------------------
# Kakao Local API
# -----------------------------
def kakao_keyword_search(query: str, kakao_rest_key: str, size: int = 15, page: int = 1,
                        x: str | None = None, y: str | None = None,
                        radius: int | None = None, sort: str | None = None):
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {kakao_rest_key}"}
    params = {"query": query, "size": size, "page": page}
    if x and y:
        params["x"] = x
        params["y"] = y
    if radius is not None:
        params["radius"] = radius
    if sort:
        params["sort"] = sort
    res = requests.get(url, headers=headers, params=params, timeout=10)
    res.raise_for_status()
    return res.json()

def kakao_keyword_search_paged(query: str, kakao_rest_key: str,
                              x: str | None = None, y: str | None = None,
                              radius: int | None = None, sort: str | None = None,
                              size: int = 15, max_pages: int = 3):
    all_docs = []
    for page in range(1, max_pages + 1):
        data = kakao_keyword_search(query, kakao_rest_key, size=size, page=page, x=x, y=y, radius=radius, sort=sort)
        docs = data.get("documents", [])
        meta = data.get("meta", {}) or {}
        all_docs.extend(docs)
        if meta.get("is_end") is True:
            break
    seen, uniq = set(), []
    for d in all_docs:
        pid = d.get("id")
        if not pid or pid in seen:
            continue
        seen.add(pid)
        uniq.append(d)
    return uniq

# -----------------------------
# Geo / Walk
# -----------------------------
def haversine_m(x1, y1, x2, y2):
    lon1, lat1, lon2, lat2 = map(radians, [float(x1), float(y1), float(x2), float(y2)])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return 6371000 * c

def estimate_walk_minutes(distance_m: float, speed_m_per_min: float = 80.0) -> int:
    if distance_m is None:
        return 999
    if distance_m >= 10**11:
        return 999
    return max(1, int(math.ceil(distance_m / speed_m_per_min)))

def place_distance_m(place: dict, center: dict):
    if not center or not center.get("x") or not center.get("y"):
        return None
    px, py = place.get("x"), place.get("y")
    if not px or not py:
        return None
    return haversine_m(center["x"], center["y"], px, py)

def attach_distance_meta(places: list, center: dict):
    if center:
        for p in places:
            d = place_distance_m(p, center)
            p["_distance_m"] = d if d is not None else 10**12
            p["_walk_min"] = estimate_walk_minutes(p["_distance_m"])
    else:
        for p in places:
            p["_distance_m"] = 10**12
            p["_walk_min"] = None
    return places

def get_location_center(location: str, kakao_rest_key: str):
    loc = (location or "").strip()
    if not loc:
        return None
    cache = st.session_state.loc_center_cache
    if loc in cache:
        return cache[loc]
    candidates = [loc] if "ì—­" in loc else [f"{loc}ì—­", loc]
    for cand in candidates:
        try:
            docs = kakao_keyword_search_paged(cand, kakao_rest_key, size=15, max_pages=1)
            if not docs:
                continue
            d = docs[0]
            center = {"x": d.get("x"), "y": d.get("y"), "name": cand}
            if center["x"] and center["y"]:
                cache[loc] = center
                return center
        except Exception:
            continue
    return None

def filter_places_by_radius(places: list, center: dict, radius_m: int):
    if not center or not center.get("x") or not center.get("y"):
        return places
    out = []
    cx, cy = center["x"], center["y"]
    for p in places:
        px, py = p.get("x"), p.get("y")
        if not px or not py:
            continue
        if haversine_m(cx, cy, px, py) <= radius_m:
            out.append(p)
    return out

def parking_signal_score(place: dict) -> int:
    text = f"{place.get('place_name','')} {place.get('category_name','')}".lower()
    score = 0
    if "ì£¼ì°¨" in text or "parking" in text or "ë°œë ›" in text:
        score += 3
    big_like = ["ë°±í™”ì ", "ëª°", "ì•„ìš¸ë ›", "í˜¸í…”", "ì»¨ë²¤ì…˜", "ëŒ€í˜•"]
    if any(k in text for k in big_like):
        score += 1
    return score

def sort_places_for_transport(places: list, center: dict, transport: str):
    if not center or not center.get("x") or not center.get("y"):
        return places
    cx, cy = center["x"], center["y"]
    scored = []
    for p in places:
        px, py = p.get("x"), p.get("y")
        dist = haversine_m(cx, cy, px, py) if (px and py) else 10**12
        park = parking_signal_score(p) if transport == "ì°¨" else 0
        score = dist - (park * 120)
        scored.append((score, dist, p))
    scored.sort(key=lambda t: (t[0], t[1]))
    return [p for _, __, p in scored]

# -----------------------------
# Place kind inference (meal/cafe/drink)
# -----------------------------
def infer_place_kind(conditions: dict) -> str:
    normalize_conditions(conditions)
    cm = conditions["meta"]["common"]
    alcohol = cm.get("alcohol_level")

    ft = (conditions.get("food_type") or "")
    mood = (conditions.get("mood") or "")
    purpose = (conditions.get("purpose") or "")
    text = f"{ft} {mood} {purpose}"
    if any(k in text for k in ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬"]):
        return "cafe"

    if alcohol in ("ê°€ë³ê²Œ", "ìˆ  ì¤‘ì‹¬"):
        return "drink"
    return "meal"

def filter_by_kind(places: list, kind: str):
    def cat(p): return (p.get("category_name") or "")
    if kind == "meal":
        banned = ["ì¹´í˜", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì•„ì´ìŠ¤í¬ë¦¼"]
        out = [p for p in places if not any(b in cat(p) for b in banned)]
        return out if len(out) >= 10 else places
    if kind == "cafe":
        allow = ["ì¹´í˜", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì•„ì´ìŠ¤í¬ë¦¼"]
        out = [p for p in places if any(a in cat(p) for a in allow)]
        return out if len(out) >= 10 else places
    if kind == "drink":
        allow = ["ìˆ ", "ì£¼ì ", "í˜¸í”„", "ì´ìì¹´ì•¼", "ë°”", "í¬ì°¨", "í"]
        out = [p for p in places if any(a in cat(p) for a in allow)]
        return out if len(out) >= 10 else places
    return places

# -----------------------------
# Mild "too heavy" filter
# -----------------------------
def mild_context_filter(places: list, conditions: dict):
    normalize_conditions(conditions)
    mode = conditions["meta"].get("context_mode")
    s = conditions["meta"]["common"].get("sensitivity_level")
    if mode != "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…":
        return places
    if not isinstance(s, int) or s < 3:
        return places

    banned = ["ì˜¤ë§ˆì¹´ì„¸", "íŒŒì¸ë‹¤ì´ë‹", "ì½”ìŠ¤ìš”ë¦¬", "í…Œì´ìŠ¤íŒ…", "ì…°í”„", "í•œìš°ì˜¤ë§ˆì¹´ì„¸"]
    out = []
    for p in places:
        name = (p.get("place_name") or "")
        if any(b in name for b in banned):
            continue
        out.append(p)
    return out if len(out) >= 10 else places

# -----------------------------
# Ensure 3 picks
# -----------------------------
def ensure_3_picks(picks: list, candidates: list):
    if not isinstance(picks, list):
        picks = []
    cand_ids = [p.get("id") for p in candidates if p.get("id")]
    cand_set = set(cand_ids)

    fixed, used = [], set()
    for pk in picks:
        if not isinstance(pk, dict):
            continue
        pid = pk.get("id")
        if not pid or pid not in cand_set or pid in used:
            continue
        used.add(pid)
        fixed.append(pk)

    for p in candidates:
        pid = p.get("id")
        if not pid or pid in used:
            continue
        used.add(pid)
        fixed.append({
            "id": pid,
            "scene_feel": "í›„ë³´ í’€ ìƒìœ„ì—ì„œ ë¬´ë‚œí•˜ê²Œ ë§ëŠ” ê³³ë„ ê°™ì´ ì±™ê²¨ë’€ì–´. ë§í¬ ëˆŒëŸ¬ì„œ ë¶„ìœ„ê¸°ë§Œ ë¹ ë¥´ê²Œ í™•ì¸í•˜ë©´ ë¼.",
            "one_line": "ê·¼ì²˜ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ê°€ê¸° ì¢‹ì€ ì„ íƒì§€!",
            "hashtags": ["#ê·¼ì²˜", "#ë¬´ë‚œ", "#ë°”ë¡œê°€ê¸°", "#í›„ë³´ì¶”ê°€"],
            "matched_conditions": ["ê·¼ì²˜ ìš°ì„ "],
            "reason": "ì¶”ì²œ ê²°ê³¼ì— ëˆ„ë½ì´ ìƒê²¨ì„œ, í›„ë³´ í’€ ìƒìœ„ì—ì„œ ëŒ€ì‹  ì±„ì› ì–´ ğŸ˜"
        })
        if len(fixed) >= 3:
            break
    return fixed[:3]

# -----------------------------
# LLM Patch extraction
# -----------------------------
def extract_conditions_patch(latest_user_text: str, current_conditions: dict):
    if client is None:
        return {}
    system = """
ë„ˆëŠ” 'ê²°ì • ë©”ì´íŠ¸'ì˜ ì¡°ê±´ ì—…ë°ì´íŠ¸ ì—”ì§„ì´ë‹¤.

[ëª©í‘œ]
ì‚¬ìš©ìì˜ 'ìµœì‹  ë°œí™”'ë¥¼ ë³´ê³ , ê¸°ì¡´ ì¡°ê±´ì—ì„œ ë³€ê²½/ì¶”ê°€ëœ ê°’ë§Œ JSON PATCHë¡œ ì¶œë ¥í•œë‹¤.

[ì¤‘ìš”]
- ë°˜ë“œì‹œ JSON ì˜¤ë¸Œì íŠ¸ë§Œ ì¶œë ¥.
- ì–¸ê¸‰í•˜ì§€ ì•Šì€ í•„ë“œëŠ” ì¶œë ¥í•˜ì§€ ë§ ê²ƒ.
- nullë¡œ ì´ˆê¸°í™” ê¸ˆì§€.
- constraints ë¦¬ìŠ¤íŠ¸ëŠ” ì‚¬ìš©ìê°€ ìƒˆë¡œ ì–¸ê¸‰í•œ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸.
- "ì•„ê¹Œ ë§ê³  ë‹¤ë¥¸ ë°" => diversify=true
- "ë°©ê¸ˆ ì¶”ì²œ ì œì™¸" => exclude_last=true
- "í”„ì°¨ ë¹¼ì¤˜" => avoid_franchise=true

ê°€ëŠ¥í•œ í•„ë“œ:
- location, food_type, purpose, people, mood
- constraints.cannot_eat (list[str])
- constraints.avoid_recent (list[str])
- constraints.need_parking (true/false)
- diversify (true/false)
- exclude_last (true/false)
- avoid_franchise (true/false)
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": f"[ê¸°ì¡´ ì¡°ê±´]\n{json.dumps(current_conditions, ensure_ascii=False)}"},
            {"role": "user", "content": f"[ìµœì‹  ë°œí™”]\n{latest_user_text}"},
        ],
        temperature=0.2,
        response_format={"type": "json_object"},
    )
    raw = (res.choices[0].message.content or "").strip()
    st.session_state.debug_raw_patch = raw
    patch = safe_json_load(raw) or extract_first_json_object(raw)
    return patch if isinstance(patch, dict) else {}

# -----------------------------
# Question flow
# -----------------------------
MODE_REQUIRED_QUESTIONS = {
    "ì¹œêµ¬": [
        {"key": "friend_style", "text": "ì¹œêµ¬ë‘ì´ë©´ ì˜¤ëŠ˜ ëŠë‚Œì´ ë­ì•¼? **ìˆ˜ë‹¤ ì¤‘ì‹¬ / ë¨¹ëŠ” ì¬ë¯¸ ì¤‘ì‹¬** ğŸ˜†", "type": "enum"},
    ],
    "íšŒì‚¬ íšŒì‹": [
        {"key": "work_vibe", "text": "íšŒì‹ ë¶„ìœ„ê¸°: **ê°€ë³ê²Œ / ì •ëˆëœ ìë¦¬** ì¤‘ ë­ì— ê°€ê¹Œì›Œ?", "type": "enum"},
    ],
    "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…": [
        {"key": "dating_stage", "text": "ì§€ê¸ˆ ë‹¨ê³„ëŠ”? **ì²«/ì–´ìƒ‰ / ìµìˆ™**", "type": "enum"},
    ],
    "ê°€ì¡±": [
        {"key": "family_member", "text": "ê°€ì¡± êµ¬ì„±ì— **ì•„ì´/ì–´ë¥¸(ì—°ì„¸)** ìˆì–´? **ì•„ì´ / ì–´ë¥¸ / ë‘˜ ë‹¤ / ì—†ìŒ**", "type": "enum"},
    ],
}

SENSI_TEXT = "ì´ ìë¦¬ëŠ” ì–¼ë§ˆë‚˜ ì‹ ê²½ ì¨ì•¼ í•˜ëŠ” ìë¦¬ì•¼?\n**1) ì•„ë¬´ ìƒê° ì—†ì´ / 2) í¸í•˜ì§€ë§Œ ë„ˆë¬´ ë§‰ì€ ì•„ë‹Œ / 3) ì¢€ ì‹ ê²½ ì¨ì•¼ í•˜ëŠ” / 4) ì¤‘ìš”í•œ ìë¦¬**"
FOCUS_TEXT = "ì˜¤ëŠ˜ì€ **ëŒ€í™”ê°€ ë” ì¤‘ìš”í•´? ìŒì‹ì´ ë” ì¤‘ìš”í•´?** ğŸ˜Œ\n**ëŒ€í™” ì¤‘ì‹¬ / ìŒì‹ ì¤‘ì‹¬ / ë‘˜ ë‹¤ ë¹„ìŠ·(ê· í˜•)**"

def get_next_mode_question(conditions: dict):
    normalize_conditions(conditions)
    mode = conditions["meta"]["context_mode"]
    if not mode or mode not in MODE_REQUIRED_QUESTIONS:
        return None
    answers = conditions["meta"]["answers"]
    for q in MODE_REQUIRED_QUESTIONS[mode]:
        if answers.get(q["key"]) is None:
            return {"scope": "mode", **q}
    return None

def get_next_common_question(conditions: dict):
    normalize_conditions(conditions)
    cm = conditions["meta"]["common"]

    if not conditions.get("location"):
        return {"scope": "common", "key": "location", "text": "ì˜¤ì¼€ì´! **ì–´ëŠ ë™ë„¤/ì—­ ê·¼ì²˜**ì—ì„œ ì°¾ì„ê¹Œ? ğŸ“", "type": "free"}

    if not cm.get("cannot_eat_done", False):
        return {"scope": "common", "key": "cannot_eat", "text": "ëª» ë¨¹ëŠ” ê±° ìˆì–´? (ì•Œë ˆë¥´ê¸°/ê·¹í˜ í¬í•¨) ì—†ìœ¼ë©´ **ì—†ìŒ** ğŸ™…", "type": "list_or_none"}

    if conditions["meta"].get("fast_mode"):
        return None

    if cm.get("alcohol_level") is None:
        return {"scope": "common", "key": "alcohol_level", "text": "ì˜¤ëŠ˜ ìˆ ì€ ì–´ë•Œ? **ì—†ìŒ / ê°€ë³ê²Œ / ìˆ  ì¤‘ì‹¬** ğŸ»", "type": "enum_alcohol"}

    if cm.get("transport") is None:
        return {"scope": "common", "key": "transport", "text": "ì´ë™ìˆ˜ë‹¨ì€? **ëŒ€ì¤‘êµí†µ / ì°¨ / ìƒê´€ì—†ìŒ** ğŸ§­", "type": "enum_transport"}

    if cm.get("sensitivity_level") is None:
        return {"scope": "common", "key": "sensitivity_level", "text": SENSI_TEXT, "type": "enum_sensitivity"}

    if cm.get("focus_priority") is None:
        return {"scope": "common", "key": "focus_priority", "text": FOCUS_TEXT, "type": "enum_focus"}

    if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_plan") is None:
        return {"scope": "common", "key": "alcohol_plan",
                "text": "ìˆ  ì¤‘ì‹¬ì´ë©´ íë¦„ì€? **í•œ ê³³ / 1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„ / ëª¨ë¥´ê² ìŒ**", "type": "enum_alcohol_plan"}

    if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_plan") in ("í•œ ê³³", "1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„") and cm.get("alcohol_type") is None:
        return {"scope": "common", "key": "alcohol_type",
                "text": "ì£¼ë¡œ ë­ ë§ˆì‹¤ ìƒê°ì´ì•¼? **ì†Œì£¼ / ë§¥ì£¼ / ì™€ì¸ / ìƒê´€ì—†ìŒ** ğŸ¶", "type": "enum_alcohol_type"}

    return None

def get_next_question(conditions: dict):
    q = get_next_common_question(conditions)
    if q:
        return q
    return get_next_mode_question(conditions)

# -----------------------------
# âœ… apply_answer() : ìì—°ì–´ ëŒ€ì‘ í†µì§œ êµì²´ + focus_priority í¬í•¨
# -----------------------------
def apply_answer(conditions: dict, pending_q: dict, user_text: str) -> bool:
    normalize_conditions(conditions)

    t = (user_text or "").strip()
    if not t:
        return False

    t_low = t.lower()

    cm = conditions["meta"]["common"]
    answers = conditions["meta"]["answers"]

    key = pending_q.get("key")
    qtype = pending_q.get("type")

    # -----------------------------
    # LOCATION
    # -----------------------------
    if key == "location":
        conditions["location"] = t
        return True

    # -----------------------------
    # CANNOT EAT (ì•Œë ˆë¥´ê¸°/ëª»ë¨¹ëŠ”ê±°)
    # -----------------------------
    if qtype == "list_or_none" and key == "cannot_eat":
        if any(k in t for k in ["ì—†", "ìƒê´€ì—†", "ë‹¤ ë¨¹", "ì•„ë¬´ê±°ë‚˜"]):
            conditions["constraints"]["cannot_eat"] = []
        else:
            parts = re.split(r"[,\n/]+", t)
            cleaned = []
            for p in parts:
                p = p.strip()
                if not p:
                    continue
                p = re.sub(r"(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ë§Œ|ë¹¼ê³ |ë¹¼ì¤˜)$", "", p).strip()
                if p and p not in cleaned:
                    cleaned.append(p)
            conditions["constraints"]["cannot_eat"] = cleaned[:6]
        cm["cannot_eat_done"] = True
        return True

    # -----------------------------
    # ALCOHOL LEVEL
    # -----------------------------
    if qtype == "enum_alcohol" and key == "alcohol_level":
        if any(k in t_low for k in ["ì•ˆ ë§ˆ", "ìˆ  ì•ˆ", "ê¸ˆì£¼", "ë…¸ì•Œì½œ", "ë…¸ ì•Œì½œ", "ëª» ë§ˆ", "ì•ˆë¨¹", "ì•ˆ ë¨¹"]):
            cm["alcohol_level"] = "ì—†ìŒ"
            cm["alcohol_plan"] = None
            cm["alcohol_type"] = None
            return True

        if any(k in t_low for k in ["ê°€ë³", "í•œë‘ì”", "í•œë‘ ì”", "ì ë‹¹íˆ", "ì¡°ê¸ˆ", "ì‚´ì§", "1~2ì”", "1-2ì”"]):
            cm["alcohol_level"] = "ê°€ë³ê²Œ"
            cm["alcohol_plan"] = None
            cm["alcohol_type"] = None
            return True

        if any(k in t_low for k in ["ìˆ  ì¤‘ì‹¬", "ì œëŒ€ë¡œ", "ë§ì´", "ë‹¬ë¦´", "ëê¹Œì§€", "ì·¨í• ", "í­", "ì­‰"]):
            cm["alcohol_level"] = "ìˆ  ì¤‘ì‹¬"
            return True

        return False

    # -----------------------------
    # TRANSPORT (ì°¨/ëŒ€ì¤‘êµí†µ/ë„ë³´/íƒì‹œ ë“± ìì—°ì–´)
    # -----------------------------
    if qtype == "enum_transport" and key == "transport":
        # car-ish
        if any(k in t_low for k in [
            "ì°¨", "ìê°€ìš©", "ìš´ì „", "ëª°ê³ ", "ëŒê³ ", "ì£¼ì°¨", "ë°œë ›", "ì¹´í’€", "ë ŒíŠ¸", "ëŒ€ë¦¬", "íƒ€ê³ ê°ˆ", "íƒ€ê³  ê°ˆ"
        ]):
            cm["transport"] = "ì°¨"
            return True

        # public/walk-ish (ì‚¬ìš©ì í‘œí˜„ì„ "ëŒ€ì¤‘êµí†µ"ìœ¼ë¡œ ë¬¶ìŒ)
        if any(k in t_low for k in [
            "ì§€í•˜ì² ", "ë²„ìŠ¤", "ëŒ€ì¤‘", "ê±¸ì–´", "ë„ë³´", "ëšœë²…", "ëšœë²…ì´", "íƒì‹œ", "ì „ì² ", "í™˜ìŠ¹", "ì—­", "ê·¼ì²˜ ê±¸ì„"
        ]):
            cm["transport"] = "ëŒ€ì¤‘êµí†µ"
            return True

        # doesn't matter
        if any(k in t_low for k in ["ìƒê´€", "ì•„ë¬´", "ëª°ë¼", "ê·¸ëƒ¥", "ë¬´ê´€"]):
            cm["transport"] = "ìƒê´€ì—†ìŒ"
            return True

        return False

    # -----------------------------
    # SENSITIVITY LEVEL (ì‹ ê²½ ì“°ëŠ” ì •ë„)
    # -----------------------------
    if qtype == "enum_sensitivity" and key == "sensitivity_level":
        # numeric
        if re.search(r"\b1\b", t):
            cm["sensitivity_level"] = 1; return True
        if re.search(r"\b2\b", t):
            cm["sensitivity_level"] = 2; return True
        if re.search(r"\b3\b", t):
            cm["sensitivity_level"] = 3; return True
        if re.search(r"\b4\b", t):
            cm["sensitivity_level"] = 4; return True

        # keywords
        if any(k in t for k in ["ì•„ë¬´ ìƒê°", "ë§‰", "í¸í•˜ê²Œ", "ì™„ì „ í¸", "ìºì£¼ì–¼", "ëŒ€ì¶©", "ê°€ë³ê²Œ ê°€ì"]):
            cm["sensitivity_level"] = 1; return True

        if any(k in t for k in ["ì ë‹¹íˆ", "ë¬´ë‚œ", "ë„ˆë¬´ ë§‰ì€ ì•„ë‹Œ", "ê¹”ë”í•˜ë©´", "í‰ë²”í•˜ê²Œ"]):
            cm["sensitivity_level"] = 2; return True

        if any(k in t for k in ["ì¢€ ì‹ ê²½", "ë¶„ìœ„ê¸°", "ê´œì°®ì€ ë°", "ë°ì´íŠ¸ ëŠë‚Œ", "ë‚˜ì˜ì§€ ì•Šê²Œ", "ê´œì°®ê²Œ"]):
            cm["sensitivity_level"] = 3; return True

        if any(k in t for k in ["ì¤‘ìš”", "ê²©ì‹", "ê¸°ë…ì¼", "íŠ¹ë³„í•œ ë‚ ", "ìƒê²¬ë¡€", "ë¶€ëª¨ë‹˜", "ì ‘ëŒ€"]):
            cm["sensitivity_level"] = 4; return True

        return False

    # -----------------------------
    # FOCUS PRIORITY (ëŒ€í™”/ìŒì‹/ê· í˜•) âœ… ì¶”ê°€
    # -----------------------------
    if qtype == "enum_focus" and key == "focus_priority":
        # ëŒ€í™”
        if any(k in t for k in ["ëŒ€í™”", "ìˆ˜ë‹¤", "ì–˜ê¸°", "ë§", "í† í¬", "ì´ì•¼ê¸°", "ì¡°ìš©", "í¸í•˜ê²Œ ì–˜ê¸°"]):
            cm["focus_priority"] = "ëŒ€í™” ì¤‘ì‹¬"
            return True

        # ìŒì‹
        if any(k in t for k in ["ìŒì‹", "ë¨¹ëŠ”", "ë§›", "ë©”ë‰´", "ë§›ìˆëŠ”", "ë§›ì§‘", "ë°°ê³ íŒŒ", "ë“ ë“ "]):
            cm["focus_priority"] = "ìŒì‹ ì¤‘ì‹¬"
            return True

        # ê· í˜•
        if any(k in t for k in ["ë‘˜", "ë¹„ìŠ·", "ë°˜ë°˜", "ê· í˜•", "ìƒê´€", "ì•„ë¬´"]):
            cm["focus_priority"] = "ê· í˜•"
            return True

        return False

    # -----------------------------
    # ALCOHOL PLAN
    # -----------------------------
    if qtype == "enum_alcohol_plan" and key == "alcohol_plan":
        if any(k in t for k in ["í•œ ê³³", "í•œêµ°ë°", "í•œ êµ°ë°", "ì˜¬ì¸ì›", "í•œë°©ì—", "í•œ ë²ˆì—"]):
            cm["alcohol_plan"] = "í•œ ê³³"; return True
        if any(k in t for k in ["ë‚˜ëˆ ", "2ì°¨", "1ì°¨", "ì˜®ê²¨", "ì´ë™", "ì½”ìŠ¤", "ë°”ê¿”"]):
            cm["alcohol_plan"] = "1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„"; return True
        if any(k in t for k in ["ëª¨ë¥´", "ì•„ì§", "ê·¸ë•Œ ê°€ì„œ", "ìƒí™©ë´ì„œ"]):
            cm["alcohol_plan"] = "ëª¨ë¥´ê² ìŒ"; return True
        return False

    # -----------------------------
    # ALCOHOL TYPE
    # -----------------------------
    if qtype == "enum_alcohol_type" and key == "alcohol_type":
        if "ì†Œì£¼" in t or "ì°¸ì´ìŠ¬" in t or "ì²˜ìŒì²˜ëŸ¼" in t:
            cm["alcohol_type"] = "ì†Œì£¼"; return True
        if any(k in t for k in ["ë§¥ì£¼", "ë¹„ì–´", "í¬ë˜í”„íŠ¸", "IPA", "ë¼ê±°", "ì—ì¼"]):
            cm["alcohol_type"] = "ë§¥ì£¼"; return True
        if "ì™€ì¸" in t or "ë‚´ì¶”ëŸ´" in t:
            cm["alcohol_type"] = "ì™€ì¸"; return True
        if any(k in t for k in ["ìƒê´€", "ì•„ë¬´", "ë¬´ê´€"]):
            cm["alcohol_type"] = "ìƒê´€ì—†ìŒ"; return True
        return False

    # -----------------------------
    # MODE questions (optional)
    # -----------------------------
    if pending_q.get("scope") == "mode":
        k = key
        maps = {
            "friend_style": {"ìˆ˜ë‹¤": "ìˆ˜ë‹¤ ì¤‘ì‹¬", "ëŒ€í™”": "ìˆ˜ë‹¤ ì¤‘ì‹¬", "ë¨¹": "ë¨¹ëŠ” ì¬ë¯¸ ì¤‘ì‹¬"},
            "work_vibe": {"ê°€ë³": "ê°€ë³ê²Œ", "ìºì£¼ì–¼": "ê°€ë³ê²Œ", "ì •ëˆ": "ì •ëˆëœ ìë¦¬", "ê²©ì‹": "ì •ëˆëœ ìë¦¬"},
            "dating_stage": {"ì²«": "ì²«/ì–´ìƒ‰", "ì–´ìƒ‰": "ì²«/ì–´ìƒ‰", "ìµìˆ™": "ìµìˆ™", "í¸": "ìµìˆ™"},
            "family_member": {"ë‘˜": "ë‘˜ ë‹¤", "ì•„ì´": "ì•„ì´", "ì–´ë¥¸": "ì–´ë¥¸", "ë¶€ëª¨": "ì–´ë¥¸", "ì—†": "ì—†ìŒ"},
        }
        picked = None
        for kw, val in maps.get(k, {}).items():
            if kw in t:
                picked = val
                break
        if picked is None:
            return False
        answers[k] = picked
        return True

    return False

# -----------------------------
# Query build (relax 0~3) + focus_priority ë°˜ì˜(ì•½í•˜ê²Œ)
# -----------------------------
def build_query(conditions):
    normalize_conditions(conditions)
    cm = conditions["meta"]["common"]
    mode = conditions["meta"].get("context_mode")
    budget = conditions["meta"].get("budget_tier")
    alcohol = cm.get("alcohol_level")
    alcohol_type = cm.get("alcohol_type")
    s = cm.get("sensitivity_level")
    focus = cm.get("focus_priority")
    relax = int(cm.get("search_relax", 0) or 0)

    tokens = []
    loc = conditions.get("location")
    if loc:
        tokens.append(loc)

    # user food_type (optional)
    if conditions.get("food_type"):
        tokens.append(conditions["food_type"])

    kind = infer_place_kind(conditions)
    if kind == "cafe":
        place_token = "ì¹´í˜"
    elif kind == "drink":
        if alcohol_type == "ì™€ì¸":
            place_token = "ì™€ì¸ë°”"
        elif alcohol_type == "ë§¥ì£¼":
            place_token = "í"
        else:
            place_token = "ìˆ ì§‘"
    else:
        place_token = "ë§›ì§‘"

    # relax==0ì—ì„œë§Œ ì•½í•œ ì»¨í…ìŠ¤íŠ¸ í† í° ì¶”ê°€ (í›„ë³´ í’€ ë§ë¼ì£½ëŠ” ê±° ë°©ì§€)
    if relax == 0:
        tokens.append(place_token)

        if mode == "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…" and kind != "drink":
            tokens.append("ë°ì´íŠ¸")

        if mode == "íšŒì‚¬ íšŒì‹":
            tokens.append("íšŒì‹")

        if budget == "ê°€ì„±ë¹„":
            tokens.append("ê°€ì„±ë¹„")

        # ì‹ ê²½ ë ˆë²¨ì´ ë†’ìœ¼ë©´ 'ë¶„ìœ„ê¸°' ì •ë„ë§Œ
        if isinstance(s, int) and s >= 3 and kind == "meal":
            tokens.append("ë¶„ìœ„ê¸°")

        # âœ… focus_priority: ëŒ€í™” ì¤‘ì‹¬ì´ë©´ ì¡°ìš©/ëŒ€í™” í† í° ì•½í•˜ê²Œ(ê²€ìƒ‰ì–´ì—ë§Œ)
        if focus == "ëŒ€í™” ì¤‘ì‹¬":
            # ë„ˆë¬´ ê°•í•˜ë©´ í›„ë³´ê°€ ì¤„ì–´ì„œ 'ì¡°ìš©' í•˜ë‚˜ë§Œ
            tokens.append("ì¡°ìš©")
        elif focus == "ìŒì‹ ì¤‘ì‹¬":
            # ë§›ì§‘ í† í°ì€ ì´ë¯¸ ìˆì–´ì„œ ì¶”ê°€ X (ê³¼ë„ì œì•½ ë°©ì§€)
            pass

    elif relax == 1:
        tokens.append(place_token)
    elif relax == 2:
        tokens.append("ìˆ ì§‘" if kind == "drink" else ("ì¹´í˜" if kind == "cafe" else "ë§›ì§‘"))
    else:
        tokens.append("ìˆ ì§‘" if kind == "drink" else "ë§›ì§‘")

    return " ".join([t for t in tokens if t]).strip()

def make_query_variants(base_query: str, location: str, relax_level: int):
    qs = []
    if relax_level >= 1 and location:
        stripped = base_query.replace(location, "").strip()
        qs.append(f"{location} ê·¼ì²˜ {stripped}".strip())
        qs.append(f"{location} ì£¼ë³€ {stripped}".strip())
    qs.append(base_query)
    out, seen = [], set()
    for q in qs:
        q = re.sub(r"\s+", " ", q).strip()
        if q and q not in seen:
            seen.add(q)
            out.append(q)
    return out

# -----------------------------
# Candidate filtering
# -----------------------------
def filter_places(places, exclude_ids):
    if not exclude_ids:
        return places
    s = set(exclude_ids)
    return [p for p in places if p.get("id") not in s]

DEFAULT_FRANCHISE = [
    "ì‰ì´í¬ì‰‘", "ìŠ¤íƒ€ë²…ìŠ¤", "íˆ¬ì¸", "ì´ë””ì•¼", "ë¹½ë‹¤ë°©", "ë©”ê°€ì»¤í”¼", "ì»´í¬ì¦ˆ",
    "íŒŒë¦¬ë°”ê²Œëœ¨", "ëšœë ˆì¥¬ë¥´", "ë²„ê±°í‚¹", "ë§¥ë„ë‚ ë“œ", "ë¡¯ë°ë¦¬ì•„", "kfc", "ì„œë¸Œì›¨ì´"
]

def filter_franchise(places: list, enabled: bool):
    if not enabled:
        return places
    out = []
    for p in places:
        name = (p.get("place_name") or "").lower()
        if any(f.lower() in name for f in DEFAULT_FRANCHISE):
            continue
        out.append(p)
    return out if len(out) >= 10 else places

# -----------------------------
# Rerank + formatting (LLM)
# -----------------------------
def rerank_and_format(conditions, places):
    if client is None:
        return []
    normalize_conditions(conditions)
    cm = conditions["meta"]["common"]
    split_12 = (cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_plan") == "1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„")

    compact = []
    for p in places[:25]:
        compact.append({
            "id": p.get("id"),
            "name": p.get("place_name"),
            "category": p.get("category_name"),
            "address": p.get("road_address_name") or p.get("address_name"),
            "url": p.get("place_url"),
            "walk_min": p.get("_walk_min"),
            "distance_m": p.get("_distance_m"),
        })

    schema_hint = """
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ë¼:
{
  "picks": [
    {
      "id": "...",
      "scene_feel": "ì—¬ê¸°ì„œ ì•½ì†í•˜ë©´ ì–´ë–¤ ëŠë‚Œì¸ì§€ 2~3ë¬¸ì¥(ì²´ê° ì¤‘ì‹¬, ê³¼ì¥ ê¸ˆì§€)",
      "one_line": "ì§§ì€ í•œì¤„ ì†Œê°œ (ì¹œêµ¬í†¤)",
      "hashtags": ["#...","#..."],
      "matched_conditions": ["ì‚¬ìš©ì ì¡°ê±´ ì¤‘ ì‹¤ì œë¡œ ë°˜ì˜í•œ ê²ƒ"],
      "reason": "ì™œ ì¶”ì²œì¸ì§€ 2~3ë¬¸ì¥(í›„ë³´ ë°ì´í„° ê¸°ë°˜, ì—†ëŠ” ì •ë³´ ìƒìƒ ê¸ˆì§€)"%s
    }
  ]
}
""" % (',\n      "phase": "1ì°¨"  // split ëª¨ë“œì¼ ë•Œë§Œ. "1ì°¨" ë˜ëŠ” "2ì°¨"' if split_12 else "")

    extra_rules = ""
    if split_12:
        extra_rules = """
ì¶”ê°€ ê·œì¹™:
- ì§€ê¸ˆì€ '1ì°¨Â·2ì°¨'ë¥¼ ë‚˜ëˆ ì„œ ì¶”ì²œ.
- picks ì´ 3ê°œ ìœ ì§€.
- phase í¬í•¨:
  - 1ì°¨ 2ê°œ
  - 2ì°¨ 1ê°œ
"""

    prompt = f"""
ë„ˆëŠ” 'ê²°ì • ë©”ì´íŠ¸'ë‹¤.
ì‚¬ìš©ì ì¡°ê±´ì— ë§ì¶° ì•„ë˜ í›„ë³´ ì¤‘ BEST 3ê³³ë§Œ ê³¨ë¼ë¼.

{schema_hint}

ì¤‘ìš” ê·œì¹™:
- matched_conditionsëŠ” 'ì‚¬ìš©ìê°€ ë§í•œ ì¡°ê±´/í•„í„°/ì§ˆë¬¸ ë‹µë³€'ì—ì„œë§Œ ë½‘ì•„ë¼.
- hashtagsëŠ” ì‚¬ìš©ì ì¡°ê±´ ê¸°ë°˜ìœ¼ë¡œ ë¨¼ì € ë§Œë“¤ê³ , ë¶€ì¡±í•˜ë©´ categoryë¡œ ë³´ì¶©.
- í•´ì‹œíƒœê·¸ëŠ” 4~6ê°œ
- ê³¼ì¥ ê¸ˆì§€ ('ë¬´ì¡°ê±´', 'ìµœê³ ', 'ì™„ë²½' ê¸ˆì§€)
- í›„ë³´ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œë§Œ ë§í•˜ê¸° (ì—†ëŠ” ì •ë³´ ìƒìƒ ê¸ˆì§€)
- picksëŠ” ë°˜ë“œì‹œ 3ê°œ
- scene_feelì€ "ì‹¤ë‚´ ì¢Œì„ ê°„ê²©/ì¡°ëª…/ì‚¬ì§„ ë¶„ì„"ì²˜ëŸ¼ ë‹¨ì • ê¸ˆì§€. 'ì²´ê°'ë§Œ.
{extra_rules}

[ì‚¬ìš©ì ì¡°ê±´]
{json.dumps(conditions, ensure_ascii=False, indent=2)}

[í›„ë³´ ëª©ë¡]
{json.dumps(compact, ensure_ascii=False, indent=2)}
"""

    def call_llm(extra_msg=None, temp=0.35):
        msgs = [{"role": "user", "content": prompt}]
        if extra_msg:
            msgs.append({"role": "user", "content": extra_msg})
        return client.chat.completions.create(
            model="gpt-4o-mini",
            messages=msgs,
            temperature=temp,
            response_format={"type": "json_object"},
        )

    res = call_llm(temp=0.35)
    raw = (res.choices[0].message.content or "").strip()
    st.session_state.debug_raw_rerank = raw
    data = safe_json_load(raw) or extract_first_json_object(raw)

    if data is None or "picks" not in data:
        res2 = call_llm(extra_msg="ë°©ê¸ˆ ì¶œë ¥ì´ ìŠ¤í‚¤ë§ˆë¥¼ ì•ˆ ì§€ì¼°ì–´. JSONë§Œ ë‹¤ì‹œ ì¶œë ¥í•´.", temp=0.1)
        raw2 = (res2.choices[0].message.content or "").strip()
        st.session_state.debug_raw_rerank = raw2
        data = safe_json_load(raw2) or extract_first_json_object(raw2)

    if not isinstance(data, dict):
        return []
    picks = data.get("picks", [])
    return picks if isinstance(picks, list) else []

# -----------------------------
# Pre recommend text
# -----------------------------
def generate_pre_recommend_text(conditions, query):
    if client is None:
        return f"ì˜¤ì¼€ì´ã…‹ã…‹ **{query}**ë¡œ ë°”ë¡œ 3ê³³ ë½‘ì•„ë³¼ê²Œ ğŸ”"
    prompt = f"""
ë„ˆëŠ” ì‹ë‹¹ ì˜ ì•„ëŠ” ì¹œêµ¬ë‹¤.
ì¶”ì²œì„ ì‹œì‘í•˜ê¸° ì§ì „ì— í•˜ëŠ” ë©˜íŠ¸ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ë¼.
ì¡°ê±´ì„ ë°˜ì˜í•´ì„œ ë§í•´ë¼. ì´ëª¨ì§€ 1ê°œ ì •ë„.

ì¡°ê±´:
{json.dumps(conditions, ensure_ascii=False)}

ê²€ìƒ‰ í‚¤ì›Œë“œ:
{query}
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.85
    )
    return (res.choices[0].message.content or "").strip()

# -----------------------------
# Chat UI render history
# -----------------------------
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("ì˜ˆ: í™ëŒ€ ê·¼ì²˜ì—ì„œ 3ëª…ì´ ê°€ë³ê²Œ ìˆ  ë§ˆì‹¤ ê³³")

# -----------------------------
# Main interaction
# -----------------------------
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):

        if not openai_key or not kakao_key:
            st.warning("ì‚¬ì´ë“œë°”ì— OpenAI í‚¤ë‘ Kakao í‚¤ë¶€í„° ë„£ì–´ì¤˜!")
            st.stop()

        normalize_conditions(st.session_state.conditions)
        conditions = st.session_state.conditions
        cm = conditions["meta"]["common"]

        # intents
        if detect_skip_intent(user_input):
            conditions["meta"]["fast_mode"] = True
        if detect_expand_intent(user_input):
            cm["search_relax"] = min(3, int(cm.get("search_relax", 0)) + 1)

        # 1) Apply pending answer first
        if st.session_state.pending_question is not None:
            ok = apply_answer(conditions, st.session_state.pending_question, user_input)
            if ok:
                st.session_state.pending_question = None

        # 2) Patch merge
        patch = extract_conditions_patch(user_input, conditions)
        diversify = bool(patch.pop("diversify", False))
        exclude_last = bool(patch.pop("exclude_last", False))
        avoid_franchise = bool(patch.pop("avoid_franchise", False))
        conditions = merge_conditions(conditions, patch)
        st.session_state.conditions = conditions
        cm = conditions["meta"]["common"]

        # Debug
        with st.expander("ğŸ§¾ í˜„ì¬ ëˆ„ì  ì¡°ê±´(JSON)"):
            st.json(conditions)
            if debug_mode:
                st.markdown("**(ë””ë²„ê·¸) patch ì›ë¬¸**")
                st.code(st.session_state.debug_raw_patch)

        # 3) Next question
        next_q = get_next_question(conditions)

        if next_q and not (conditions["meta"].get("fast_mode") and next_q.get("key") not in ("location", "cannot_eat")):
            st.markdown(next_q["text"])
            st.session_state.messages.append({"role": "assistant", "content": next_q["text"]})
            st.session_state.pending_question = next_q
            st.stop()

        if not conditions.get("location"):
            msg = "ì¢‹ì•„! ê·¼ë° **ë™ë„¤/ì—­**ë¶€í„° ì•Œë ¤ì¤˜ì•¼ ë‚´ê°€ ë½‘ì•„ì£¼ì§€ ğŸ˜\nì˜ˆ: `í•©ì •`, `ì—°ë‚¨ë™`, `ê°•ë‚¨ì—­`"
            st.markdown(msg)
            st.session_state.messages.append({"role": "assistant", "content": msg})
            st.session_state.pending_question = {"scope": "common", "key": "location", "text": msg, "type": "free"}
            st.stop()

        # -----------------------------
        # Kakao search: bigger pool + center/radius/distance
        # -----------------------------
        transport = cm.get("transport") or "ìƒê´€ì—†ìŒ"
        location = conditions.get("location")

        center = get_location_center(location, kakao_key)
        cm["center_name"] = center.get("name") if center else None

        pool_radius_steps = [1600, 2500, 4000] if transport == "ì°¨" else [1200, 1800, 2500]

        def run_kakao_pooled(query_str: str):
            if not center:
                return kakao_keyword_search_paged(query_str, kakao_key, size=15, max_pages=3)
            final_docs = []
            for r in pool_radius_steps:
                docs = kakao_keyword_search_paged(
                    query_str, kakao_key,
                    x=center["x"], y=center["y"],
                    radius=r, sort="distance",
                    size=15, max_pages=3
                )
                final_docs = docs
                if len(docs) >= 25:
                    break
            return final_docs

        places = []
        used_query = None

        for _ in range(4):
            base_query = build_query(conditions)
            variants = make_query_variants(base_query, location, int(cm.get("search_relax", 0)))
            for q in variants:
                try:
                    docs = run_kakao_pooled(q)
                except Exception as e:
                    st.error(f"Kakao ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                    st.stop()
                if docs:
                    places = docs
                    used_query = q
                    break
            if places:
                break
            if int(cm.get("search_relax", 0)) < 3:
                cm["search_relax"] = int(cm.get("search_relax", 0)) + 1
            else:
                break

        if not places:
            msg = "í—‰â€¦ ì´ ì¡°ê±´ìœ¼ë¡œëŠ” ë”± ë§ëŠ” ë°ê°€ ì˜ ì•ˆ ì¡íˆë„¤ ğŸ¥²\nì¡°ê±´ì„ ì¡°ê¸ˆ ëŠìŠ¨í•˜ê²Œ í•´ì„œ ê·¼ì²˜ ìœ„ì£¼ë¡œ ë‹¤ì‹œ ë½‘ì•„ë³¼ê¹Œ?"
            st.markdown(msg)
            st.session_state.messages.append({"role": "assistant", "content": msg})
            st.stop()

        pre_text = generate_pre_recommend_text(conditions, used_query or build_query(conditions))
        st.markdown(pre_text)

        if debug_mode:
            st.caption(f"ğŸ” ì‚¬ìš©ëœ ê²€ìƒ‰ì–´: {used_query} (relax={cm.get('search_relax', 0)})")
            if center:
                st.caption(f"ğŸ“Œ ì¤‘ì‹¬ì¢Œí‘œ: {cm.get('center_name')}")

        # -----------------------------
        # Sort + exclude last + radius focus + attach meta
        # -----------------------------
        if center:
            places = sort_places_for_transport(places, center, transport)

        if diversify or exclude_last:
            places = filter_places(places, st.session_state.last_picks_ids)

        focused = []
        if center:
            for r in ([1200, 1800, 2500] if transport != "ì°¨" else [1600, 2500, 4000]):
                within = filter_places_by_radius(places, center, r)
                if len(within) >= 12:
                    focused = within
                    break
            if not focused:
                focused = places
        else:
            focused = places

        focused = attach_distance_meta(focused, center)

        # -----------------------------
        # Filters BEFORE LLM
        # -----------------------------
        kind = infer_place_kind(conditions)
        filtered = filter_by_kind(focused, kind)
        filtered = mild_context_filter(filtered, conditions)
        filtered = filter_franchise(filtered, avoid_franchise)

        candidates = filtered[:25]

        if debug_mode:
            with st.expander("ğŸ§ª (ë””ë²„ê·¸) í›„ë³´ í’€"):
                sample = [{
                    "name": p.get("place_name"),
                    "cat": p.get("category_name"),
                    "walk_min": p.get("_walk_min"),
                    "dist_m": p.get("_distance_m")
                } for p in candidates[:15]]
                st.json({
                    "kind": kind,
                    "raw_places": len(places),
                    "focused": len(focused),
                    "after_filters": len(filtered),
                    "candidates": len(candidates),
                    "sample": sample
                })

        # -----------------------------
        # Rerank
        # -----------------------------
        picks = rerank_and_format(conditions, candidates)

        if debug_mode:
            with st.expander("ğŸ¤– (ë””ë²„ê·¸) rerank LLM ì›ë¬¸"):
                st.code(st.session_state.debug_raw_rerank)

        picks = ensure_3_picks(picks, candidates)

        # -----------------------------
        # Render
        # -----------------------------
        kakao_map = {p.get("id"): p for p in candidates if p.get("id")}

        st.markdown("---")
        st.subheader("ğŸ½ï¸ ë”± 3ê³³ë§Œ ê³¨ëì–´")
        st.caption("â€» ì •ë‹µ ì¶”ì²œì´ ì•„ë‹ˆë¼, ê³ ë¯¼ ë²”ìœ„ë¥¼ 3ê°œë¡œ ì¤„ì—¬ì£¼ëŠ” í›„ë³´ ì••ì¶•ì´ì•¼.")

        cols = st.columns(3)
        current_pick_ids = []
        center_name = cm.get("center_name") or "ê¸°ì¤€ì "

        for i, pick in enumerate(picks[:3]):
            pid = pick.get("id")
            place = kakao_map.get(pid)
            if not place:
                continue
            current_pick_ids.append(pid)

            with cols[i]:
                name = place.get("place_name")
                addr = place.get("road_address_name") or place.get("address_name")
                url = place.get("place_url")
                category = place.get("category_name")

                phase = pick.get("phase")
                if phase:
                    st.markdown(f"**[{phase}]**")

                st.markdown(f"### {i+1}. {name}")
                st.caption(category or "")
                st.write(f"ğŸ“ {addr}")

                walk_min = place.get("_walk_min")
                if isinstance(walk_min, int) and walk_min < 180:
                    st.caption(f"ğŸš¶ {center_name} ê¸°ì¤€ ë„ë³´ ì•½ {walk_min}ë¶„")

                scene = (pick.get("scene_feel") or "").strip()
                if scene:
                    st.markdown("ğŸ§  **ì´ëŸ° ìë¦¬ ëŠë‚Œ**")
                    st.write(scene)

                st.markdown(f"**{pick.get('one_line','')}**")

                matched = pick.get("matched_conditions", [])
                if matched:
                    st.markdown("**ë°˜ì˜í•œ ì¡°ê±´**")
                    st.markdown(" Â· ".join([f"`{m}`" for m in matched]))

                tags = pick.get("hashtags", [])
                if tags:
                    st.markdown(" ".join(tags))

                st.markdown("**ì™œ ì—¬ê¸°ëƒë©´â€¦**")
                st.write(pick.get("reason", ""))

                if url:
                    st.link_button("ì¹´ì¹´ì˜¤ë§µì—ì„œ ë³´ê¸°", url)

        st.session_state.last_picks_ids = current_pick_ids

        # optional log
        try:
            with open("decision_mate_logs.jsonl", "a", encoding="utf-8") as f:
                f.write(json.dumps({
                    "ts": int(time.time()),
                    "query_used": used_query,
                    "kind": kind,
                    "avoid_franchise": avoid_franchise,
                    "center": cm.get("center_name"),
                    "conditions": conditions,
                    "picks": picks,
                    "place_ids": current_pick_ids,
                    "pool_counts": {
                        "raw_places": len(places),
                        "focused": len(focused),
                        "after_filters": len(filtered),
                        "candidates": len(candidates),
                    }
                }, ensure_ascii=False) + "\n")
        except Exception:
            pass

        final = "ë! ğŸ˜\nì…‹ ì¤‘ì— í•˜ë‚˜ ê³ ë¥´ê±°ë‚˜, 'ëŒ€í™” ë” ë˜ëŠ” ìª½', 'ìŒì‹ ë” í™•ì‹¤í•œ ìª½', 'í”„ì°¨ ë¹¼ì¤˜', 'ë°©ê¸ˆ ì¶”ì²œ ì œì™¸í•˜ê³  ë‹¤ì‹œ' ì´ëŸ° ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì¼œë„ ë¼."
        st.session_state.messages.append({"role": "assistant", "content": final})
        st.markdown(final)
