# decision_mate_app_final.py
# Streamlit prototype for "ê²°ì • ë©”ì´íŠ¸" (Decision Mate)
# - Multi-step chat questions (common + mode)
# - Kakao Local Keyword Search (paged, center/radius/sort=distance) => bigger candidate pool
# - Rule-based kind filter BEFORE LLM (meal/cafe/drink) to prevent cafe when "ì‹ì‚¬"
# - Distance + walk minutes badge (center station preferred)
# - Transport weighting (car => parking-signal light bonus)
# - Relax search tokens (0~3) + "ê·¼ì²˜/ì£¼ë³€" variants
# - Always returns 3 picks (fallback if LLM fails)

import json
import re
import time
import math
import requests
import streamlit as st
from openai import OpenAI
from math import radians, sin, cos, sqrt, atan2

# -----------------------------
# App config
# -----------------------------
st.set_page_config(page_title="ê²°ì • ë©”ì´íŠ¸", page_icon="ğŸ½ï¸", layout="wide")
st.title("ğŸ½ï¸ ê²°ì • ë©”ì´íŠ¸ (Decision Mate)")
st.caption("ì‹ë‹¹/ì¹´í˜/ìˆ ì§‘â€¦ â€˜ì¥ì†Œ í”½ìŠ¤â€™ê°€ í•„ìš”í•  ë•Œ, ì¡°ê±´ ì •ë¦¬ + 3ê³³ë§Œ ë”± ì¶”ì²œ")

# -----------------------------
# Sidebar
# -----------------------------
st.sidebar.header("ğŸ”‘ API ì„¤ì •")
openai_key = st.sidebar.text_input("OpenAI API Key", type="password")
kakao_key = st.sidebar.text_input("Kakao Local REST API Key", type="password")

st.sidebar.markdown("---")
debug_mode = st.sidebar.checkbox("ğŸ› ï¸ ë””ë²„ê·¸ ëª¨ë“œ(LLM ì›ë¬¸ ì¶œë ¥)", value=False)

client = OpenAI(api_key=openai_key) if openai_key else None

# -----------------------------
# Session State
# -----------------------------
if "messages" not in st.session_state:
    st.session_state.messages = [{
        "role": "assistant",
        "content": "ì˜¤ì¼€ì´ ğŸ˜\nì˜¤ëŠ˜ ì–´ë””ì„œ ëˆ„êµ¬ë‘ ë­ ë¨¹ì„ì§€ ë‚´ê°€ ë”± ì •í•´ì¤„ê²Œ.\nì¼ë‹¨ **ì–´ëŠ ë™ë„¤/ì—­ ê·¼ì²˜**ì—ì„œ ì°¾ì„ê¹Œ?"
    }]

if "conditions" not in st.session_state:
    st.session_state.conditions = {
        "location": None,     # ex) ì‹ ì´Œ / ì‹ ì´Œì—­
        "food_type": None,    # ex) ì–‘ì‹ / ì¼ì‹ / í•œì‹ ...
        "purpose": None,
        "people": None,
        "mood": None,
        "constraints": {
            "cannot_eat": [],
            "avoid_recent": [],
            "need_parking": None
        },
        "meta": {
            "context_mode": None,       # íšŒì‚¬ íšŒì‹ / ì¹œêµ¬ / ë‹¨ì²´ ëª¨ì„ / ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ… / í˜¼ë°¥ / ê°€ì¡± / None
            "people_count": None,       # int
            "budget_tier": "ìƒê´€ì—†ìŒ",  # ê°€ì„±ë¹„ / ë³´í†µ / ì¡°ê¸ˆ íŠ¹ë³„ / ìƒê´€ì—†ìŒ
            "answers": {},              # mode ì§ˆë¬¸ ë‹µ
            "common": {
                "cannot_eat_done": False,   # ëª» ë¨¹ëŠ” ê²ƒ ì§ˆë¬¸ ì™„ë£Œ ì—¬ë¶€
                "alcohol_level": None,      # ì—†ìŒ / ê°€ë³ê²Œ / ìˆ  ì¤‘ì‹¬
                "stay_duration": None,      # ë¹ ë¥´ê²Œ / ì ë‹¹íˆ / ì˜¤ë˜
                "transport": None,          # ì°¨ / ëŒ€ì¤‘êµí†µ / ìƒê´€ì—†ìŒ
                "alcohol_plan": None,       # (ìˆ  ì¤‘ì‹¬) í•œ ê³³ / ë‚˜ëˆŒ ìˆ˜ë„ / ëª¨ë¥´ê² ìŒ
                "alcohol_type": None,       # (ìˆ  ì¤‘ì‹¬) ì†Œì£¼/ë§¥ì£¼/ì™€ì¸/ìƒê´€ì—†ìŒ
                "search_relax": 0,          # 0~3: ê²€ìƒ‰ í† í° ì™„í™”
                "center_name": None,        # ì˜ˆ: "ì‹ ì´Œì—­"
            },
            "fast_mode": False           # "ê·¸ëƒ¥ ì¶”ì²œí•´" ìŠ¤í‚µ ì˜ë„
        }
    }

if "last_picks_ids" not in st.session_state:
    st.session_state.last_picks_ids = []

if "pending_question" not in st.session_state:
    st.session_state.pending_question = None  # {"scope": "...", "key": "...", "text": "...", "type": "..."}

if "debug_raw_patch" not in st.session_state:
    st.session_state.debug_raw_patch = ""

if "debug_raw_rerank" not in st.session_state:
    st.session_state.debug_raw_rerank = ""

if "loc_center_cache" not in st.session_state:
    st.session_state.loc_center_cache = {}  # {"ì‹ ì´Œ": {"x":..,"y":..,"name":..}}

# -----------------------------
# Helpers
# -----------------------------
def safe_json_load(text: str):
    try:
        return json.loads(text)
    except Exception:
        return None

def extract_first_json_object(text: str):
    m = re.search(r"\{.*\}", text, re.DOTALL)
    if not m:
        return None
    return safe_json_load(m.group(0))

def normalize_conditions(cond: dict):
    if not isinstance(cond, dict):
        return

    if "constraints" not in cond or not isinstance(cond["constraints"], dict):
        cond["constraints"] = {"cannot_eat": [], "avoid_recent": [], "need_parking": None}

    c = cond["constraints"]
    if "cannot_eat" not in c or not isinstance(c["cannot_eat"], list):
        c["cannot_eat"] = []
    if "avoid_recent" not in c or not isinstance(c["avoid_recent"], list):
        c["avoid_recent"] = []
    if "need_parking" not in c:
        c["need_parking"] = None

    if "meta" not in cond or not isinstance(cond["meta"], dict):
        cond["meta"] = {}

    m = cond["meta"]
    m.setdefault("context_mode", None)
    m.setdefault("people_count", None)
    m.setdefault("budget_tier", "ìƒê´€ì—†ìŒ")
    m.setdefault("answers", {})
    m.setdefault("fast_mode", False)
    if "common" not in m or not isinstance(m["common"], dict):
        m["common"] = {}

    cm = m["common"]
    cm.setdefault("cannot_eat_done", False)
    cm.setdefault("alcohol_level", None)
    cm.setdefault("stay_duration", None)
    cm.setdefault("transport", None)
    cm.setdefault("alcohol_plan", None)
    cm.setdefault("alcohol_type", None)
    cm.setdefault("search_relax", 0)
    cm.setdefault("center_name", None)

def merge_conditions(base: dict, patch: dict):
    if not isinstance(patch, dict):
        return base

    if "constraints" in patch and isinstance(patch["constraints"], dict):
        base_constraints = base.get("constraints", {}) or {}
        for k, v in patch["constraints"].items():
            if v is None:
                continue
            base_constraints[k] = v
        base["constraints"] = base_constraints

    if "meta" in patch and isinstance(patch["meta"], dict):
        base_meta = base.get("meta", {}) or {}
        for k, v in patch["meta"].items():
            if v is None:
                continue
            base_meta[k] = v
        base["meta"] = base_meta

    for k, v in patch.items():
        if k in ("constraints", "meta"):
            continue
        if v is None:
            continue
        base[k] = v

    normalize_conditions(base)
    return base

def detect_skip_intent(text: str) -> bool:
    t = (text or "").strip()
    if not t:
        return False
    keywords = ["ê·¸ëƒ¥ ì¶”ì²œ", "ê± ì¶”ì²œ", "ë¹¨ë¦¬ ì¶”ì²œ", "ìŠ¤í‚µ", "ì•„ë¬´ê±°ë‚˜", "ëê³  ì¶”ì²œ", "ë°”ë¡œ ì¶”ì²œ", "ì¶”ì²œí•´ì¤˜"]
    return any(k in t for k in keywords)

def detect_expand_intent(text: str) -> bool:
    t = (text or "").strip()
    if not t:
        return False
    keywords = ["ë„“í˜€", "ë„“í˜€ë´", "ë²”ìœ„", "ì¡°ê¸ˆë§Œ ë„“í˜€", "ê·¼ì²˜ë¡œ", "ì£¼ë³€ìœ¼ë¡œ"]
    return any(k in t for k in keywords)

# -----------------------------
# Sidebar: Mode / People / Budget
# -----------------------------
st.sidebar.markdown("---")
st.sidebar.header("ğŸ§­ ìƒí™© ì„¤ì •")

MODE_OPTIONS = [
    "ì„ íƒ ì•ˆ í•¨",
    "íšŒì‚¬ íšŒì‹",
    "ì¹œêµ¬",
    "ë‹¨ì²´ ëª¨ì„",
    "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…",
    "í˜¼ë°¥",
    "ê°€ì¡±",
]
BUDGET_OPTIONS = ["ìƒê´€ì—†ìŒ", "ê°€ì„±ë¹„", "ë³´í†µ", "ì¡°ê¸ˆ íŠ¹ë³„"]

selected_mode = st.sidebar.selectbox("ìƒí™© ëª¨ë“œ", MODE_OPTIONS, index=0)
people_count = st.sidebar.number_input("ì¸ì›", min_value=1, max_value=30, value=2, step=1)
budget_tier = st.sidebar.radio("ì˜ˆì‚°ëŒ€(1ì¸)", BUDGET_OPTIONS, index=0)

normalize_conditions(st.session_state.conditions)
meta = st.session_state.conditions["meta"]
meta["context_mode"] = None if selected_mode == "ì„ íƒ ì•ˆ í•¨" else selected_mode
meta["people_count"] = int(people_count) if people_count else None
meta["budget_tier"] = budget_tier

# -----------------------------
# Kakao Local API
# -----------------------------
def kakao_keyword_search(query: str, kakao_rest_key: str, size: int = 15, page: int = 1,
                        x: str | None = None, y: str | None = None,
                        radius: int | None = None, sort: str | None = None):
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {kakao_rest_key}"}
    params = {"query": query, "size": size, "page": page}
    # Kakao: x=longitude, y=latitude
    if x and y:
        params["x"] = x
        params["y"] = y
    if radius is not None:
        params["radius"] = radius
    if sort:
        params["sort"] = sort  # "distance" or "accuracy"

    res = requests.get(url, headers=headers, params=params, timeout=10)
    res.raise_for_status()
    return res.json()

def kakao_keyword_search_paged(query: str, kakao_rest_key: str,
                              x: str | None = None, y: str | None = None,
                              radius: int | None = None,
                              sort: str | None = None,
                              size: int = 15, max_pages: int = 3):
    """
    ì •ì±…/ìŠ¤í™ìƒ size=15ê°€ ì¼ë°˜ì ìœ¼ë¡œ ìµœëŒ€. pageë¥¼ ëŒë ¤ ìµœëŒ€ 45ê°œê¹Œì§€ í’€ì„ í™•ë³´.
    """
    all_docs = []
    for page in range(1, max_pages + 1):
        data = kakao_keyword_search(query, kakao_rest_key, size=size, page=page, x=x, y=y, radius=radius, sort=sort)
        docs = data.get("documents", [])
        meta = data.get("meta", {}) or {}
        all_docs.extend(docs)
        if meta.get("is_end") is True:
            break

    # Dedup by id
    seen = set()
    uniq = []
    for d in all_docs:
        pid = d.get("id")
        if not pid or pid in seen:
            continue
        seen.add(pid)
        uniq.append(d)
    return uniq

# -----------------------------
# Geo / Walk / Transport scoring
# -----------------------------
def haversine_m(x1, y1, x2, y2):
    lon1, lat1, lon2, lat2 = map(radians, [float(x1), float(y1), float(x2), float(y2)])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return 6371000 * c

def estimate_walk_minutes(distance_m: float, speed_m_per_min: float = 80.0) -> int:
    if distance_m is None:
        return 999
    if distance_m >= 10**11:
        return 999
    return max(1, int(math.ceil(distance_m / speed_m_per_min)))

def place_distance_m(place: dict, center: dict):
    if not center or not center.get("x") or not center.get("y"):
        return None
    px, py = place.get("x"), place.get("y")
    if not px or not py:
        return None
    return haversine_m(center["x"], center["y"], px, py)

def get_location_center(location: str, kakao_rest_key: str):
    """
    locationì´ 'ë™ë„¤'ë©´ 'ë™ë„¤ì—­'ì„ ìš°ì„  ì‹œë„í•´ ì¤‘ì‹¬ì¢Œí‘œ í™•ë³´.
    (í‚¤ì›Œë“œ ê²€ìƒ‰ 1ê°œ ê²°ê³¼ì˜ ì¢Œí‘œë¥¼ centerë¡œ ì‚¬ìš©)
    """
    loc = (location or "").strip()
    if not loc:
        return None

    cache = st.session_state.loc_center_cache
    if loc in cache:
        return cache[loc]

    candidates = []
    if "ì—­" in loc:
        candidates.append(loc)
    else:
        candidates.append(f"{loc}ì—­")
        candidates.append(loc)

    for cand in candidates:
        try:
            docs = kakao_keyword_search_paged(cand, kakao_rest_key, size=15, max_pages=1)
            if not docs:
                continue
            d = docs[0]
            center = {"x": d.get("x"), "y": d.get("y"), "name": cand}
            if center["x"] and center["y"]:
                cache[loc] = center
                return center
        except Exception:
            continue
    return None

def filter_places_by_radius(places: list, center: dict, radius_m: int):
    if not center or not center.get("x") or not center.get("y"):
        return places
    out = []
    cx, cy = center["x"], center["y"]
    for p in places:
        px, py = p.get("x"), p.get("y")
        if not px or not py:
            continue
        if haversine_m(cx, cy, px, py) <= radius_m:
            out.append(p)
    return out

def parking_signal_score(place: dict) -> int:
    # v1 heuristic only
    text = f"{place.get('place_name','')} {place.get('category_name','')}".lower()
    score = 0
    if "ì£¼ì°¨" in text or "parking" in text or "ë°œë ›" in text:
        score += 3
    big_like = ["ë°±í™”ì ", "ëª°", "ì•„ìš¸ë ›", "í˜¸í…”", "ë¦¬ì¡°íŠ¸", "ì›¨ë”©", "ì»¨ë²¤ì…˜", "ëŒ€í˜•"]
    if any(k in text for k in big_like):
        score += 1
    alley_like = ["í¬ì°¨", "í˜¸í”„", "ì´ìì¹´ì•¼", "ë°”", "ì£¼ì "]
    if any(k in text for k in alley_like):
        score -= 1
    return score

def sort_places_for_transport(places: list, center: dict, transport: str):
    """
    - ëŒ€ì¤‘êµí†µ: ê±°ë¦¬ ìš°ì„ 
    - ì°¨: ê±°ë¦¬ ê¸°ë°˜ì´ì§€ë§Œ, ì£¼ì°¨ ì‹ í˜¸ ì•½ê°€ì (ê°€ê¹Œìš´ ê±°ë¦¬ëŒ€ì—ì„œë§Œ ì‚´ì§ ìœ ë¦¬)
    """
    if not center or not center.get("x") or not center.get("y"):
        return places
    cx, cy = center["x"], center["y"]
    scored = []
    for p in places:
        px, py = p.get("x"), p.get("y")
        if px and py:
            dist = haversine_m(cx, cy, px, py)
        else:
            dist = 10**12
        park = parking_signal_score(p) if transport == "ì°¨" else 0
        score = dist - (park * 120)  # 1ì ë‹¹ 120m ê°€ì 
        scored.append((score, dist, p))
    scored.sort(key=lambda t: (t[0], t[1]))
    return [p for _, __, p in scored]

def attach_distance_meta(places: list, center: dict):
    if center:
        for p in places:
            d = place_distance_m(p, center)
            p["_distance_m"] = d if d is not None else 10**12
            p["_walk_min"] = estimate_walk_minutes(p["_distance_m"])
    else:
        for p in places:
            p["_distance_m"] = 10**12
            p["_walk_min"] = None
    return places

# -----------------------------
# Kind filter BEFORE LLM (prevents cafe when meal)
# -----------------------------
def infer_place_kind_from_conditions(conditions: dict) -> str:
    cm = conditions["meta"]["common"]
    alcohol = cm.get("alcohol_level")
    stay = cm.get("stay_duration")

    # ìˆ ì´ ìˆìœ¼ë©´ drink ìš°ì„ 
    if alcohol in ("ê°€ë³ê²Œ", "ìˆ  ì¤‘ì‹¬"):
        return "drink"

    # ì˜¤ë˜ ë¨¸ë¬´ë¥´ë©´ ì¹´í˜ ì„±í–¥
    if stay == "ì˜¤ë˜":
        return "cafe"

    # ê¸°ë³¸ì€ ì‹ì‚¬
    return "meal"

def filter_by_kind(places: list, kind: str):
    def cat(p): return (p.get("category_name") or "")

    if kind == "meal":
        banned = ["ì¹´í˜", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì•„ì´ìŠ¤í¬ë¦¼"]
        out = [p for p in places if not any(b in cat(p) for b in banned)]
        return out if len(out) >= 10 else places

    if kind == "cafe":
        allow = ["ì¹´í˜", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì•„ì´ìŠ¤í¬ë¦¼"]
        out = [p for p in places if any(a in cat(p) for a in allow)]
        return out if len(out) >= 10 else places

    if kind == "drink":
        allow = ["ìˆ ", "ì£¼ì ", "í˜¸í”„", "ì´ìì¹´ì•¼", "ë°”", "í¬ì°¨", "í"]
        out = [p for p in places if any(a in cat(p) for a in allow)]
        return out if len(out) >= 10 else places

    return places

# -----------------------------
# Simple franchise filter (optional)
# -----------------------------
DEFAULT_FRANCHISE = [
    "ì‰ì´í¬ì‰‘", "ìŠ¤íƒ€ë²…ìŠ¤", "íˆ¬ì¸", "ì´ë””ì•¼", "ë¹½ë‹¤ë°©", "ë©”ê°€ì»¤í”¼", "ì»´í¬ì¦ˆ",
    "íŒŒë¦¬ë°”ê²Œëœ¨", "ëšœë ˆì¥¬ë¥´", "ë²„ê±°í‚¹", "ë§¥ë„ë‚ ë“œ", "ë¡¯ë°ë¦¬ì•„", "kfc", "ì„œë¸Œì›¨ì´"
]

def filter_franchise(places: list, enabled: bool):
    if not enabled:
        return places
    out = []
    for p in places:
        name = (p.get("place_name") or "").lower()
        if any(f.lower() in name for f in DEFAULT_FRANCHISE):
            continue
        out.append(p)
    return out if len(out) >= 10 else places

# -----------------------------
# 1) Latest utterance -> condition PATCH (LLM)
# -----------------------------
def extract_conditions_patch(latest_user_text: str, current_conditions: dict):
    if client is None:
        return {}

    system = """
ë„ˆëŠ” 'ê²°ì • ë©”ì´íŠ¸'ì˜ ì¡°ê±´ ì—…ë°ì´íŠ¸ ì—”ì§„ì´ë‹¤.

[ëª©í‘œ]
ì‚¬ìš©ìì˜ 'ìµœì‹  ë°œí™”'ë¥¼ ë³´ê³ ,
ê¸°ì¡´ ì¡°ê±´ì—ì„œ ë³€ê²½/ì¶”ê°€ëœ ê°’ë§Œ JSON PATCH í˜•íƒœë¡œ ì¶œë ¥í•´ë¼.

[ì¤‘ìš”]
- ë°˜ë“œì‹œ JSON ì˜¤ë¸Œì íŠ¸ë§Œ ì¶œë ¥í•´ë¼.
- ì‚¬ìš©ìê°€ ì–¸ê¸‰í•˜ì§€ ì•Šì€ í•„ë“œëŠ” ì¶œë ¥í•˜ì§€ ë§ˆë¼.
- "nullë¡œ ì´ˆê¸°í™”" ê°™ì€ í–‰ë™ ê¸ˆì§€.
- constraints ì•ˆì˜ ë¦¬ìŠ¤íŠ¸ëŠ” ì‚¬ìš©ìê°€ ìƒˆë¡œ ì–¸ê¸‰í•œ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸í•´ë¼.
- ì‚¬ìš©ìê°€ "ì•„ê¹Œ ì¶”ì²œ ë§ê³  ë‹¤ë¥¸ ë°"ë¼ê³  í•˜ë©´ diversify=true ë¥¼ ë„£ì–´ë¼.
- ì‚¬ìš©ìê°€ "ë°©ê¸ˆ ì¶”ì²œí•œ ë° ì œì™¸" ê°™ì€ ì˜ë¯¸ë©´ exclude_last=true ë¥¼ ë„£ì–´ë¼.

ê°€ëŠ¥í•œ í•„ë“œ:
- location, food_type, purpose, people, mood
- constraints.cannot_eat (list[str])
- constraints.avoid_recent (list[str])
- constraints.need_parking (true/false)
- diversify (true/false)
- exclude_last (true/false)
- avoid_franchise (true/false)
"""

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": f"[ê¸°ì¡´ ì¡°ê±´]\n{json.dumps(current_conditions, ensure_ascii=False)}"},
            {"role": "user", "content": f"[ìµœì‹  ë°œí™”]\n{latest_user_text}"},
        ],
        temperature=0.2,
        response_format={"type": "json_object"},
    )

    raw = (res.choices[0].message.content or "").strip()
    st.session_state.debug_raw_patch = raw

    patch = safe_json_load(raw) or extract_first_json_object(raw)
    if not isinstance(patch, dict):
        return {}
    return patch

# -----------------------------
# Question tree: common + mode
# -----------------------------
MODE_REQUIRED_QUESTIONS = {
    "íšŒì‚¬ íšŒì‹": [
        {"key": "work_tone", "text": "ë¶„ìœ„ê¸°ëŠ” **ê°€ë²¼ìš´ íšŒì‹**ì´ì•¼, ì•„ë‹ˆë©´ **ì •ëˆëœ ìë¦¬** ìª½?", "type": "enum"},
    ],
    "ì¹œêµ¬": [
        {"key": "friend_focus", "text": "ì˜¤ëŠ˜ì€ **ìˆ˜ë‹¤/ëŒ€í™” ì¤‘ì‹¬**ì´ì•¼, ì•„ë‹ˆë©´ **ë¨¹ëŠ” ì¬ë¯¸ ì¤‘ì‹¬**ì´ì•¼? ğŸ˜†", "type": "enum"},
    ],
    "ë‹¨ì²´ ëª¨ì„": [
        {"key": "group_purpose", "text": "ëª¨ì„ ëª©ì ì´ ë­ì•¼? (**ë°¥+ìˆ˜ë‹¤ / ìŠ¤í„°ë””+ì–˜ê¸° / ì¶•í•˜/í–‰ì‚¬**)", "type": "enum"},
    ],
    "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…": [
        {"key": "dating_stage", "text": "ì²« ë§Œë‚¨(ì–´ìƒ‰í•œ ë‹¨ê³„)ì´ì•¼, ì•„ë‹ˆë©´ ì¢€ ìµìˆ™í•œ ì‚¬ì´ì•¼? (**ì²«/ì–´ìƒ‰ / ìµìˆ™**)", "type": "enum"},
    ],
    "í˜¼ë°¥": [
        {"key": "solo_weight", "text": "ì˜¤ëŠ˜ì€ ë“ ë“ í•˜ê²Œ ë¨¹ì„ë˜, ê°€ë³ê²Œ ë¨¹ì„ë˜? (**ë“ ë“  / ê°€ë³ê²Œ**)", "type": "enum"},
    ],
    "ê°€ì¡±": [
        {"key": "family_member", "text": "êµ¬ì„±ì›ì— **ì•„ì´/ì–´ë¥¸(ì—°ì„¸)** ìˆì–´? (**ì•„ì´ / ì–´ë¥¸ / ë‘˜ ë‹¤ / ì—†ìŒ**)", "type": "enum"},
    ],
}

def get_next_mode_question(conditions: dict):
    normalize_conditions(conditions)
    mode = conditions["meta"]["context_mode"]
    if not mode or mode not in MODE_REQUIRED_QUESTIONS:
        return None
    answers = conditions["meta"]["answers"]
    for q in MODE_REQUIRED_QUESTIONS[mode]:
        if answers.get(q["key"]) is None:
            return {"scope": "mode", **q}
    return None

def get_next_common_question(conditions: dict):
    normalize_conditions(conditions)
    cm = conditions["meta"]["common"]

    if not conditions.get("location"):
        return {"scope": "common", "key": "location", "text": "ì˜¤ì¼€ì´! **ì–´ëŠ ë™ë„¤/ì—­ ê·¼ì²˜**ì—ì„œ ì°¾ì„ê¹Œ? ğŸ“", "type": "free"}

    if not cm.get("cannot_eat_done", False):
        return {"scope": "common", "key": "cannot_eat", "text": "ëª» ë¨¹ëŠ” ê±° ìˆì–´? (ì•Œë ˆë¥´ê¸°/ê·¹í˜ í¬í•¨) ì—†ìœ¼ë©´ **ì—†ìŒ**ì´ë¼ê³  í•´ì¤˜ ğŸ™…", "type": "list_or_none"}

    if conditions["meta"].get("fast_mode"):
        return None

    if cm.get("alcohol_level") is None:
        return {"scope": "common", "key": "alcohol_level", "text": "ì˜¤ëŠ˜ ìˆ ì€ ì–´ë•Œ? **ì—†ìŒ / ê°€ë³ê²Œ / ìˆ  ì¤‘ì‹¬** ğŸ»", "type": "enum_alcohol"}

    if cm.get("stay_duration") is None:
        return {"scope": "common", "key": "stay_duration", "text": "ì–¼ë§ˆë‚˜ ìˆì„ ê±°ì•¼? **ë¹ ë¥´ê²Œ / ì ë‹¹íˆ / ì˜¤ë˜** â±ï¸", "type": "enum_stay"}

    if cm.get("transport") is None:
        return {"scope": "common", "key": "transport", "text": "ì´ë™ìˆ˜ë‹¨ì€ ë­ì•¼? **ì°¨ / ëŒ€ì¤‘êµí†µ / ìƒê´€ì—†ìŒ** ğŸ§­", "type": "enum_transport"}

    if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_plan") is None:
        return {"scope": "common", "key": "alcohol_plan",
                "text": "ì˜¤ì¼€ì´ ìˆ  ì¤‘ì‹¬ ğŸ‘ í•œ ê³³ì—ì„œ ì­‰ ê°ˆ ê±°ì•¼, ì•„ë‹ˆë©´ **1ì°¨Â·2ì°¨ ë‚˜ëˆŒ ìˆ˜ë„** ìˆì–´? (**í•œ ê³³ / ë‚˜ëˆŒ ìˆ˜ë„ / ëª¨ë¥´ê² ìŒ**)",
                "type": "enum_alcohol_plan"}

    if cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_plan") in ("í•œ ê³³", "ë‚˜ëˆŒ ìˆ˜ë„") and cm.get("alcohol_type") is None:
        return {"scope": "common", "key": "alcohol_type",
                "text": "ì£¼ë¡œ ë­ ë§ˆì‹¤ ìƒê°ì´ì•¼? **ì†Œì£¼ / ë§¥ì£¼ / ì™€ì¸ / ìƒê´€ì—†ìŒ** ğŸ¶",
                "type": "enum_alcohol_type"}

    return None

def get_next_question(conditions: dict):
    q = get_next_common_question(conditions)
    if q:
        return q
    return get_next_mode_question(conditions)

# -----------------------------
# Answer parsing & apply (prevents loop)
# -----------------------------
def parse_list_or_none(text: str):
    t = (text or "").strip()
    if not t:
        return None
    if "ì—†" in t:
        return []
    parts = re.split(r"[,\n/]+", t)
    out = []
    for p in parts:
        p = p.strip()
        if not p:
            continue
        p = re.sub(r"(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ë§Œ|ë¹¼ê³ |ë¹¼ì¤˜)$", "", p).strip()
        if p and p not in out:
            out.append(p)
    return out[:6]

def apply_answer(conditions: dict, pending_q: dict, user_text: str) -> bool:
    normalize_conditions(conditions)
    t = (user_text or "").strip()
    cm = conditions["meta"]["common"]
    answers = conditions["meta"]["answers"]

    # Any time user says no alcohol -> override (avoid asking repeatedly)
    if any(x in t for x in ["ìˆ  ì•ˆ", "ìˆ ì•ˆ", "ì•ˆ ë§ˆì…”", "ê¸ˆì£¼", "ë…¸ì•Œì½œ", "ë…¸ ì•Œì½œ"]):
        cm["alcohol_level"] = "ì—†ìŒ"
        cm["alcohol_plan"] = None
        cm["alcohol_type"] = None
        return True

    key = pending_q.get("key")
    qtype = pending_q.get("type")

    if key == "location":
        if len(t) >= 1:
            conditions["location"] = t
            return True
        return False

    if qtype == "list_or_none" and key == "cannot_eat":
        parsed = parse_list_or_none(t)
        if parsed is None:
            return False
        conditions["constraints"]["cannot_eat"] = parsed
        cm["cannot_eat_done"] = True
        return True

    if qtype == "enum_alcohol" and key == "alcohol_level":
        if "ì—†" in t:
            cm["alcohol_level"] = "ì—†ìŒ"
            return True
        if "ê°€ë³" in t or "í•œë‘" in t:
            cm["alcohol_level"] = "ê°€ë³ê²Œ"
            return True
        if "ìˆ " in t or "ì œëŒ€ë¡œ" in t or "ì¤‘ì‹¬" in t:
            cm["alcohol_level"] = "ìˆ  ì¤‘ì‹¬"
            return True
        return False

    if qtype == "enum_stay" and key == "stay_duration":
        if "ë¹ " in t or "í›„ë”±" in t or "ê°„ë‹¨" in t:
            cm["stay_duration"] = "ë¹ ë¥´ê²Œ"
            return True
        if "ì˜¤ë˜" in t or "ê¸¸ê²Œ" in t:
            cm["stay_duration"] = "ì˜¤ë˜"
            return True
        if "ì ë‹¹" in t or "ë³´í†µ" in t:
            cm["stay_duration"] = "ì ë‹¹íˆ"
            return True
        return False

    if qtype == "enum_transport" and key == "transport":
        if "ì°¨" in t or "ìš´ì „" in t:
            cm["transport"] = "ì°¨"
            return True
        if "ëŒ€ì¤‘" in t or "ì§€í•˜ì² " in t or "ë²„ìŠ¤" in t:
            cm["transport"] = "ëŒ€ì¤‘êµí†µ"
            return True
        if "ìƒê´€" in t or "ì•„ë¬´" in t:
            cm["transport"] = "ìƒê´€ì—†ìŒ"
            return True
        return False

    if qtype == "enum_alcohol_plan" and key == "alcohol_plan":
        if "í•œ" in t and "ê³³" in t:
            cm["alcohol_plan"] = "í•œ ê³³"
            return True
        if "ë‚˜ëˆŒ" in t or ("1" in t and "2" in t):
            cm["alcohol_plan"] = "ë‚˜ëˆŒ ìˆ˜ë„"
            return True
        if "ëª¨ë¥´" in t or "ì•„ì§" in t:
            cm["alcohol_plan"] = "ëª¨ë¥´ê² ìŒ"
            return True
        return False

    if qtype == "enum_alcohol_type" and key == "alcohol_type":
        if "ì†Œì£¼" in t:
            cm["alcohol_type"] = "ì†Œì£¼"
            return True
        if "ë§¥ì£¼" in t or "ë¹„ì–´" in t:
            cm["alcohol_type"] = "ë§¥ì£¼"
            return True
        if "ì™€ì¸" in t:
            cm["alcohol_type"] = "ì™€ì¸"
            return True
        if "ìƒê´€" in t or "ì•„ë¬´" in t:
            cm["alcohol_type"] = "ìƒê´€ì—†ìŒ"
            return True
        return False

    if pending_q.get("scope") == "mode":
        k = key
        maps = {
            "work_tone": {"ê°€ë³": "ê°€ë²¼ìš´ íšŒì‹", "ìºì£¼ì–¼": "ê°€ë²¼ìš´ íšŒì‹", "ì •ëˆ": "ì •ëˆëœ ìë¦¬", "ê²©ì‹": "ì •ëˆëœ ìë¦¬"},
            "friend_focus": {"ëŒ€í™”": "ëŒ€í™”", "ìˆ˜ë‹¤": "ëŒ€í™”", "ë¨¹": "ë¨¹ëŠ” ì¬ë¯¸"},
            "group_purpose": {"ìŠ¤í„°ë””": "ìŠ¤í„°ë””+ì–˜ê¸°", "ê³µë¶€": "ìŠ¤í„°ë””+ì–˜ê¸°", "ì¶•í•˜": "ì¶•í•˜/í–‰ì‚¬", "í–‰ì‚¬": "ì¶•í•˜/í–‰ì‚¬", "ë°¥": "ë°¥+ìˆ˜ë‹¤", "ìˆ˜ë‹¤": "ë°¥+ìˆ˜ë‹¤"},
            "dating_stage": {"ì²«": "ì²«/ì–´ìƒ‰", "ì–´ìƒ‰": "ì²«/ì–´ìƒ‰", "ìµìˆ™": "ìµìˆ™", "í¸": "ìµìˆ™"},
            "solo_weight": {"ë“ ë“ ": "ë“ ë“ ", "ê°€ë³": "ê°€ë³ê²Œ"},
            "family_member": {"ë‘˜": "ë‘˜ ë‹¤", "ì•„ì´": "ì•„ì´", "ì–´ë¥¸": "ì–´ë¥¸", "ë¶€ëª¨": "ì–´ë¥¸", "ì—†": "ì—†ìŒ"},
        }
        picked = None
        for kw, val in maps.get(k, {}).items():
            if kw in t:
                picked = val
                break
        if picked is None:
            return False
        answers[k] = picked
        return True

    return False

# -----------------------------
# Query build (relax 0~3)
# -----------------------------
def build_query(conditions):
    normalize_conditions(conditions)
    tokens = []

    mode = conditions["meta"].get("context_mode")
    budget = conditions["meta"].get("budget_tier")
    cm = conditions["meta"]["common"]

    alcohol = cm.get("alcohol_level")
    stay = cm.get("stay_duration")
    alcohol_type = cm.get("alcohol_type")
    relax = int(cm.get("search_relax", 0) or 0)

    loc = conditions.get("location")
    if loc:
        tokens.append(loc)

    # If user explicitly says food_type (ì–‘ì‹/ì¼ì‹/ì¤‘ì‹/í•œì‹ ë“±), push early
    if conditions.get("food_type"):
        tokens.append(conditions["food_type"])

    # Place type token
    if alcohol in ("ê°€ë³ê²Œ", "ìˆ  ì¤‘ì‹¬"):
        if alcohol_type == "ì™€ì¸":
            place_token = "ì™€ì¸ë°”"
        elif alcohol_type == "ë§¥ì£¼":
            place_token = "í"
        elif alcohol_type == "ì†Œì£¼":
            place_token = "ìˆ ì§‘"
        else:
            place_token = "ìˆ ì§‘"
    else:
        if stay == "ì˜¤ë˜":
            place_token = "ì¹´í˜"
        elif stay == "ë¹ ë¥´ê²Œ":
            place_token = "ì‹ì‚¬"
        else:
            place_token = "ë§›ì§‘"

    if relax == 0:
        tokens.append(place_token)
        if mode == "íšŒì‚¬ íšŒì‹":
            tokens.append("íšŒì‹")
        elif mode == "ê°€ì¡±":
            tokens.append("ê°€ì¡±ì‹ì‚¬")
        elif mode == "ì—°ì¸ Â· ì¸ Â· ì†Œê°œíŒ…":
            tokens.append("ë°ì´íŠ¸")
        elif mode == "ë‹¨ì²´ ëª¨ì„":
            tokens.append("ë‹¨ì²´")
        if budget == "ê°€ì„±ë¹„":
            tokens.append("ê°€ì„±ë¹„")

    elif relax == 1:
        tokens.append(place_token)

    elif relax == 2:
        if place_token in ("ì™€ì¸ë°”", "í"):
            tokens.append("ìˆ ì§‘")
        else:
            tokens.append(place_token)

    else:  # relax >= 3
        if alcohol in ("ê°€ë³ê²Œ", "ìˆ  ì¤‘ì‹¬"):
            tokens.append("ìˆ ì§‘")
        else:
            tokens.append("ë§›ì§‘")

    return " ".join([t for t in tokens if t]).strip()

def make_query_variants(base_query: str, location: str, relax_level: int):
    qs = []
    if relax_level >= 1 and location:
        stripped = base_query.replace(location, "").strip()
        qs.append(f"{location} ê·¼ì²˜ {stripped}".strip())
        qs.append(f"{location} ì£¼ë³€ {stripped}".strip())
    qs.append(base_query)

    out, seen = [], set()
    for q in qs:
        q = re.sub(r"\s+", " ", q).strip()
        if q and q not in seen:
            seen.add(q)
            out.append(q)
    return out

# -----------------------------
# Candidate filtering
# -----------------------------
def filter_places(places, exclude_ids):
    if not exclude_ids:
        return places
    s = set(exclude_ids)
    return [p for p in places if p.get("id") not in s]

# -----------------------------
# rerank + formatting
# -----------------------------
def rerank_and_format(conditions, places):
    if client is None:
        return []

    normalize_conditions(conditions)
    cm = conditions["meta"]["common"]
    split_12 = (cm.get("alcohol_level") == "ìˆ  ì¤‘ì‹¬" and cm.get("alcohol_plan") == "ë‚˜ëˆŒ ìˆ˜ë„")

    compact = []
    for p in places[:25]:
        compact.append({
            "id": p.get("id"),
            "name": p.get("place_name"),
            "category": p.get("category_name"),
            "address": p.get("road_address_name") or p.get("address_name"),
            "url": p.get("place_url"),
            "walk_min": p.get("_walk_min"),
            "distance_m": p.get("_distance_m"),
        })

    schema_hint = """
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ë¼:
{
  "picks": [
    {
      "id": "...",
      "scene_feel": "ì—¬ê¸°ì„œ ì•½ì†í•˜ë©´ ì–´ë–¤ ëŠë‚Œì¸ì§€ 2~3ë¬¸ì¥(ì²´ê° ì¤‘ì‹¬, ê³¼ì¥ ê¸ˆì§€)",
      "one_line": "ì§§ì€ í•œì¤„ ì†Œê°œ (ì¹œêµ¬í†¤)",
      "hashtags": ["#...","#..."],
      "matched_conditions": ["ì‚¬ìš©ì ì¡°ê±´ ì¤‘ ì‹¤ì œë¡œ ë°˜ì˜í•œ ê²ƒ"],
      "reason": "ì™œ ì¶”ì²œì¸ì§€ 2~3ë¬¸ì¥(í›„ë³´ ë°ì´í„° ê¸°ë°˜, ì—†ëŠ” ì •ë³´ ìƒìƒ ê¸ˆì§€)"
      %s
    }
  ]
}
""" % (',\n      "phase": "1ì°¨"  // split ëª¨ë“œì¼ ë•Œë§Œ. "1ì°¨" ë˜ëŠ” "2ì°¨"' if split_12 else "")

    extra_rules = ""
    if split_12:
        extra_rules = """
ì¶”ê°€ ê·œì¹™ (ì¤‘ìš”):
- ì§€ê¸ˆì€ '1ì°¨Â·2ì°¨'ë¥¼ ë‚˜ëˆ ì„œ ì¶”ì²œí•´ì•¼ í•œë‹¤.
- picksëŠ” ì´ 3ê°œ ìœ ì§€.
- phaseë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ê³ ,
  - 1ì°¨ 2ê°œ
  - 2ì°¨ 1ê°œ
  êµ¬ì„±ìœ¼ë¡œ ì¶œë ¥í•´ë¼.
"""

    prompt = f"""
ë„ˆëŠ” 'ê²°ì • ë©”ì´íŠ¸'ë‹¤.
ì‚¬ìš©ì ì¡°ê±´ì— ë§ì¶° ì•„ë˜ í›„ë³´ ì¤‘ BEST 3ê³³ë§Œ ê³¨ë¼ë¼.

{schema_hint}

ì¤‘ìš” ê·œì¹™:
- matched_conditionsëŠ” 'ì‚¬ìš©ìê°€ ë§í•œ ì¡°ê±´/í•„í„°/ì§ˆë¬¸ ë‹µë³€'ì—ì„œë§Œ ë½‘ì•„ë¼.
- hashtagsëŠ” ì‚¬ìš©ì ì¡°ê±´ ê¸°ë°˜ìœ¼ë¡œ ë¨¼ì € ë§Œë“¤ê³ , ë¶€ì¡±í•˜ë©´ categoryë¡œ ë³´ì¶©.
- í•´ì‹œíƒœê·¸ëŠ” 4~6ê°œ
- ê³¼ì¥ ê¸ˆì§€ ('ë¬´ì¡°ê±´', 'ìµœê³ ', 'ì™„ë²½' ê¸ˆì§€)
- í›„ë³´ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œë§Œ ë§í•˜ê¸° (ì—†ëŠ” ì •ë³´ ìƒìƒ ê¸ˆì§€)
- picksëŠ” ë°˜ë“œì‹œ 3ê°œë§Œ
- scene_feelì€ "ìë¦¬ ë°°ì¹˜/ì¡°ëª…/ë™ì„ " ê°™ì€ ë””í…Œì¼ ë¬˜ì‚¬ ê¸ˆì§€. ì²´ê°ë§Œ.
- ê°€ëŠ¥í•˜ë©´(íŠ¹íˆ ëŒ€ì¤‘êµí†µì¼ ë•Œ) walk_minì´ í° í›„ë³´ëŠ” í”¼í•˜ë˜, ì¡°ê±´ ì í•©ì„±ì´ ë” ì¤‘ìš”í•˜ë©´ ì˜ˆì™¸ ê°€ëŠ¥.

{extra_rules}

[ì‚¬ìš©ì ì¡°ê±´]
{json.dumps(conditions, ensure_ascii=False, indent=2)}

[í›„ë³´ ëª©ë¡]
{json.dumps(compact, ensure_ascii=False, indent=2)}
"""

    def call_llm(extra_msg=None, temp=0.35):
        msgs = [{"role": "user", "content": prompt}]
        if extra_msg:
            msgs.append({"role": "user", "content": extra_msg})
        return client.chat.completions.create(
            model="gpt-4o-mini",
            messages=msgs,
            temperature=temp,
            response_format={"type": "json_object"},
        )

    res = call_llm(temp=0.35)
    raw = (res.choices[0].message.content or "").strip()
    st.session_state.debug_raw_rerank = raw

    data = safe_json_load(raw) or extract_first_json_object(raw)
    if data is None or "picks" not in data:
        res2 = call_llm(extra_msg="ë°©ê¸ˆ ì¶œë ¥ì´ ìŠ¤í‚¤ë§ˆë¥¼ ì•ˆ ì§€ì¼°ì–´. JSONë§Œ ë‹¤ì‹œ ì¶œë ¥í•´.", temp=0.1)
        raw2 = (res2.choices[0].message.content or "").strip()
        st.session_state.debug_raw_rerank = raw2
        data = safe_json_load(raw2) or extract_first_json_object(raw2)

    if not isinstance(data, dict):
        return []
    picks = data.get("picks", [])
    if not isinstance(picks, list):
        return []
    return picks[:3]

# -----------------------------
# Pre recommend text
# -----------------------------
def generate_pre_recommend_text(conditions, query):
    if client is None:
        return f"ì˜¤ì¼€ì´ã…‹ã…‹ **{query}**ë¡œ ë°”ë¡œ 3ê³³ ë½‘ì•„ë³¼ê²Œ ğŸ”"
    prompt = f"""
ë„ˆëŠ” ì‹ë‹¹ ì˜ ì•„ëŠ” ì¹œêµ¬ë‹¤.
ì¶”ì²œì„ ì‹œì‘í•˜ê¸° ì§ì „ì— í•˜ëŠ” ë©˜íŠ¸ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ë¼.
ì¡°ê±´ì„ ë°˜ì˜í•´ì„œ ë§í•´ë¼.

ì¡°ê±´:
{json.dumps(conditions, ensure_ascii=False)}

ê²€ìƒ‰ í‚¤ì›Œë“œ:
{query}

í†¤:
- í¸í•˜ê²Œ
- ë¦¬ì•¡ì…˜ í¬í•¨
- ì´ëª¨ì§€ 1ê°œ ì •ë„
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.85
    )
    return (res.choices[0].message.content or "").strip()

# -----------------------------
# Chat UI render history
# -----------------------------
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("ì˜ˆ: í™ëŒ€ ê·¼ì²˜ì—ì„œ 3ëª…ì´ ê°€ë³ê²Œ ìˆ  ë§ˆì‹¤ ê³³")

# -----------------------------
# Main interaction
# -----------------------------
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):

        if not openai_key or not kakao_key:
            st.warning("ì‚¬ì´ë“œë°”ì— OpenAI í‚¤ë‘ Kakao í‚¤ë¶€í„° ë„£ì–´ì¤˜!")
            st.stop()

        normalize_conditions(st.session_state.conditions)
        conditions = st.session_state.conditions
        cm = conditions["meta"]["common"]

        # Skip intent
        if detect_skip_intent(user_input):
            conditions["meta"]["fast_mode"] = True

        # Expand intent => relax up
        if detect_expand_intent(user_input):
            cm["search_relax"] = min(3, int(cm.get("search_relax", 0)) + 1)

        # 1) Apply pending question answer first
        if st.session_state.pending_question is not None:
            ok = apply_answer(conditions, st.session_state.pending_question, user_input)
            if ok:
                st.session_state.pending_question = None

        # 2) Extract patch and merge (diversify/exclude_last/franchise)
        patch = extract_conditions_patch(user_input, conditions)
        diversify = bool(patch.pop("diversify", False))
        exclude_last = bool(patch.pop("exclude_last", False))
        avoid_franchise = bool(patch.pop("avoid_franchise", False))
        conditions = merge_conditions(conditions, patch)
        st.session_state.conditions = conditions
        cm = conditions["meta"]["common"]

        # Debug: current conditions
        with st.expander("ğŸ§¾ í˜„ì¬ ëˆ„ì  ì¡°ê±´(JSON)"):
            st.json(conditions)
            if debug_mode:
                st.markdown("**(ë””ë²„ê·¸) patch ì›ë¬¸**")
                st.code(st.session_state.debug_raw_patch)

        # 3) Ask next question if needed
        next_q = get_next_question(conditions)

        # In fast_mode, still ask location/cannot_eat, but skip others
        if next_q and not (conditions["meta"].get("fast_mode") and next_q.get("key") not in ("location", "cannot_eat")):
            st.markdown(next_q["text"])
            st.session_state.messages.append({"role": "assistant", "content": next_q["text"]})
            st.session_state.pending_question = next_q
            st.stop()

        # 4) If location missing, force ask
        if not conditions.get("location"):
            msg = "ì¢‹ì•„! ê·¼ë° **ë™ë„¤/ì—­**ë¶€í„° ì•Œë ¤ì¤˜ì•¼ ë‚´ê°€ ë½‘ì•„ì£¼ì§€ ğŸ˜\nì˜ˆ: `í•©ì •`, `ì—°ë‚¨ë™`, `ê°•ë‚¨ì—­`"
            st.markdown(msg)
            st.session_state.messages.append({"role": "assistant", "content": msg})
            st.session_state.pending_question = {"scope": "common", "key": "location", "text": msg, "type": "free"}
            st.stop()

        # -----------------------------
        # 5) Kakao search: bigger pool + center/radius/distance
        # -----------------------------
        transport = cm.get("transport")  # ì°¨ / ëŒ€ì¤‘êµí†µ / ìƒê´€ì—†ìŒ
        location = conditions.get("location")

        # center (station preferred)
        center = get_location_center(location, kakao_key)
        cm["center_name"] = center.get("name") if center else None

        # radius steps for pooling
        if transport == "ì°¨":
            pool_radius_steps = [1600, 2500, 4000]
        else:
            pool_radius_steps = [1200, 1800, 2500]

        def run_kakao_pooled(query_str: str):
            # if no center, just page through (still up to 45)
            if not center:
                return kakao_keyword_search_paged(query_str, kakao_key, size=15, max_pages=3)

            final_docs = []
            for r in pool_radius_steps:
                docs = kakao_keyword_search_paged(
                    query_str, kakao_key,
                    x=center["x"], y=center["y"],
                    radius=r,
                    sort="distance",
                    size=15, max_pages=3
                )
                final_docs = docs
                if len(docs) >= 25:  # enough pool for rerank
                    break
            return final_docs

        places = []
        used_query = None

        # Try relax 0~3, with variants
        for _ in range(4):
            base_query = build_query(conditions)
            variants = make_query_variants(base_query, location, int(cm.get("search_relax", 0)))

            for q in variants:
                try:
                    docs = run_kakao_pooled(q)
                except Exception as e:
                    st.error(f"Kakao ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                    st.stop()

                if docs:
                    places = docs
                    used_query = q
                    break

            if places:
                break

            if int(cm.get("search_relax", 0)) < 3:
                cm["search_relax"] = int(cm.get("search_relax", 0)) + 1
            else:
                break

        if not places:
            msg = "í—‰â€¦ ì´ ì¡°ê±´ìœ¼ë¡œëŠ” ë”± ë§ëŠ” ë°ê°€ ì˜ ì•ˆ ì¡íˆë„¤ ğŸ¥²\nì¡°ê±´ì„ ì¡°ê¸ˆ ëŠìŠ¨í•˜ê²Œ í•´ì„œ ê·¼ì²˜ ìœ„ì£¼ë¡œ ë‹¤ì‹œ ë½‘ì•„ë³¼ê¹Œ?"
            st.markdown(msg)
            st.session_state.messages.append({"role": "assistant", "content": msg})
            st.stop()

        # Pre-text
        pre_text = generate_pre_recommend_text(conditions, used_query or build_query(conditions))
        st.markdown(pre_text)
        if debug_mode and used_query:
            st.caption(f"ğŸ” ì‚¬ìš©ëœ ê²€ìƒ‰ì–´: {used_query} (relax={cm.get('search_relax', 0)})")
            if center:
                st.caption(f"ğŸ“Œ ì¤‘ì‹¬ì¢Œí‘œ: {cm.get('center_name')}")

        # -----------------------------
        # 6) Sort + exclude last + radius focus + attach meta
        # -----------------------------
        if center:
            places = sort_places_for_transport(places, center, transport)

        if diversify or exclude_last:
            places = filter_places(places, st.session_state.last_picks_ids)

        # radius focus (prefer within steps but don't kill pool)
        focus_steps = [1200, 1800, 2500] if transport != "ì°¨" else [1600, 2500, 4000]
        focused = []
        if center:
            for r in focus_steps:
                within = filter_places_by_radius(places, center, r)
                if len(within) >= 12:  # keep a stronger pool than 6
                    focused = within
                    break
            if not focused:
                focused = places
        else:
            focused = places

        # Attach distance meta for UI + LLM
        focused = attach_distance_meta(focused, center)

        # -----------------------------
        # 7) Rule-based kind filter BEFORE LLM (meal/cafe/drink)
        # -----------------------------
        kind = infer_place_kind_from_conditions(conditions)
        filtered_kind = filter_by_kind(focused, kind)

        # Optional: franchise exclusion (only if user asked)
        filtered_kind = filter_franchise(filtered_kind, avoid_franchise)

        # Final candidate pool for rerank
        candidates = filtered_kind[:25]  # give LLM more room than 15

        if debug_mode:
            with st.expander("ğŸ§ª (ë””ë²„ê·¸) í›„ë³´ í’€ ìƒ˜í”Œ"):
                sample = [{
                    "name": p.get("place_name"),
                    "cat": p.get("category_name"),
                    "walk_min": p.get("_walk_min"),
                    "dist_m": p.get("_distance_m")
                } for p in candidates[:12]]
                st.json({
                    "kind": kind,
                    "pool_total": len(places),
                    "focused_total": len(focused),
                    "after_kind_filter": len(filtered_kind),
                    "after_franchise_filter": len(candidates),
                    "sample": sample
                })

        # -----------------------------
        # 8) Rerank
        # -----------------------------
        picks = rerank_and_format(conditions, candidates)

        if debug_mode:
            with st.expander("ğŸ¤– (ë””ë²„ê·¸) rerank LLM ì›ë¬¸"):
                st.code(st.session_state.debug_raw_rerank)

        # Fallback if LLM fails: choose closest 3 from candidates
        if not picks:
            fallback = []
            for p in candidates[:3]:
                fallback.append({
                    "id": p.get("id"),
                    "scene_feel": "ì¡°ê±´ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¼ì²˜ ìœ„ì£¼ë¡œ ì •ë¦¬í–ˆì–´. ë§í¬ ëˆŒëŸ¬ì„œ ë¶„ìœ„ê¸°ë§Œ ë¹ ë¥´ê²Œ í™•ì¸í•˜ë©´ ë”±ì´ì•¼.",
                    "one_line": "ê·¼ì²˜ì—ì„œ ë¬´ë‚œí•˜ê²Œ ê°€ê¸° ì¢‹ì€ ì„ íƒì§€!",
                    "hashtags": ["#ê·¼ì²˜", "#ë¬´ë‚œ", "#ë°”ë¡œê°€ê¸°", "#ì¶”ì²œ"],
                    "matched_conditions": ["ê·¼ì²˜ ìš°ì„ ", "ë„ë³´/ê±°ë¦¬ ê¸°ì¤€"],
                    "reason": "ì •ë¦¬ ê³¼ì •ì´ ê¼¬ì—¬ì„œ, ìš°ì„  ê°€ê¹Œìš´ ê³³ë¶€í„° ì¶”ë ¸ì–´. ë©”ë‰´/ë¶„ìœ„ê¸° í™•ì¸í•˜ê³  ê³¨ë¼ì¤˜ ğŸ˜"
                })
            picks = fallback

        # -----------------------------
        # 9) Render cards
        # -----------------------------
        kakao_map = {p.get("id"): p for p in candidates}

        st.markdown("---")
        st.subheader("ğŸ½ï¸ ë”± 3ê³³ë§Œ ê³¨ëì–´")

        cols = st.columns(3)
        current_pick_ids = []
        center_name = cm.get("center_name") or "ê¸°ì¤€ì "

        for i, pick in enumerate(picks[:3]):
            if not isinstance(pick, dict) or "id" not in pick:
                continue

            place = kakao_map.get(pick["id"])
            if not place:
                continue

            current_pick_ids.append(pick["id"])

            with cols[i]:
                name = place.get("place_name")
                addr = place.get("road_address_name") or place.get("address_name")
                url = place.get("place_url")
                category = place.get("category_name")

                phase = pick.get("phase")
                if phase:
                    st.markdown(f"**[{phase}]**")

                st.markdown(f"### {i+1}. {name}")
                st.caption(category or "")
                st.write(f"ğŸ“ {addr}")

                walk_min = place.get("_walk_min")
                if isinstance(walk_min, int) and walk_min < 180:
                    st.caption(f"ğŸš¶ {center_name} ê¸°ì¤€ ë„ë³´ ì•½ {walk_min}ë¶„")

                scene = (pick.get("scene_feel") or "").strip()
                if scene:
                    st.markdown("ğŸ§  **ì´ëŸ° ìë¦¬ ëŠë‚Œ**")
                    st.write(scene)

                st.markdown(f"**{pick.get('one_line','')}**")

                matched = pick.get("matched_conditions", [])
                if matched:
                    st.markdown("**ë°˜ì˜í•œ ì¡°ê±´**")
                    st.markdown(" Â· ".join([f"`{m}`" for m in matched]))

                tags = pick.get("hashtags", [])
                if tags:
                    st.markdown(" ".join(tags))

                st.markdown("**ì™œ ì—¬ê¸°ëƒë©´â€¦**")
                st.write(pick.get("reason", ""))

                if url:
                    st.link_button("ì¹´ì¹´ì˜¤ë§µì—ì„œ ë³´ê¸°", url)

        st.session_state.last_picks_ids = current_pick_ids

        # Prototype log
        try:
            with open("decision_mate_logs.jsonl", "a", encoding="utf-8") as f:
                f.write(json.dumps({
                    "ts": int(time.time()),
                    "query_used": used_query,
                    "kind": kind,
                    "avoid_franchise": avoid_franchise,
                    "center": cm.get("center_name"),
                    "conditions": conditions,
                    "picks": picks,
                    "place_ids": current_pick_ids,
                    "pool_counts": {
                        "raw_places": len(places),
                        "focused": len(focused),
                        "after_kind": len(filtered_kind),
                        "candidates": len(candidates),
                    }
                }, ensure_ascii=False) + "\n")
        except Exception:
            pass

        final = "ë! ğŸ˜\nì…‹ ì¤‘ì— í•˜ë‚˜ ê³ ë¥´ê±°ë‚˜, 'ë” ì¡°ìš©í•œ ë°', 'ì£¼ì°¨ ë˜ëŠ” ë°', 'ì™„ì „ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼', 'í”„ì°¨ ë¹¼ì¤˜' ì´ëŸ° ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì¼œë„ ë¼."
        st.session_state.messages.append({"role": "assistant", "content": final})
        st.markdown(final)
